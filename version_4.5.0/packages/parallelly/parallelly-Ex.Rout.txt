
R version 4.5.0 (2025-04-11) -- "How About a Twenty-Six"
Copyright (C) 2025 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "parallelly"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('parallelly')
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("as.cluster")
> ### * as.cluster
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: as.cluster
> ### Title: Coerce an Object to a Cluster Object
> ### Aliases: as.cluster as.cluster.cluster as.cluster.list
> ###   as.cluster.SOCKnode as.cluster.SOCK0node as.cluster.RichSOCKnode
> ###   c.cluster
> 
> ### ** Examples
> 
> cl1 <- makeClusterPSOCK(2, dryrun = TRUE)
----------------------------------------------------------------------
Manually, start worker #1 on local machine ‘localhost’ with:

  '/usr/local/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions="no-delay")' -e 'workRSOCK<-tryCatch(parallel:::.workRSOCK,error=function(e)parallel:::.slaveRSOCK);workRSOCK()' MASTER=localhost PORT=11986 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential

----------------------------------------------------------------------
Manually, start worker #2 on local machine ‘localhost’ with:

  '/usr/local/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions="no-delay")' -e 'workRSOCK<-tryCatch(parallel:::.workRSOCK,error=function(e)parallel:::.slaveRSOCK);workRSOCK()' MASTER=localhost PORT=11986 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential

> cl2 <- makeClusterPSOCK(c("n1", "server.remote.org"), dryrun = TRUE)
----------------------------------------------------------------------
Manually, (i) login into external machine ‘n1’:

  '/usr/bin/ssh' -R 11592:localhost:11592 n1

and (ii) start worker #1 from there:

  '/usr/local/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions="no-delay")' -e 'workRSOCK<-tryCatch(parallel:::.workRSOCK,error=function(e)parallel:::.slaveRSOCK);workRSOCK()' MASTER=localhost PORT=11592 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential

Alternatively, start worker #1 from the local machine by combining both steps in a single call:

  '/usr/bin/ssh' -R 11592:localhost:11592 n1 "'/usr/local/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions=\"no-delay\")' -e 'workRSOCK<-tryCatch(parallel:::.workRSOCK,error=function(e)parallel:::.slaveRSOCK);workRSOCK()' MASTER=localhost PORT=11592 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential"

----------------------------------------------------------------------
Manually, (i) login into external machine ‘server.remote.org’:

  '/usr/bin/ssh' -R 11593:localhost:11592 server.remote.org

and (ii) start worker #2 from there:

  'Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions="no-delay")' -e 'workRSOCK<-tryCatch(parallel:::.workRSOCK,error=function(e)parallel:::.slaveRSOCK);workRSOCK()' MASTER=localhost PORT=11593 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential

Alternatively, start worker #2 from the local machine by combining both steps in a single call:

  '/usr/bin/ssh' -R 11593:localhost:11592 server.remote.org "'Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions=\"no-delay\")' -e 'workRSOCK<-tryCatch(parallel:::.workRSOCK,error=function(e)parallel:::.slaveRSOCK);workRSOCK()' MASTER=localhost PORT=11593 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential"

> cl <- c(cl1, cl2)
Warning: The combined cluster contains 3 duplicated nodes
> print(cl)
Socket cluster with 4 nodes where 4 nodes are on host ‘NA’ (R version and platform not queried)
> 
> 
> 
> cleanEx()
> nameEx("autoStopCluster")
> ### * autoStopCluster
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: autoStopCluster
> ### Title: Automatically Stop a Cluster when Garbage Collected
> ### Aliases: autoStopCluster
> 
> ### ** Examples
> 
> cl <- makeClusterPSOCK(2, dryrun = TRUE)
----------------------------------------------------------------------
Manually, start worker #1 on local machine ‘localhost’ with:

  '/usr/local/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions="no-delay")' -e 'workRSOCK<-tryCatch(parallel:::.workRSOCK,error=function(e)parallel:::.slaveRSOCK);workRSOCK()' MASTER=localhost PORT=11943 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential

----------------------------------------------------------------------
Manually, start worker #2 on local machine ‘localhost’ with:

  '/usr/local/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions="no-delay")' -e 'workRSOCK<-tryCatch(parallel:::.workRSOCK,error=function(e)parallel:::.slaveRSOCK);workRSOCK()' MASTER=localhost PORT=11943 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential

> cl <- autoStopCluster(cl)
> print(cl)
Socket cluster with 2 nodes where 2 nodes are on host ‘NA’ (R version and platform not queried). This cluster is registered to be automatically stopped by the garbage collector
> rm(list = "cl")
> gc()
         used (Mb) gc trigger (Mb) max used (Mb)
Ncells 439991 23.5     903280 48.3   707674 37.8
Vcells 822234  6.3    8388608 64.0  1973740 15.1
> 
> 
> 
> cleanEx()
> nameEx("availableConnections")
> ### * availableConnections
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: availableConnections
> ### Title: Number of Available and Free Connections
> ### Aliases: availableConnections freeConnections
> 
> ### ** Examples
> 
> total <- availableConnections()
> message("You can have ", total, " connections open in this R installation")
You can have 128 connections open in this R installation
> free <- freeConnections()
> message("There are ", free, " connections remaining")
There are 125 connections remaining
> 
> 
> 
> 
> cleanEx()
> nameEx("availableCores")
> ### * availableCores
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: availableCores
> ### Title: Get Number of Available Cores on The Current Machine
> ### Aliases: availableCores
> 
> ### ** Examples
> 
> message(paste("Number of cores available:", availableCores()))
Number of cores available: 4
> 
> ## Not run: 
> ##D options(mc.cores = 2L)
> ##D message(paste("Number of cores available:", availableCores()))
> ## End(Not run)
> 
> ## Not run: 
> ##D ## IMPORTANT: availableCores() may return 1L
> ##D options(mc.cores = 1L)
> ##D ncores <- availableCores() - 1      ## ncores = 0
> ##D ncores <- availableCores(omit = 1)  ## ncores = 1
> ##D message(paste("Number of cores to use:", ncores))
> ## End(Not run)
> 
> ## Not run: 
> ##D ## Use 75% of the cores on the system but never more than four
> ##D options(parallelly.availableCores.custom = function() {
> ##D   ncores <- max(parallel::detectCores(), 1L, na.rm = TRUE)
> ##D   ncores <- min(as.integer(0.75 * ncores), 4L)
> ##D   max(1L, ncores)
> ##D })
> ##D message(paste("Number of cores available:", availableCores()))
> ##D 
> ##D ## Use 50% of the cores according to availableCores(), e.g.
> ##D ## allocated by a job scheduler or cgroups.
> ##D ## Note that it is safe to call availableCores() here.
> ##D options(parallelly.availableCores.custom = function() {
> ##D   0.50 * parallelly::availableCores()
> ##D })
> ##D message(paste("Number of cores available:", availableCores()))
> ## End(Not run)
> 
> 
> 
> 
> cleanEx()
> nameEx("availableWorkers")
> ### * availableWorkers
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: availableWorkers
> ### Title: Get Set of Available Workers
> ### Aliases: availableWorkers
> 
> ### ** Examples
> 
> message(paste("Available workers:",
+         paste(sQuote(availableWorkers()), collapse = ", ")))
Available workers: ‘localhost’, ‘localhost’, ‘localhost’, ‘localhost’
> 
> ## Not run: 
> ##D options(mc.cores = 2L)
> ##D message(paste("Available workers:",
> ##D         paste(sQuote(availableWorkers()), collapse = ", ")))
> ## End(Not run)
> 
> ## Not run: 
> ##D ## Always use two workers on host 'n1' and one on host 'n2'
> ##D options(parallelly.availableWorkers.custom = function() {
> ##D   c("n1", "n1", "n2")
> ##D })
> ##D message(paste("Available workers:",
> ##D         paste(sQuote(availableWorkers()), collapse = ", ")))
> ## End(Not run)
> 
> ## Not run: 
> ##D ## A 50% random subset of the available workers.
> ##D ## Note that it is safe to call availableWorkers() here.
> ##D options(parallelly.availableWorkers.custom = function() {
> ##D   workers <- parallelly::availableWorkers()
> ##D   sample(workers, size = 0.50 * length(workers))
> ##D })
> ##D message(paste("Available workers:",
> ##D         paste(sQuote(availableWorkers()), collapse = ", ")))
> ## End(Not run)
> 
> 
> 
> 
> cleanEx()
> nameEx("cloneNode")
> ### * cloneNode
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cloneNode
> ### Title: Clone one or more nodes
> ### Aliases: cloneNode
> 
> ### ** Examples
> 
> 
> 
> 
> 
> cleanEx()
> nameEx("cpuLoad")
> ### * cpuLoad
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cpuLoad
> ### Title: Get the Recent CPU Load
> ### Aliases: cpuLoad
> ### Keywords: internal
> 
> ### ** Examples
> 
> loadavg <- cpuLoad()
> print(loadavg)
 1min  5min 15min 
 1.21  1.39  1.40 
> 
> 
> 
> cleanEx()
> nameEx("freeCores")
> ### * freeCores
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: freeCores
> ### Title: Get the Average Number of Free CPU Cores
> ### Aliases: freeCores
> ### Keywords: internal
> 
> ### ** Examples
> 
> free <- freeCores()
> print(free)
[1] 2
attr(,"loadavg")
 1min  5min 15min 
 1.21  1.39  1.40 
attr(,"maxCores")
system 
     4 
attr(,"memory")
[1] "5min"
attr(,"fraction")
[1] 0.9
> 
> ## Not run: 
> ##D ## Make availableCores() agile to the system load
> ##D options(parallelly.availableCores.custom = function() freeCores())
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("isConnectionValid")
> ### * isConnectionValid
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: isConnectionValid
> ### Title: Checks if a Connection is Valid
> ### Aliases: isConnectionValid connectionId
> 
> ### ** Examples
> 
> ## R represents connections as plain indices
> as.integer(stdin())          ## int 0
[1] 0
> as.integer(stdout())         ## int 1
[1] 1
> as.integer(stderr())         ## int 2
[1] 2
> 
> ## The first three connections always exist and are always valid
> isConnectionValid(stdin())   ## TRUE
[1] TRUE
> connectionId(stdin())        ## 0L
[1] 0
> isConnectionValid(stdout())  ## TRUE
[1] TRUE
> connectionId(stdout())       ## 1L
[1] 1
> isConnectionValid(stderr())  ## TRUE
[1] TRUE
> connectionId(stderr())       ## 2L
[1] 2
> 
> ## Connections cannot be serialized
> con <- file(tempfile(), open = "w")
> x <- list(value = 42, stderr = stderr(), con = con)
> y <- unserialize(serialize(x, connection = NULL))
> isConnectionValid(y$stderr)  ## TRUE
[1] TRUE
> connectionId(y$stderr)       ##  2L
[1] 2
> isConnectionValid(y$con)     ## FALSE with attribute 'reason'
[1] FALSE
attr(,"reason")
[1] "Connection (connection: index=3, description=\"/tmp/RtmpH01jue/file1827f18b0c68a\", class=\"file\", mode=\"w\", text=\"text\", opened=\"opened\", can read=\"no\", can write=\"yes\", id=-1) is no longer valid. It differ from the currently registered R connection with the same index 3 (connection: index=3, description=\"/tmp/RtmpH01jue/file1827f18b0c68a\", class=\"file\", mode=\"w\", text=\"text\", opened=\"opened\", can read=\"no\", can write=\"yes\", id=210, raw_id=\"<pointer: 0xd2>\")"
> connectionId(y$con)          ## -1L
[1] -1
> close(con)
> 
> 
> 
> 
> cleanEx()
> nameEx("isNodeAlive")
> ### * isNodeAlive
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: isNodeAlive
> ### Title: Check whether or not the cluster nodes are alive
> ### Aliases: isNodeAlive
> 
> ### ** Examples
> 
> 
> 
> 
> 
> cleanEx()
> nameEx("killNode")
> ### * killNode
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: killNode
> ### Title: Terminate one or more cluster nodes using process signaling
> ### Aliases: killNode
> 
> ### ** Examples
> 
> ## Don't show: 
> if ((interactive() || .Platform[["OS.type"]] != "windows")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ cl <- makeClusterPSOCK(2)
+ print(isNodeAlive(cl))  ## [1] TRUE TRUE
+ 
+ res <- killNode(cl)
+ print(res)
+ 
+ ## It might take a moment before the background
+ ## workers are shutdown after having been signaled
+ Sys.sleep(1.0)
+ 
+ print(isNodeAlive(cl))  ## [1] FALSE FALSE
+ ## Don't show: 
+ }) # examplesIf
> cl <- makeClusterPSOCK(2)
> print(isNodeAlive(cl))
[1] TRUE TRUE
> res <- killNode(cl)
> print(res)
[1] TRUE TRUE
> Sys.sleep(1)
> print(isNodeAlive(cl))
[1] TRUE TRUE
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("makeClusterMPI")
> ### * makeClusterMPI
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: makeClusterMPI
> ### Title: Create a Rich Message Passing Interface (MPI) Cluster of R
> ###   Workers for Parallel Processing
> ### Aliases: makeClusterMPI RMPI
> 
> ### ** Examples
> 
> 
> 
> 
> 
> cleanEx()
> nameEx("makeClusterPSOCK")
> ### * makeClusterPSOCK
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: makeClusterPSOCK
> ### Title: Create a Rich PSOCK Cluster of R Workers for Parallel Processing
> ### Aliases: makeClusterPSOCK RPSOCK makeNodePSOCK
> 
> ### ** Examples
> 
> ## NOTE: Drop 'dryrun = TRUE' below in order to actually connect.  Add
> ## 'verbose = TRUE' if you run into problems and need to troubleshoot.
> 
> ## ---------------------------------------------------------------
> ## Section 1. Setting up parallel workers on the local machine
> ## ---------------------------------------------------------------
> ## EXAMPLE: Two workers on the local machine
> workers <- c("localhost", "localhost")
> cl <- makeClusterPSOCK(workers, dryrun = TRUE, quiet = TRUE)
> 
> 
> ## EXAMPLE: Launch 124 workers on MS Windows 10, where half are
> ## running on CPU Group #0 and half on CPU Group #1.  
> ## (https://lovickconsulting.com/2021/11/18/
> ##  running-r-clusters-on-an-amd-threadripper-3990x-in-windows-10-2/)
> ## The parallel workers are launched as:
> ## "%COMSPEC%" /c start /B /NODE 1 /AFFINITY 0xFFFFFFFFFFFFFFFE ...
> ## ...
> ## "%COMSPEC%" /c start /B /NODE 1 /AFFINITY 0xFFFFFFFFFFFFFFFE ...
> 
> ## Temporarily disable CPU load protection for this example
> oopts <- options(parallelly.maxWorkers.localhost = Inf)
> 
> ncores <- 124
> cpu_groups <- c(0, 1)
> cl <- lapply(cpu_groups, FUN = function(cpu_group) {
+     parallelly::makeClusterPSOCK(ncores %/% length(cpu_groups),
+       rscript = I(c(
+         Sys.getenv("COMSPEC"), "/c", "start", "/B",
+         "/NODE", cpu_group, "/AFFINITY", "0xFFFFFFFFFFFFFFFE",
+         "*"
+       )),
+       dryrun = TRUE, quiet = TRUE
+     )
+ })
> ## merge the two 62-node clusters into one with 124 nodes
> cl <- do.call(c, cl)
Warning: The combined cluster contains 123 duplicated nodes
> 
> ## Re-enable CPU load protection
> options(oopts)
> 
> 
> ## ---------------------------------------------------------------
> ## Section 2. Setting up parallel workers on remote machines
> ## ---------------------------------------------------------------
> ## EXAMPLE: Three remote workers
> ## Setup of three R workers on two remote machines are set up
> ## The parallel workers are launched as:
> ## '/usr/bin/ssh' -R 11058:localhost:11058 n1.remote.org ...
> ## '/usr/bin/ssh' -R 11059:localhost:11058 n2.remote.org ...
> ## '/usr/bin/ssh' -R 11060:localhost:11058 n1.remote.org ...
> workers <- c("n1.remote.org", "n2.remote.org", "n1.remote.org")
> cl <- makeClusterPSOCK(workers, dryrun = TRUE, quiet = TRUE)
> 
> 
> ## EXAMPLE: Two remote workers running on MS Windows.  Because the
> ## remote workers are MS Windows machines, we need to use
> ## rscript_sh = "cmd".
> ## The parallel workers are launched as:
> ## '/usr/bin/ssh' -R 11912:localhost:11912 mswin1.remote.org ...
> ## '/usr/bin/ssh' -R 11913:localhost:11912 mswin2.remote.org ...
> workers <- c("mswin1.remote.org", "mswin2.remote.org")
> cl <- makeClusterPSOCK(workers, rscript_sh = "cmd", dryrun = TRUE, quiet = TRUE)
> 
> 
> ## EXAMPLE: Local and remote workers
> ## Same setup when the two machines are on the local network and
> ## have identical software setups
> cl <- makeClusterPSOCK(
+   workers,
+   revtunnel = FALSE, homogeneous = TRUE,
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> ## EXAMPLE: Three remote workers 'n1', 'n2', and 'n3' that can only be
> ## accessed via jumphost 'login.remote.org'
> ## The parallel workers are launched as:
> ## '/usr/bin/ssh' -R 11226:localhost:11226 -J login.remote.org n1 ...
> ## '/usr/bin/ssh' -R 11227:localhost:11226 -J login.remote.org n2 ...
> ## '/usr/bin/ssh' -R 11228:localhost:11226 -J login.remote.org n1 ...
> workers <- c("n1", "n2", "n1")
> cl <- makeClusterPSOCK(
+   workers,
+   rshopts = c("-J", "login.remote.org"),
+   homogeneous = FALSE,
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> ## EXAMPLE: Remote worker running on Linux from MS Windows machine
> ## Connect to remote Unix machine 'remote.server.org' on port 2200
> ## as user 'bob' from a MS Windows machine with PuTTY installed.
> ## Using the explicit special rshcmd = "<putty-plink>", will force
> ## makeClusterPSOCK() to search for and use the PuTTY plink software,
> ## preventing it from using other SSH clients on the system search PATH.
> ## The parallel worker is launched as:
> ## 'plink' -l bob -P 2200 -i C:/Users/bobby/.ssh/putty.ppk remote.server.org ...
> cl <- makeClusterPSOCK(
+   "remote.server.org", user = "bob",
+   rshcmd = "<putty-plink>",
+   rshopts = c("-P", 2200, "-i", "C:/Users/bobby/.ssh/putty.ppk"),
+   dryrun = TRUE, quiet = TRUE
+ )
Warning in find_rshcmd(which = which, must_work = !localMachine && !manual &&  :
  Failed to locate a default SSH client (checked: ‘putty-plink’). Please specify one via argument 'rshcmd'. Will still try with ‘ssh’.
> 
> 
> ## EXAMPLE: Remote workers with specific setup
> ## Setup of remote worker with more detailed control on
> ## authentication and reverse SSH tunneling
> ## The parallel worker is launched as:
> ## '/usr/bin/ssh' -l johnny -v -R 11000:gateway:11942 remote.server.org ...
> ## "R_DEFAULT_PACKAGES=... 'nice' '/path/to/Rscript' --no-init-file ...
> cl <- makeClusterPSOCK(
+   "remote.server.org", user = "johnny",
+   ## Manual configuration of reverse SSH tunneling
+   revtunnel = FALSE,
+   rshopts = c("-v", "-R 11000:gateway:11942"),
+   master = "gateway", port = 11942,
+   ## Run Rscript nicely and skip any startup scripts
+   rscript = c("nice", "/path/to/Rscript"),
+   rscript_args = c("--no-init-file"),
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> ## EXAMPLE: Remote worker running on Linux from RStudio on MS Windows
> ## Connect to remote Unix machine 'remote.server.org' on port 2200
> ## as user 'bob' from a MS Windows machine via RStudio's SSH client.
> ## Using the explicit special rshcmd = "<rstudio-ssh>", will force
> ## makeClusterPSOCK() to use the SSH client that comes with RStudio,
> ## preventing it from using other SSH clients on the system search PATH.
> ## The parallel worker is launched as:
> ## 'ssh' -l bob remote.server.org:2200 ...
> cl <- makeClusterPSOCK(
+   "remote.server.org:2200", user = "bob", rshcmd = "<rstudio-ssh>",
+   dryrun = TRUE, quiet = TRUE
+ )
Warning in find_rshcmd(which = which, must_work = !localMachine && !manual &&  :
  Failed to locate a default SSH client (checked: ‘rstudio-ssh’). Please specify one via argument 'rshcmd'. Will still try with ‘ssh’.
> 
> 
> ## ---------------------------------------------------------------
> ## Section 3. Setting up parallel workers on HPC cluster
> ## ---------------------------------------------------------------
> ## EXAMPLE: 'Grid Engine' is a high-performance compute (HPC) job
> ## scheduler where one can request compute resources on multiple nodes,
> ## each running multiple cores. Examples of Grid Engine schedulers are
> ## Oracle Grid Engine (formerly Sun Grid Engine), Univa Grid Engine,
> ## and Son of Grid Engine - all commonly referred to as SGE schedulers.
> ## Each SGE cluster may have its own configuration with their own way
> ## of requesting parallel slots. Here are a few examples:
> ##
> ##   ## Request 18 slots on a single host
> ##   qsub -pe smp 18 script.sh
> ##
> ##   ## Request 18 slots on one or more hosts
> ##   qsub -pe mpi 18 script.sh
> ##
> ## This will launch the job script 'script.sh' on one host, while have
> ## reserved in total 18 slots (CPU cores) on this host and possible
> ## other hosts.
> ##
> ## This example shows how to use the SGE command 'qrsh' to launch
> ## 18 parallel workers from R, which is assumed to have been launched
> ## by 'script.sh'.
> ##
> ## The parallel workers are launched as:
> ## 'qrsh' -inherit -nostdin -V comphost01 ...
> ## 'qrsh' -inherit -nostdin -V comphost01 ...
> ## ...
> ## 'qrsh' -inherit -nostdin -V comphost06 ...
> cl <- makeClusterPSOCK(
+   availableWorkers(),
+   rshcmd = "qrsh", rshopts = c("-inherit", "-nostdin", "-V"),
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> ## EXAMPLE: The 'Fujitsu Technical Computing Suite' is a high-performance
> ## compute (HPC) job scheduler where one can request compute resources on
> ## multiple nodes, each running multiple cores.  For example,
> ##
> ##   pjsub -L vnode=3 -L vnode-core=18 script.sh
> ##
> ## reserves 18 cores on three nodes. The job script runs on the first
> ## with enviroment variables set to infer the other nodes, resulting in
> ## availableWorkers() to return 3 * 18 workers. When the HPC environment
> ## does not support SSH between compute nodes, one can use the 'pjrsh'
> ## command to launch the parallel workers.
> ##
> ## The parallel workers are launched as:
> ## 'pjrsh' comphost01 ...
> ## 'pjrsh' comphost01 ...
> ## ...
> ## 'pjrsh' comphost06 ...
> cl <- makeClusterPSOCK(
+   availableWorkers(),
+   rshcmd = "pjrsh",
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> 
> ## ---------------------------------------------------------------
> ## Section 4. Setting up remote parallel workers in the cloud
> ## ---------------------------------------------------------------
> ## EXAMPLE: Remote worker running on AWS
> ## Launching worker on Amazon AWS EC2 running one of the
> ## Amazon Machine Images (AMI) provided by RStudio
> ## (https://www.louisaslett.com/RStudio_AMI/)
> ##
> ## The parallel worker is launched as:
> ## '/usr/bin/ssh' -R 11153:localhost:11153 -l ubuntu ...
> ## -o StrictHostKeyChecking=no -o IdentitiesOnly=yes ...
> ## -i ~/.ssh/my-private-aws-key.pem 1.2.3.4 ...
> public_ip <- "1.2.3.4"
> ssh_private_key_file <- "~/.ssh/my-private-aws-key.pem"
> cl <- makeClusterPSOCK(
+   ## Public IP number of EC2 instance
+   public_ip,
+   ## User name (always 'ubuntu')
+   user = "ubuntu",
+   ## Use private SSH key registered with AWS
+   rshopts = c(
+     "-o", "StrictHostKeyChecking=no",
+     "-o", "IdentitiesOnly=yes",
+     "-i", ssh_private_key_file
+   ),
+   ## Set up .libPaths() for the 'ubuntu' user
+   ## and then install the future package
+   rscript_startup = quote(local({
+     p <- Sys.getenv("R_LIBS_USER")
+     dir.create(p, recursive = TRUE, showWarnings = FALSE)
+     .libPaths(p)
+     install.packages("future")
+   })),
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> ## EXAMPLE: Remote worker running on GCE
> ## Launching worker on Google Cloud Engine (GCE) running a
> ## container based VM (with a #cloud-config specification)
> public_ip <- "1.2.3.4"
> user <- "johnny"
> ssh_private_key_file <- "~/.ssh/google_compute_engine"
> cl <- makeClusterPSOCK(
+   ## Public IP number of GCE instance
+   public_ip,
+   ## User name (== SSH key label (sic!))
+   user = user,
+   ## Use private SSH key registered with GCE
+   rshopts = c(
+     "-o", "StrictHostKeyChecking=no",
+     "-o", "IdentitiesOnly=yes",
+     "-i", ssh_private_key_file
+   ),
+   ## Launch Rscript inside Docker container
+   rscript = c(
+     "docker", "run", "--net=host", "rocker/r-parallel",
+     "Rscript"
+   ),
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> 
> ## ---------------------------------------------------------------
> ## Section 5. Parallel workers running locally inside virtual
> ## machines, Linux containers, etc.
> ## ---------------------------------------------------------------
> ## EXAMPLE: Two workers limited to 100% CPU process and 50 MiB of
> ## memory using Linux CGroups management. The 100% CPU quota limit
> ## constrain each worker to use at most one CPU worth of
> ## processing preventing them from overusing the machine, e.g.
> ## through unintended nested parallelization. The 50 MiB memory
> ## limit is strict - if a worker use more than this, the operating
> ## system will terminate the worker instantly.
> ## See 'man systemd.resource-control' for more details.
> cl <- makeClusterPSOCK(2L,
+   rscript = c("systemd-run", "--user", "--scope",
+     "-p", "CPUQuota=100%",
+     "-p", "MemoryMax=50M", "-p", "MemorySwapMax=50M",
+     "*"
+   ),
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> ## EXAMPLE: Two workers running in Docker on the local machine
> ## Setup of 2 Docker workers running rocker/r-parallel
> ##
> ## The parallel workers are launched as:
> ## R_DEFAULT_PACKAGES=... '/usr/bin/docker' 'run' '--net=host' 'rocker/r-parallel' ...
> ## R_DEFAULT_PACKAGES=... '/usr/bin/docker' 'run' '--net=host' 'rocker/r-parallel' ...
> cl <- makeClusterPSOCK(
+   rep("localhost", times = 2L),
+   ## Launch Rscript inside Docker container
+   rscript = c(
+     "docker", "run", "--net=host", "rocker/r-parallel",
+     "Rscript"
+   ),
+   ## IMPORTANT: Because Docker runs inside a virtual machine (VM) on macOS
+   ## and MS Windows (not Linux), when the R worker tries to connect back to
+   ## the default 'localhost' it will fail, because the main R session is
+   ## not running in the VM, but outside on the host.  To reach the host on
+   ## macOS and MS Windows, make sure to use master = "host.docker.internal"
+   master = if (.Platform$OS.type == "unix") NULL else "host.docker.internal",
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> ## EXAMPLE: Two workers running via Linux container 'rocker/r-parallel' from
> ## DockerHub on the local machine using Apptainer (formerly Singularity)
> ##
> ## The parallel workers are launched as:
> ## R_DEFAULT_PACKAGES=... '/usr/bin/apptainer' 'exec' 'docker://rocker/r-parallel' ...
> ## R_DEFAULT_PACKAGES=... '/usr/bin/apptainer' 'exec' 'docker://rocker/r-parallel' ...
> cl <- makeClusterPSOCK(
+   rep("localhost", times = 2L),
+   ## Launch Rscript inside Linux container
+   rscript = c(
+     "apptainer", "exec", "docker://rocker/r-parallel",
+     "Rscript"
+   ),
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> ## EXAMPLE: One worker running in udocker on the local machine
> ## Setup of a single udocker.py worker running rocker/r-parallel
> ##
> ## The parallel worker is launched as:
> ## R_DEFAULT_PACKAGES=... 'udocker.py' 'run' 'rocker/r-parallel' ...
> cl <- makeClusterPSOCK(
+   "localhost",
+   ## Launch Rscript inside Docker container (using udocker)
+   rscript = c(
+     "udocker.py", "run", "rocker/r-parallel",
+     "Rscript"
+   ), 
+   ## Manually launch parallel workers
+   ## (need double shQuote():s because udocker.py drops one level)
+   rscript_args = c(
+     "-e", shQuote(shQuote("parallel:::.workRSOCK()"))
+   ),
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> ## EXAMPLE: One worker running in Wine for Linux on the local machine
> ## To install R for MS Windows in Wine, do something like:
> ##   winecfg  # In GUI, set 'Windows version' to 'Windows 10'
> ##   wget https://cran.r-project.org/bin/windows/base/R-4.5.0-win.exe
> ##   wine R-4.5.0-win.exe /SILENT
> ## Prevent packages from being installed to R's system library:
> ##   chmod ugo-w "$HOME/.wine/drive_c/Program Files/R/R-4.5.0/library/"
> ## Verify it works:
> ##   wine "C:/Program Files/R/R-4.5.0/bin/x64/Rscript.exe" --version
> ##
> ## The parallel worker is launched as:
> ## R_DEFAULT_PACKAGES=... WINEDEBUG=fixme-all R_LIBS_SITE= R_LIBS_USER= 'wine' ...
> cl <- makeClusterPSOCK(1L,
+   rscript = c(
+     ## Silence Wine warnings
+     "WINEDEBUG=fixme-all",
+     ## Don't pass LC_* and R_LIBS* environments from host to Wine
+     sprintf("%s=", grep("^(LC_|R_LIBS)", names(Sys.getenv()), value = TRUE)),
+     "wine",
+     "C:/Program Files/R/R-4.5.0/bin/x64/Rscript.exe"
+   ),
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> 
> cleanEx()
> nameEx("makeClusterSequential")
> ### * makeClusterSequential
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: makeClusterSequential
> ### Title: Create a "parallel" cluster running sequentially in the current
> ###   session
> ### Aliases: makeClusterSequential SEQ
> 
> ### ** Examples
> 
> ## Don't show: 
> if ((getRversion() >= "4.4.0")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ library(parallel)
+ 
+ cl <- makeClusterSequential()
+ print(cl)
+ 
+ y <- parLapply(cl, X = 1:3, fun = sqrt)
+ str(y)
+ 
+ pid <- Sys.getpid()
+ print(pid)
+ y <- clusterEvalQ(cl, Sys.getpid())
+ str(y)
+ 
+ abc <- 3.14
+ y <- clusterEvalQ(cl, { abc <- 42; abc })
+ str(y)
+ stopifnot(abc == 3.14)
+ ## Don't show: 
+ }) # examplesIf
> library(parallel)
> cl <- makeClusterSequential()
> print(cl)
A ‘sequential_cluster’ cluster with 1 node
> y <- parLapply(cl, X = 1:3, fun = sqrt)
> str(y)
List of 3
 $ : num 1
 $ : num 1.41
 $ : num 1.73
> pid <- Sys.getpid()
> print(pid)
[1] 98943
> y <- clusterEvalQ(cl, Sys.getpid())
> str(y)
List of 1
 $ : int 98943
> abc <- 3.14
> y <- clusterEvalQ(cl, {
+     abc <- 42
+     abc
+ })
> str(y)
List of 1
 $ : num 42
> stopifnot(abc == 3.14)
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:parallel’

> nameEx("serializedSize")
> ### * serializedSize
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: serializedSize
> ### Title: Calculate the size of an R object when it is serialized
> ### Aliases: serializedSize
> 
> ### ** Examples
> 
> object.size(mtcars)
7208 bytes
> serializedSize(mtcars)
[1] 3807
> 
> 
> 
> 
> cleanEx()
> nameEx("supportsMulticore")
> ### * supportsMulticore
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: supportsMulticore
> ### Title: Check If Forked Processing ("multicore") is Supported
> ### Aliases: supportsMulticore
> 
> ### ** Examples
> 
> ## Check whether or not forked processing is supported
> supportsMulticore()
[1] TRUE
> 
> 
> 
> 
> cleanEx()
> nameEx("zzz-parallelly.options")
> ### * zzz-parallelly.options
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: zzz-parallelly.options
> ### Title: Options Used by the 'parallelly' Package
> ### Aliases: zzz-parallelly.options parallelly.options parallelly.debug
> ###   parallelly.availableCores.custom parallelly.availableCores.methods
> ###   parallelly.availableCores.min parallelly.availableCores.fallback
> ###   parallelly.availableCores.omit parallelly.availableCores.max
> ###   parallelly.availableCores.system parallelly.availableWorkers.methods
> ###   parallelly.availableWorkers.custom parallelly.fork.enable
> ###   parallelly.maxWorkers.localhost
> ###   parallelly.supportsMulticore.disableOn
> ###   parallelly.supportsMulticore.unstable
> ###   R_PARALLELLY_AVAILABLECORES_FALLBACK R_PARALLELLY_AVAILABLECORES_OMIT
> ###   R_PARALLELLY_AVAILABLECORES_MAX R_PARALLELLY_AVAILABLECORES_SYSTEM
> ###   R_PARALLELLY_AVAILABLECORES_MIN R_PARALLELLY_FORK_ENABLE
> ###   R_PARALLELLY_SUPPORTSMULTICORE_DISABLEON
> ###   R_PARALLELLY_SUPPORTSMULTICORE_UNSTABLE future.availableCores.custom
> ###   future.availableCores.methods future.availableCores.fallback
> ###   future.availableCores.system future.availableWorkers.methods
> ###   future.availableWorkers.custom future.fork.enable
> ###   future.supportsMulticore.unstable R_FUTURE_AVAILABLECORES_FALLBACK
> ###   R_FUTURE_AVAILABLECORES_SYSTEM R_FUTURE_FORK_ENABLE
> ###   R_FUTURE_SUPPORTSMULTICORE_UNSTABLE
> ###   parallelly.makeNodePSOCK.setup_strategy
> ###   parallelly.makeNodePSOCK.validate
> ###   parallelly.makeNodePSOCK.connectTimeout
> ###   parallelly.makeNodePSOCK.timeout parallelly.makeNodePSOCK.useXDR
> ###   parallelly.makeNodePSOCK.socketOptions
> ###   parallelly.makeNodePSOCK.rshcmd parallelly.makeNodePSOCK.rshopts
> ###   parallelly.makeNodePSOCK.tries parallelly.makeNodePSOCK.tries.delay
> ###   parallelly.makeNodePSOCK.calls
> ###   R_PARALLELLY_MAKENODEPSOCK_SETUP_STRATEGY
> ###   R_PARALLELLY_MAKENODEPSOCK_VALIDATE
> ###   R_PARALLELLY_MAKENODEPSOCK_CONNECTTIMEOUT
> ###   R_PARALLELLY_MAKENODEPSOCK_TIMEOUT R_PARALLELLY_MAKENODEPSOCK_USEXDR
> ###   R_PARALLELLY_MAKENODEPSOCK_SOCKETOPTIONS
> ###   R_PARALLELLY_MAKENODEPSOCK_RSHCMD R_PARALLELLY_MAKENODEPSOCK_RSHOPTS
> ###   R_PARALLELLY_MAKENODEPSOCK_TRIES
> ###   R_PARALLELLY_MAKENODEPSOCK_TRIES_DELAY
> ###   R_PARALLELLY_MAKENODEPSOCK_CALLS
> 
> ### ** Examples
> 
> # Set an R option:
> options(parallelly.availableCores.fallback = 1L)
> 
> 
> 
> 
> 
> ### * <FOOTER>
> ###
> cleanEx()
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  0.356 0.028 1.946 0.226 0.379 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
