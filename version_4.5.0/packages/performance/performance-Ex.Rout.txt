
R version 4.5.0 (2025-04-11) -- "How About a Twenty-Six"
Copyright (C) 2025 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "performance"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('performance')
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("binned_residuals")
> ### * binned_residuals
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: binned_residuals
> ### Title: Binned residuals for binomial logistic regression
> ### Aliases: binned_residuals
> 
> ### ** Examples
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> result <- binned_residuals(model)
> result
Warning: Probably bad model fit. Only about 50% of the residuals are inside the error bounds.
> 
> # look at the data frame
> as.data.frame(result)
                xbar        ybar n       x.lo       x.hi         se     CI_low
conf_int  0.03786483 -0.26905395 5 0.01744776 0.06917366 0.07079661 -0.5299658
conf_int1 0.09514191 -0.44334345 5 0.07087498 0.15160143 0.06530245 -0.7042553
conf_int2 0.25910531  0.03762945 6 0.17159955 0.35374001 1.02017708 -0.3293456
conf_int3 0.47954643 -0.19916717 5 0.38363314 0.54063600 1.16107852 -0.5994783
conf_int4 0.71108931  0.81563262 5 0.57299903 0.89141359 0.19814385  0.5547207
conf_int5 0.97119262 -0.23399465 6 0.91147360 0.99815623 0.77513642 -0.5525066
               CI_high group
conf_int  -0.008142076    no
conf_int1 -0.182431572    no
conf_int2  0.404604465   yes
conf_int3  0.201143953   yes
conf_int4  1.076544495    no
conf_int5  0.084517267   yes
> 
> ## Don't show: 
> if (insight::check_if_installed("see", minimum_version = "0.9.1", quietly = TRUE)) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ ## Don't show: 
+ }) # examplesIf
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_autocorrelation")
> ### * check_autocorrelation
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_autocorrelation
> ### Title: Check model for independence of residuals.
> ### Aliases: check_autocorrelation check_autocorrelation.default
> 
> ### ** Examples
> 
> m <- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
> check_autocorrelation(m)
OK: Residuals appear to be independent and not autocorrelated (p = 0.324).> 
> 
> 
> cleanEx()
> nameEx("check_clusterstructure")
> ### * check_clusterstructure
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_clusterstructure
> ### Title: Check suitability of data for clustering
> ### Aliases: check_clusterstructure
> 
> ### ** Examples
> 
> 
> 
> 
> cleanEx()
> nameEx("check_collinearity")
> ### * check_collinearity
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_collinearity
> ### Title: Check for multicollinearity of model terms
> ### Aliases: check_collinearity multicollinearity
> ###   check_collinearity.default check_collinearity.glmmTMB
> ###   check_concurvity
> 
> ### ** Examples
> 
> m <- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
> check_collinearity(m)
# Check for Multicollinearity

Low Correlation

 Term  VIF    VIF 95% CI adj. VIF Tolerance Tolerance 95% CI
 gear 1.53 [1.19,  2.51]     1.24      0.65     [0.40, 0.84]

Moderate Correlation

 Term  VIF    VIF 95% CI adj. VIF Tolerance Tolerance 95% CI
   wt 5.05 [3.21,  8.41]     2.25      0.20     [0.12, 0.31]
  cyl 5.41 [3.42,  9.04]     2.33      0.18     [0.11, 0.29]
 disp 9.97 [6.08, 16.85]     3.16      0.10     [0.06, 0.16]
> 
> ## Don't show: 
> if (insight::check_if_installed("see", minimum_version = "0.9.1", quietly = TRUE)) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ # plot results
+ x <- check_collinearity(m)
+ plot(x)
+ ## Don't show: 
+ }) # examplesIf
> x <- check_collinearity(m)
> plot(x)
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_convergence")
> ### * check_convergence
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_convergence
> ### Title: Convergence test for mixed effects models
> ### Aliases: check_convergence
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("lme4") && require("glmmTMB")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ data(cbpp, package = "lme4")
+ set.seed(1)
+ cbpp$x <- rnorm(nrow(cbpp))
+ cbpp$x2 <- runif(nrow(cbpp))
+ 
+ model <- lme4::glmer(
+   cbind(incidence, size - incidence) ~ period + x + x2 + (1 + x | herd),
+   data = cbpp,
+   family = binomial()
+ )
+ 
+ check_convergence(model)
+ 
+ ## Don't show: 
+ }) # examplesIf
Loading required package: lme4
Loading required package: Matrix
Loading required package: glmmTMB
> data(cbpp, package = "lme4")
> set.seed(1)
> cbpp$x <- rnorm(nrow(cbpp))
> cbpp$x2 <- runif(nrow(cbpp))
> model <- lme4::glmer(cbind(incidence, size - incidence) ~ period + x + 
+     x2 + (1 + x | herd), data = cbpp, family = binomial())
> check_convergence(model)
[1] TRUE
attr(,"gradient")
[1] 0.0002803063
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:glmmTMB’, ‘package:lme4’, ‘package:Matrix’

> nameEx("check_dag")
> ### * check_dag
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_dag
> ### Title: Check correct model adjustment for identifying causal effects
> ### Aliases: check_dag as.dag
> 
> ### ** Examples
> 
> ## Don't show: 
> if (all(insight::check_if_installed(c("ggdag", "dagitty", "see"), quietly = TRUE))) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ # no adjustment needed
+ check_dag(
+   y ~ x + b,
+   outcome = "y",
+   exposure = "x"
+ )
+ 
+ # incorrect adjustment
+ dag <- check_dag(
+   y ~ x + b + c,
+   x ~ b,
+   outcome = "y",
+   exposure = "x"
+ )
+ dag
+ plot(dag)
+ 
+ # After adjusting for `b`, the model is correctly specified
+ dag <- check_dag(
+   y ~ x + b + c,
+   x ~ b,
+   outcome = "y",
+   exposure = "x",
+   adjusted = "b"
+ )
+ dag
+ 
+ # using formula interface for arguments "outcome", "exposure" and "adjusted"
+ check_dag(
+   y ~ x + b + c,
+   x ~ b,
+   outcome = ~y,
+   exposure = ~x,
+   adjusted = ~ b + c
+ )
+ 
+ # if not provided, "outcome" is taken from first formula, same for "exposure"
+ # thus, we can simplify the above expression to
+ check_dag(
+   y ~ x + b + c,
+   x ~ b,
+   adjusted = ~ b + c
+ )
+ 
+ # use specific layout for the DAG
+ dag <- check_dag(
+   score ~ exp + b + c,
+   exp ~ b,
+   outcome = "score",
+   exposure = "exp",
+   coords = list(
+     # x-coordinates for all nodes
+     x = c(score = 5, exp = 4, b = 3, c = 3),
+     # y-coordinates for all nodes
+     y = c(score = 3, exp = 3, b = 2, c = 4)
+   )
+ )
+ plot(dag)
+ 
+ # alternative way of providing the coordinates
+ dag <- check_dag(
+   score ~ exp + b + c,
+   exp ~ b,
+   outcome = "score",
+   exposure = "exp",
+   coords = list(
+     # x/y coordinates for each node
+     score = c(5, 3),
+     exp = c(4, 3),
+     b = c(3, 2),
+     c = c(3, 4)
+   )
+ )
+ plot(dag)
+ 
+ # Objects returned by `check_dag()` can be used with "ggdag" or "dagitty"
+ ggdag::ggdag_status(dag)
+ 
+ # Using a model object to extract information about outcome,
+ # exposure and adjusted variables
+ data(mtcars)
+ m <- lm(mpg ~ wt + gear + disp + cyl, data = mtcars)
+ dag <- check_dag(
+   m,
+   wt ~ disp + cyl,
+   wt ~ am
+ )
+ dag
+ plot(dag)
+ ## Don't show: 
+ }) # examplesIf
> check_dag(y ~ x + b, outcome = "y", exposure = "x")
# Check for correct adjustment sets
- Outcome: y
- Exposure: x

Identification of direct and total effects

Model is correctly specified.
No adjustment needed to estimate the direct and total effect of `x` on `y`.

> dag <- check_dag(y ~ x + b + c, x ~ b, outcome = "y", exposure = "x")
> dag
# Check for correct adjustment sets
- Outcome: y
- Exposure: x

Identification of direct and total effects

Incorrectly adjusted!
To estimate the direct and total effect, at least adjust for `b`. Currently, the model does not adjust for any variables.

> plot(dag)
> dag <- check_dag(y ~ x + b + c, x ~ b, outcome = "y", exposure = "x", 
+     adjusted = "b")
> dag
# Check for correct adjustment sets
- Outcome: y
- Exposure: x
- Adjustment: b

Identification of direct and total effects

Model is correctly specified.
All minimal sufficient adjustments to estimate the direct and total effect were done.

> check_dag(y ~ x + b + c, x ~ b, outcome = ~y, exposure = ~x, adjusted = ~b + 
+     c)
# Check for correct adjustment sets
- Outcome: y
- Exposure: x
- Adjustments: b and c

Identification of direct and total effects

Model is correctly specified.
All minimal sufficient adjustments to estimate the direct and total effect were done.

> check_dag(y ~ x + b + c, x ~ b, adjusted = ~b + c)
# Check for correct adjustment sets
- Outcome: y
- Exposure: x
- Adjustments: b and c

Identification of direct and total effects

Model is correctly specified.
All minimal sufficient adjustments to estimate the direct and total effect were done.

> dag <- check_dag(score ~ exp + b + c, exp ~ b, outcome = "score", exposure = "exp", 
+     coords = list(x = c(score = 5, exp = 4, b = 3, c = 3), y = c(score = 3, exp = 3, 
+         b = 2, c = 4)))
> plot(dag)
> dag <- check_dag(score ~ exp + b + c, exp ~ b, outcome = "score", exposure = "exp", 
+     coords = list(score = c(5, 3), exp = c(4, 3), b = c(3, 2), c = c(3, 4)))
> plot(dag)
> ggdag::ggdag_status(dag)
> data(mtcars)
> m <- lm(mpg ~ wt + gear + disp + cyl, data = mtcars)
> dag <- check_dag(m, wt ~ disp + cyl, wt ~ am)
> dag
# Check for correct adjustment sets
- Outcome: mpg
- Exposure: wt
- Adjustments: cyl, disp and gear

Identification of direct and total effects

Model is correctly specified.
All minimal sufficient adjustments to estimate the direct and total effect were done.

> plot(dag)
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_distribution")
> ### * check_distribution
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_distribution
> ### Title: Classify the distribution of a model-family using machine
> ###   learning
> ### Aliases: check_distribution
> 
> ### ** Examples
> 
> ## Don't show: 
> if (all(insight::check_if_installed(c("lme4", "parameters", "randomForest"), quietly = TRUE))) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ data(sleepstudy, package = "lme4")
+ model <<- lme4::lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
+ check_distribution(model)
+ ## Don't show: 
+ }) # examplesIf
> data(sleepstudy, package = "lme4")
> model <<- lme4::lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
> check_distribution(model)
# Distribution of Model Family

Predicted Distribution of Residuals

               Distribution Probability
                     cauchy         91%
                      gamma          6%
 neg. binomial (zero-infl.)          3%

Predicted Distribution of Response

 Distribution Probability
    lognormal         66%
        gamma         34%
> ## End(Don't show)
> ## Don't show: 
> if (all(insight::check_if_installed(c("see", "patchwork", "randomForest"), quietly = TRUE))) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ plot(check_distribution(model))
+ ## Don't show: 
+ }) # examplesIf
> plot(check_distribution(model))
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_factorstructure")
> ### * check_factorstructure
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_factorstructure
> ### Title: Check suitability of data for Factor Analysis (FA) with
> ###   Bartlett's Test of Sphericity and KMO
> ### Aliases: check_factorstructure check_kmo check_sphericity_bartlett
> 
> ### ** Examples
> 
> library(performance)
> 
> check_factorstructure(mtcars)
# Is the data suitable for Factor Analysis?


  - Sphericity: Bartlett's test of sphericity suggests that there is sufficient significant correlation in the data for factor analysis (Chisq(55) = 408.01, p < .001).
  - KMO: The Kaiser, Meyer, Olkin (KMO) overall measure of sampling adequacy suggests that data seems appropriate for factor analysis (KMO = 0.83). The individual KMO scores are: mpg (0.93), cyl (0.90), disp (0.76), hp (0.84), drat (0.95), wt (0.74), qsec (0.74), vs (0.91), am (0.88), gear (0.85), carb (0.62).> 
> # One can also pass a correlation matrix
> r <- cor(mtcars)
> check_factorstructure(r, n = nrow(mtcars))
# Is the data suitable for Factor Analysis?


  - Sphericity: Bartlett's test of sphericity suggests that there is sufficient significant correlation in the data for factor analysis (Chisq(55) = 408.01, p < .001).
  - KMO: The Kaiser, Meyer, Olkin (KMO) overall measure of sampling adequacy suggests that data seems appropriate for factor analysis (KMO = 0.83). The individual KMO scores are: mpg (0.93), cyl (0.90), disp (0.76), hp (0.84), drat (0.95), wt (0.74), qsec (0.74), vs (0.91), am (0.88), gear (0.85), carb (0.62).> 
> 
> 
> 
> cleanEx()
> nameEx("check_group_variation")
> ### * check_group_variation
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_group_variation
> ### Title: Check variables for within- and/or between-group variation
> ### Aliases: check_group_variation check_group_variation.default
> ###   check_group_variation.data.frame summary.check_group_variation
> 
> ### ** Examples
> 
> data(npk)
> check_group_variation(npk, by = "block")
Check block variation

Variable | Variation |  Design
------------------------------
N        |    within | crossed
P        |    within | crossed
K        |    within | crossed
yield    |      both |        
> 
> data(iris)
> check_group_variation(iris, by = "Species")
Check Species variation

Variable     | Variation | Design
---------------------------------
Sepal.Length |      both |       
Sepal.Width  |      both |       
Petal.Length |      both |       
Petal.Width  |      both |       
> 
> data(ChickWeight)
> check_group_variation(ChickWeight, by = "Chick")
Check Chick variation

Variable | Variation | Design
-----------------------------
weight   |      both |       
Time     |      both |       
Diet     |   between |       
> 
> # A subset of mlmRev::egsingle
> egsingle <- data.frame(
+   schoolid = factor(rep(c("2020", "2820"), times = c(18, 6))),
+   lowinc = rep(c(TRUE, FALSE), times = c(18, 6)),
+   childid = factor(rep(
+     c("288643371", "292020281", "292020361", "295341521"),
+     each = 6
+   )),
+   female = rep(c(TRUE, FALSE), each = 12),
+   year = rep(1:6, times = 4),
+   math = c(
+     -3.068, -1.13, -0.921, 0.463, 0.021, 2.035,
+     -2.732, -2.097, -0.988, 0.227, 0.403, 1.623,
+     -2.732, -1.898, -0.921, 0.587, 1.578, 2.3,
+     -2.288, -2.162, -1.631, -1.555, -0.725, 0.097
+   )
+ )
> 
> result <- check_group_variation(
+   egsingle,
+   by = c("schoolid", "childid"),
+   include_by = TRUE
+ )
> result
Check schoolid variation

Variable | Variation | Design
-----------------------------
childid  |      both | nested
lowinc   |   between | nested
female   |      both |       
year     |    within |       
math     |      both |       

Check childid variation

Variable | Variation | Design
-----------------------------
schoolid |   between |       
lowinc   |   between |       
female   |   between |       
year     |    within |       
math     |      both |       
> 
> summary(result)
Possible heterogeneity bias due to following predictors:
- childid: math
  - schoolid: childid, female, math
> 
> ## Don't show: 
> if (insight::check_if_installed("lme4", quietly = TRUE)) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ 
+ data(sleepstudy, package = "lme4")
+ check_group_variation(sleepstudy, select = "Days", by = "Subject")
+ 
+ # Or
+ mod <- lme4::lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy)
+ result <- check_group_variation(mod)
+ result
+ 
+ summary(result)
+ ## Don't show: 
+ }) # examplesIf
> data(sleepstudy, package = "lme4")
> check_group_variation(sleepstudy, select = "Days", by = "Subject")
Check Subject variation

Variable | Variation | Design
-----------------------------
Days     |    within |       
> mod <- lme4::lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy)
> result <- check_group_variation(mod)
> result
Check Subject variation

Variable | Variation | Design
-----------------------------
Days     |    within |       
> summary(result)
No predictor found that could cause heterogeneity bias.
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_heterogeneity_bias")
> ### * check_heterogeneity_bias
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_heterogeneity_bias
> ### Title: Check model predictor for heterogeneity bias _(Deprecated)_
> ### Aliases: check_heterogeneity_bias
> 
> ### ** Examples
> 
> data(iris)
> iris$ID <- sample(1:4, nrow(iris), replace = TRUE) # fake-ID
> check_heterogeneity_bias(iris, select = c("Sepal.Length", "Petal.Length"), by = "ID")
`check_heterogeneity_bias()` is deprecated. Please use
  `check_group_variation()` instead.
Possible heterogeneity bias due to following predictors: Sepal.Length, Petal.Length
> 
> 
> 
> cleanEx()
> nameEx("check_heteroscedasticity")
> ### * check_heteroscedasticity
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_heteroscedasticity
> ### Title: Check model for (non-)constant error variance
> ### Aliases: check_heteroscedasticity check_heteroskedasticity
> 
> ### ** Examples
> 
> m <<- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
> check_heteroscedasticity(m)
Warning: Heteroscedasticity (non-constant error variance) detected (p = 0.042).
> 
> # plot results
> ## Don't show: 
> if (insight::check_if_installed("see", minimum_version = "0.9.1", quietly = TRUE)) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ x <- check_heteroscedasticity(m)
+ plot(x)
+ ## Don't show: 
+ }) # examplesIf
> x <- check_heteroscedasticity(m)
> plot(x)
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_homogeneity")
> ### * check_homogeneity
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_homogeneity
> ### Title: Check model for homogeneity of variances
> ### Aliases: check_homogeneity check_homogeneity.afex_aov
> 
> ### ** Examples
> 
> model <<- lm(len ~ supp + dose, data = ToothGrowth)
> check_homogeneity(model)
OK: There is not clear evidence for different variances across groups (Bartlett Test, p = 0.226).
> 
> # plot results
> ## Don't show: 
> if (insight::check_if_installed("see", minimum_version = "0.9.1", quietly = TRUE)) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ result <- check_homogeneity(model)
+ plot(result)
+ ## Don't show: 
+ }) # examplesIf
> result <- check_homogeneity(model)
> plot(result)
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_itemscale")
> ### * check_itemscale
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_itemscale
> ### Title: Describe Properties of Item Scales
> ### Aliases: check_itemscale
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("parameters") && require("psych")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ # data generation from '?prcomp', slightly modified
+ C <- chol(S <- toeplitz(0.9^(0:15)))
+ set.seed(17)
+ X <- matrix(rnorm(1600), 100, 16)
+ Z <- X %*% C
+ 
+ pca <- parameters::principal_components(
+   as.data.frame(Z),
+   rotation = "varimax",
+   n = 3
+ )
+ pca
+ check_itemscale(pca)
+ 
+ # as data frame
+ check_itemscale(
+   as.data.frame(Z),
+   factor_index = parameters::closest_component(pca)
+ )
+ ## Don't show: 
+ }) # examplesIf
Loading required package: parameters
Loading required package: psych
> C <- chol(S <- toeplitz(0.9^(0:15)))
> set.seed(17)
> X <- matrix(rnorm(1600), 100, 16)
> Z <- X %*% C
> pca <- parameters::principal_components(as.data.frame(Z), rotation = "varimax", 
+     n = 3)
> pca
# Rotated loadings from Principal Component Analysis (varimax-rotation)

Variable |  RC3 |  RC1 |  RC2 | Complexity | Uniqueness |  MSA
--------------------------------------------------------------
V1       | 0.85 | 0.17 | 0.20 |       1.20 |       0.21 | 0.90
V2       | 0.89 | 0.25 | 0.22 |       1.28 |       0.11 | 0.90
V3       | 0.91 | 0.26 | 0.17 |       1.23 |       0.07 | 0.89
V4       | 0.88 | 0.33 | 0.13 |       1.33 |       0.10 | 0.91
V5       | 0.82 | 0.41 | 0.14 |       1.55 |       0.14 | 0.94
V6       | 0.68 | 0.59 | 0.18 |       2.12 |       0.15 | 0.92
V7       | 0.57 | 0.74 | 0.20 |       2.04 |       0.09 | 0.93
V8       | 0.44 | 0.81 | 0.20 |       1.67 |       0.11 | 0.95
V9       | 0.33 | 0.84 | 0.32 |       1.61 |       0.09 | 0.93
V10      | 0.29 | 0.85 | 0.33 |       1.55 |       0.09 | 0.92
V11      | 0.30 | 0.79 | 0.42 |       1.86 |       0.11 | 0.92
V12      | 0.27 | 0.68 | 0.57 |       2.28 |       0.15 | 0.90
V13      | 0.20 | 0.55 | 0.71 |       2.06 |       0.15 | 0.90
V14      | 0.21 | 0.36 | 0.86 |       1.48 |       0.09 | 0.91
V15      | 0.20 | 0.23 | 0.91 |       1.23 |       0.08 | 0.88
V16      | 0.11 | 0.15 | 0.90 |       1.09 |       0.15 | 0.87

The 3 principal components (varimax rotation) accounted for 88.19% of the total variance of the original data (RC3 = 32.81%, RC1 = 31.24%, RC2 = 24.14%).
> check_itemscale(pca)
# Description of (Sub-)ScalesComponent 1

Item | Missings |  Mean |   SD | Skewness | Difficulty | Discrimination | alpha if deleted
------------------------------------------------------------------------------------------
V1   |        0 | -0.02 | 1.06 |    -0.49 |      -0.01 |           0.80 |             0.96
V2   |        0 | -0.05 | 1.05 |    -0.29 |      -0.02 |           0.90 |             0.95
V3   |        0 |  0.00 | 1.10 |    -0.77 |       0.00 |           0.94 |             0.95
V4   |        0 |  0.00 | 1.10 |    -0.82 |       0.00 |           0.92 |             0.95
V5   |        0 | -0.07 | 1.09 |    -0.29 |      -0.02 |           0.90 |             0.95
V6   |        0 | -0.04 | 1.13 |    -0.27 |      -0.01 |           0.83 |             0.96

Mean inter-item-correlation = 0.813  Cronbach's alpha = 0.963
Component 2

Item | Missings |  Mean |   SD | Skewness | Difficulty | Discrimination | alpha if deleted
------------------------------------------------------------------------------------------
V7   |        0 | -0.01 | 1.07 |     0.01 |       0.00 |           0.87 |             0.97
V8   |        0 |  0.02 | 0.96 |     0.23 |       0.01 |           0.89 |             0.96
V9   |        0 |  0.04 | 0.98 |     0.37 |       0.01 |           0.93 |             0.96
V10  |        0 |  0.08 | 1.00 |     0.18 |       0.02 |           0.93 |             0.96
V11  |        0 |  0.02 | 1.03 |     0.18 |       0.01 |           0.92 |             0.96
V12  |        0 |  0.00 | 1.04 |     0.27 |       0.00 |           0.84 |             0.97

Mean inter-item-correlation = 0.840  Cronbach's alpha = 0.969
Component 3

Item | Missings |  Mean |   SD | Skewness | Difficulty | Discrimination | alpha if deleted
------------------------------------------------------------------------------------------
V13  |        0 |  0.04 | 0.95 |     0.10 |       0.01 |           0.81 |             0.95
V14  |        0 | -0.02 | 0.96 |     0.24 |      -0.01 |           0.93 |             0.91
V15  |        0 | -0.03 | 0.94 |     0.41 |      -0.01 |           0.92 |             0.91
V16  |        0 |  0.03 | 0.96 |     0.28 |       0.01 |           0.82 |             0.94

Mean inter-item-correlation = 0.811  Cronbach's alpha = 0.945> check_itemscale(as.data.frame(Z), factor_index = parameters::closest_component(pca))
# Description of (Sub-)ScalesComponent 1

Item | Missings |  Mean |   SD | Skewness | Difficulty | Discrimination | alpha if deleted
------------------------------------------------------------------------------------------
V1   |        0 | -0.02 | 1.06 |    -0.49 |      -0.01 |           0.80 |             0.96
V2   |        0 | -0.05 | 1.05 |    -0.29 |      -0.02 |           0.90 |             0.95
V3   |        0 |  0.00 | 1.10 |    -0.77 |       0.00 |           0.94 |             0.95
V4   |        0 |  0.00 | 1.10 |    -0.82 |       0.00 |           0.92 |             0.95
V5   |        0 | -0.07 | 1.09 |    -0.29 |      -0.02 |           0.90 |             0.95
V6   |        0 | -0.04 | 1.13 |    -0.27 |      -0.01 |           0.83 |             0.96

Mean inter-item-correlation = 0.813  Cronbach's alpha = 0.963
Component 2

Item | Missings |  Mean |   SD | Skewness | Difficulty | Discrimination | alpha if deleted
------------------------------------------------------------------------------------------
V7   |        0 | -0.01 | 1.07 |     0.01 |       0.00 |           0.87 |             0.97
V8   |        0 |  0.02 | 0.96 |     0.23 |       0.01 |           0.89 |             0.96
V9   |        0 |  0.04 | 0.98 |     0.37 |       0.01 |           0.93 |             0.96
V10  |        0 |  0.08 | 1.00 |     0.18 |       0.02 |           0.93 |             0.96
V11  |        0 |  0.02 | 1.03 |     0.18 |       0.01 |           0.92 |             0.96
V12  |        0 |  0.00 | 1.04 |     0.27 |       0.00 |           0.84 |             0.97

Mean inter-item-correlation = 0.840  Cronbach's alpha = 0.969
Component 3

Item | Missings |  Mean |   SD | Skewness | Difficulty | Discrimination | alpha if deleted
------------------------------------------------------------------------------------------
V13  |        0 |  0.04 | 0.95 |     0.10 |       0.01 |           0.81 |             0.95
V14  |        0 | -0.02 | 0.96 |     0.24 |      -0.01 |           0.93 |             0.91
V15  |        0 | -0.03 | 0.94 |     0.41 |      -0.01 |           0.92 |             0.91
V16  |        0 |  0.03 | 0.96 |     0.28 |       0.01 |           0.82 |             0.94

Mean inter-item-correlation = 0.811  Cronbach's alpha = 0.945> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:psych’, ‘package:parameters’

> nameEx("check_model")
> ### * check_model
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_model
> ### Title: Visual check of model assumptions
> ### Aliases: check_model check_model.default
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("lme4")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: lme4
Loading required package: Matrix
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:lme4’, ‘package:Matrix’

> nameEx("check_multimodal")
> ### * check_multimodal
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_multimodal
> ### Title: Check if a distribution is unimodal or multimodal
> ### Aliases: check_multimodal
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("multimode") && require("mclust")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: multimode
Loading required package: mclust
Package 'mclust' version 6.1.1
Type 'citation("mclust")' for citing this R package in publications.
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:mclust’, ‘package:multimode’

> nameEx("check_normality")
> ### * check_normality
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_normality
> ### Title: Check model for (non-)normality of residuals.
> ### Aliases: check_normality check_normality.merMod
> 
> ### ** Examples
> 
> ## Don't show: 
> if (insight::check_if_installed("see", minimum_version = "0.9.1", quietly = TRUE)) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ m <<- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
+ check_normality(m)
+ 
+ # plot results
+ x <- check_normality(m)
+ plot(x)
+ 
+ ## Don't show: 
+ }) # examplesIf
> m <<- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
> check_normality(m)
OK: residuals appear as normally distributed (p = 0.230).
> x <- check_normality(m)
> plot(x)
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_outliers")
> ### * check_outliers
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_outliers
> ### Title: Outliers detection (check for influential observations)
> ### Aliases: check_outliers check_outliers.default check_outliers.numeric
> ###   check_outliers.data.frame check_outliers.performance_simres
> 
> ### ** Examples
> 
> data <- mtcars # Size nrow(data) = 32
> 
> # For single variables ------------------------------------------------------
> # Find all observations beyond +/- 2 SD
> outliers_list <- check_outliers(data$mpg, method = "zscore", threshold = 2)
> outliers_list # Show the row index of the outliers
2 outliers detected: cases 18, 20.
- Based on the following method and threshold: zscore (2).
- For variable: data$mpg.

-----------------------------------------------------------------------------
Outliers per variable (zscore): 

$`data$mpg`
   Row Distance_Zscore
18  18        2.042389
20  20        2.291272

> as.numeric(outliers_list) # The object is a binary vector...
 [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0
> filtered_data <- data[!outliers_list, ] # And can be used to filter a data frame
> nrow(filtered_data) # New size, 30 (2 outliers removed)
[1] 30
> 
> 
> # For dataframes ------------------------------------------------------
> check_outliers(data, threshold = 2) # It works the same way on data frames
32 outliers detected: cases 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,
  14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,
  32.
- Based on the following method and threshold: mahalanobis (2).
- For variables: mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb.> 
> # You can also use multiple methods at once
> outliers_list <- check_outliers(data, method = c(
+   "mahalanobis",
+   "iqr",
+   "zscore"
+ ))
> outliers_list
OK: No outliers detected.
- Based on the following methods and thresholds: mahalanobis (3.291), iqr (2), zscore (31.264).
- For variables: mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb

> 
> # Using `as.data.frame()`, we can access more details!
> outliers_info <- as.data.frame(outliers_list)
> head(outliers_info)
  Row Distance_Zscore Outlier_Zscore Distance_IQR Outlier_IQR
1   1        1.189901              0    0.4208483           0
2   2        1.189901              0    0.2941176           0
3   3        1.224858              0    0.5882353           0
4   4        1.122152              0    0.5882353           0
5   5        1.043081              0    0.3915954           0
6   6        1.564608              0    0.6809025           0
  Distance_Mahalanobis Outlier_Mahalanobis Outlier
1             8.946673                   0       0
2             8.287933                   0       0
3             8.937150                   0       0
4             6.096726                   0       0
5             5.429061                   0       0
6             8.877558                   0       0
> outliers_info$Outlier # Including the probability of being an outlier
 [1] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
 [8] 0.0000000 0.3333333 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
[15] 0.0000000 0.3333333 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
[22] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
[29] 0.0000000 0.0000000 0.3333333 0.0000000
> 
> # And we can be more stringent in our outliers removal process
> filtered_data <- data[outliers_info$Outlier < 0.1, ]
> 
> # We can run the function stratified by groups using `{datawizard}` package:
> group_iris <- datawizard::data_group(iris, "Species")
> check_outliers(group_iris)
OK: No outliers detected.
- Based on the following method and threshold: mahalanobis (20).
- For variables: Sepal.Length, Sepal.Width, Petal.Length, Petal.Width

> # nolint start
> ## Don't show: 
> if (all(insight::check_if_installed(c("bigutilsr", "MASS", "ICSOutlier", "ICS", "dbscan", "loo", "see"), quietly = TRUE))) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ # nolint end
+ ## Don't show: 
+ }) # examplesIf
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_overdispersion")
> ### * check_overdispersion
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_overdispersion
> ### Title: Check overdispersion (and underdispersion) of GL(M)M's
> ### Aliases: check_overdispersion check_overdispersion.performance_simres
> 
> ### ** Examples
> 
> ## Don't show: 
> if (getRversion() >= "4.0.0" && require("glmmTMB")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ data(Salamanders, package = "glmmTMB")
+ m <- glm(count ~ spp + mined, family = poisson, data = Salamanders)
+ check_overdispersion(m)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: glmmTMB
> data(Salamanders, package = "glmmTMB")
> m <- glm(count ~ spp + mined, family = poisson, data = Salamanders)
> check_overdispersion(m)
# Overdispersion test

       dispersion ratio =    2.946
  Pearson's Chi-Squared = 1873.710
                p-value =  < 0.001

Overdispersion detected.
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:glmmTMB’

> nameEx("check_predictions")
> ### * check_predictions
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_predictions
> ### Title: Posterior predictive checks
> ### Aliases: check_predictions check_predictions.default
> 
> ### ** Examples
> 
> ## Don't show: 
> if (insight::check_if_installed("see", minimum_version = "0.9.1", quietly = TRUE)) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ # linear model
+ model <- lm(mpg ~ disp, data = mtcars)
+ check_predictions(model)
+ 
+ # discrete/integer outcome
+ set.seed(99)
+ d <- iris
+ d$skewed <- rpois(150, 1)
+ model <- glm(
+   skewed ~ Species + Petal.Length + Petal.Width,
+   family = poisson(),
+   data = d
+ )
+ check_predictions(model, type = "discrete_both")
+ ## Don't show: 
+ }) # examplesIf
> model <- lm(mpg ~ disp, data = mtcars)
> check_predictions(model)
> set.seed(99)
> d <- iris
> d$skewed <- rpois(150, 1)
> model <- glm(skewed ~ Species + Petal.Length + Petal.Width, family = poisson(), 
+     data = d)
> check_predictions(model, type = "discrete_both")
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_residuals")
> ### * check_residuals
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_residuals
> ### Title: Check distribution of simulated quantile residuals
> ### Aliases: check_residuals check_residuals.default
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("DHARMa")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ dat <- DHARMa::createData(sampleSize = 100, overdispersion = 0.5, family = poisson())
+ m <- glm(observedResponse ~ Environment1, family = poisson(), data = dat)
+ res <- simulate_residuals(m)
+ check_residuals(res)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: DHARMa
This is DHARMa 0.4.7. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')
> dat <- DHARMa::createData(sampleSize = 100, overdispersion = 0.5, family = poisson())
> m <- glm(observedResponse ~ Environment1, family = poisson(), data = dat)
> res <- simulate_residuals(m)
> check_residuals(res)
Warning: Non-uniformity of simulated residuals detected (p = 0.006).
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:DHARMa’

> nameEx("check_singularity")
> ### * check_singularity
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_singularity
> ### Title: Check mixed models for boundary fits
> ### Aliases: check_singularity check_singularity.glmmTMB
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("lme4") && require("glmmTMB")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ data(sleepstudy, package = "lme4")
+ set.seed(123)
+ sleepstudy$mygrp <- sample(1:5, size = 180, replace = TRUE)
+ sleepstudy$mysubgrp <- NA
+ for (i in 1:5) {
+   filter_group <- sleepstudy$mygrp == i
+   sleepstudy$mysubgrp[filter_group] <-
+     sample(1:30, size = sum(filter_group), replace = TRUE)
+ }
+ 
+ model <- lme4::lmer(
+   Reaction ~ Days + (1 | mygrp / mysubgrp) + (1 | Subject),
+   data = sleepstudy
+ )
+ # any singular fits?
+ check_singularity(model)
+ # singular fit for which particular random effects terms?
+ check_singularity(model, check = "terms")
+ 
+ ## Not run: 
+ ##D # Fixing singularity issues using priors in glmmTMB
+ ##D # Example taken from `vignette("priors", package = "glmmTMB")`
+ ##D dat <- readRDS(system.file(
+ ##D   "vignette_data",
+ ##D   "gophertortoise.rds",
+ ##D   package = "glmmTMB"
+ ##D ))
+ ##D model <- glmmTMB::glmmTMB(
+ ##D   shells ~ prev + offset(log(Area)) + factor(year) + (1 | Site),
+ ##D   family = poisson,
+ ##D   data = dat
+ ##D )
+ ##D # singular fit
+ ##D check_singularity(model)
+ ##D 
+ ##D # impose Gamma prior on random effects parameters
+ ##D prior <- data.frame(
+ ##D   prior = "gamma(1, 2.5)", # mean can be 1, but even 1e8
+ ##D   class = "ranef" # for random effects
+ ##D )
+ ##D model_with_priors <- update(model, priors = prior)
+ ##D # no singular fit
+ ##D check_singularity(model_with_priors)
+ ## End(Not run)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: lme4
Loading required package: Matrix
Loading required package: glmmTMB
> data(sleepstudy, package = "lme4")
> set.seed(123)
> sleepstudy$mygrp <- sample(1:5, size = 180, replace = TRUE)
> sleepstudy$mysubgrp <- NA
> for (i in 1:5) {
+     filter_group <- sleepstudy$mygrp == i
+     sleepstudy$mysubgrp[filter_group] <- sample(1:30, size = sum(filter_group), replace = TRUE)
+ }
> model <- lme4::lmer(Reaction ~ Days + (1 | mygrp/mysubgrp) + (1 | Subject), 
+     data = sleepstudy)
boundary (singular) fit: see help('isSingular')
> check_singularity(model)
[1] TRUE
> check_singularity(model, check = "terms")
mysubgrp:mygrp        Subject          mygrp 
          TRUE          FALSE          FALSE 
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:glmmTMB’, ‘package:lme4’, ‘package:Matrix’

> nameEx("check_sphericity")
> ### * check_sphericity
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_sphericity
> ### Title: Check model for violation of sphericity
> ### Aliases: check_sphericity
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("car") && require("carData")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ data(Soils, package = "carData")
+ soils.mod <- lm(
+   cbind(pH, N, Dens, P, Ca, Mg, K, Na, Conduc) ~ Block + Contour * Depth,
+   data = Soils
+ )
+ 
+ check_sphericity(Manova(soils.mod))
+ ## Don't show: 
+ }) # examplesIf
Loading required package: car
Loading required package: carData
> data(Soils, package = "carData")
> soils.mod <- lm(cbind(pH, N, Dens, P, Ca, Mg, K, Na, Conduc) ~ Block + 
+     Contour * Depth, data = Soils)
> check_sphericity(Manova(soils.mod))
OK: Data seems to be spherical (p > .999).
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:car’, ‘package:carData’

> nameEx("check_symmetry")
> ### * check_symmetry
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_symmetry
> ### Title: Check distribution symmetry
> ### Aliases: check_symmetry
> 
> ### ** Examples
> 
> V <- suppressWarnings(wilcox.test(mtcars$mpg))
> check_symmetry(V)
OK: Data appears symmetrical (p = 0.119).
> 
> 
> 
> 
> cleanEx()
> nameEx("check_zeroinflation")
> ### * check_zeroinflation
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_zeroinflation
> ### Title: Check for zero-inflation in count models
> ### Aliases: check_zeroinflation check_zeroinflation.default
> ###   check_zeroinflation.performance_simres
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("glmmTMB") && require("DHARMa")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ data(Salamanders, package = "glmmTMB")
+ m <- glm(count ~ spp + mined, family = poisson, data = Salamanders)
+ check_zeroinflation(m)
+ 
+ # for models with zero-inflation component, it's better to carry out
+ # the check for zero-inflation using simulated residuals
+ m <- glmmTMB::glmmTMB(
+   count ~ spp + mined,
+   ziformula = ~ mined + spp,
+   family = poisson,
+   data = Salamanders
+ )
+ res <- simulate_residuals(m)
+ check_zeroinflation(res)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: glmmTMB
Loading required package: DHARMa
This is DHARMa 0.4.7. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')
> data(Salamanders, package = "glmmTMB")
> m <- glm(count ~ spp + mined, family = poisson, data = Salamanders)
> check_zeroinflation(m)
# Check for zero-inflation

   Observed zeros: 387
  Predicted zeros: 298
            Ratio: 0.77

Model is underfitting zeros (probable zero-inflation).
> m <- glmmTMB::glmmTMB(count ~ spp + mined, ziformula = ~mined + spp, family = poisson, 
+     data = Salamanders)
> res <- simulate_residuals(m)
> check_zeroinflation(res)
# Check for zero-inflation

   Observed zeros: 387
  Predicted zeros: 387
            Ratio: 1.00

Model seems ok, ratio of observed and predicted zeros is within the
  tolerance range (p > .999).
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:DHARMa’, ‘package:glmmTMB’

> nameEx("compare_performance")
> ### * compare_performance
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: compare_performance
> ### Title: Compare performance of different models
> ### Aliases: compare_performance
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("lme4")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ data(iris)
+ lm1 <- lm(Sepal.Length ~ Species, data = iris)
+ lm2 <- lm(Sepal.Length ~ Species + Petal.Length, data = iris)
+ lm3 <- lm(Sepal.Length ~ Species * Petal.Length, data = iris)
+ compare_performance(lm1, lm2, lm3)
+ compare_performance(lm1, lm2, lm3, rank = TRUE)
+ 
+ m1 <- lm(mpg ~ wt + cyl, data = mtcars)
+ m2 <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
+ m3 <- lme4::lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)
+ compare_performance(m1, m2, m3)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: lme4
Loading required package: Matrix
> data(iris)
> lm1 <- lm(Sepal.Length ~ Species, data = iris)
> lm2 <- lm(Sepal.Length ~ Species + Petal.Length, data = iris)
> lm3 <- lm(Sepal.Length ~ Species * Petal.Length, data = iris)
> compare_performance(lm1, lm2, lm3)
# Comparison of Model Performance Indices

Name | Model | AIC (weights) | AICc (weights) | BIC (weights) |    R2
---------------------------------------------------------------------
lm1  |    lm | 231.5 (<.001) |  231.7 (<.001) | 243.5 (<.001) | 0.619
lm2  |    lm | 106.2 (0.566) |  106.6 (0.611) | 121.3 (0.964) | 0.837
lm3  |    lm | 106.8 (0.434) |  107.6 (0.389) | 127.8 (0.036) | 0.840

Name | R2 (adj.) |  RMSE | Sigma
--------------------------------
lm1  |     0.614 | 0.510 | 0.515
lm2  |     0.833 | 0.333 | 0.338
lm3  |     0.835 | 0.330 | 0.336
> compare_performance(lm1, lm2, lm3, rank = TRUE)
# Comparison of Model Performance Indices

Name | Model |    R2 | R2 (adj.) |  RMSE | Sigma | AIC weights | AICc weights
-----------------------------------------------------------------------------
lm2  |    lm | 0.837 |     0.833 | 0.333 | 0.338 |       0.566 |        0.611
lm3  |    lm | 0.840 |     0.835 | 0.330 | 0.336 |       0.434 |        0.389
lm1  |    lm | 0.619 |     0.614 | 0.510 | 0.515 |    3.65e-28 |     4.23e-28

Name | BIC weights | Performance-Score
--------------------------------------
lm2  |       0.964 |            99.23%
lm3  |       0.036 |            77.70%
lm1  |    2.80e-27 |             0.00%
> m1 <- lm(mpg ~ wt + cyl, data = mtcars)
> m2 <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> m3 <- lme4::lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)
> compare_performance(m1, m2, m3)
When comparing models, please note that probably not all models were fit
  from same data.
# Comparison of Model Performance Indices

Name |   Model | AIC (weights) | AICc (weights) | BIC (weights) |  RMSE | Sigma
-------------------------------------------------------------------------------
m1   |      lm | 156.0 (<.001) |  157.5 (<.001) | 161.9 (<.001) | 2.444 | 2.568
m2   |     glm |  31.3 (>.999) |   32.2 (>.999) |  35.7 (>.999) | 0.359 | 1.000
m3   | lmerMod |  74.6 (<.001) |   74.9 (<.001) |  86.7 (<.001) | 0.279 | 0.283

Name |    R2 | R2 (adj.) | Tjur's R2 | Log_loss | Score_log | Score_spherical
-----------------------------------------------------------------------------
m1   | 0.830 |     0.819 |           |          |           |                
m2   |       |           |     0.478 |    0.395 |   -14.903 |           0.095
m3   |       |           |           |          |           |                

Name |   PCP | R2 (cond.) | R2 (marg.) |   ICC
----------------------------------------------
m1   |       |            |            |      
m2   | 0.743 |            |            |      
m3   |       |      0.972 |      0.096 | 0.969
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:lme4’, ‘package:Matrix’

> nameEx("cronbachs_alpha")
> ### * cronbachs_alpha
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cronbachs_alpha
> ### Title: Cronbach's Alpha for Items or Scales
> ### Aliases: cronbachs_alpha
> 
> ### ** Examples
> 
> data(mtcars)
> x <- mtcars[, c("cyl", "gear", "carb", "hp")]
> cronbachs_alpha(x)
[1] 0.09463206
> 
> 
> 
> cleanEx()
> nameEx("display.performance_model")
> ### * display.performance_model
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: display.performance_model
> ### Title: Print tables in different output formats
> ### Aliases: display.performance_model print_md.performance_model
> ###   print_md.compare_performance
> 
> ### ** Examples
> 
> model <- lm(mpg ~ wt + cyl, data = mtcars)
> mp <- model_performance(model)
> display(mp)
[1] "|AIC    |   AICc |    BIC |   R2 | R2 (adj.) | RMSE | Sigma |"
[2] "|:------|:------:|:------:|:----:|:---------:|:----:|:-----:|"
[3] "|156.01 | 157.49 | 161.87 | 0.83 |      0.82 | 2.44 |  2.57 |"
attr(,"format")
[1] "pipe"
attr(,"class")
[1] "knitr_kable" "character"  
> 
> 
> 
> cleanEx()
> nameEx("icc")
> ### * icc
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: icc
> ### Title: Intraclass Correlation Coefficient (ICC)
> ### Aliases: icc variance_decomposition
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("lme4")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ model <- lme4::lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
+ icc(model)
+ 
+ # ICC for specific group-levels
+ data(sleepstudy, package = "lme4")
+ set.seed(12345)
+ sleepstudy$grp <- sample(1:5, size = 180, replace = TRUE)
+ sleepstudy$subgrp <- NA
+ for (i in 1:5) {
+   filter_group <- sleepstudy$grp == i
+   sleepstudy$subgrp[filter_group] <-
+     sample(1:30, size = sum(filter_group), replace = TRUE)
+ }
+ model <- lme4::lmer(
+   Reaction ~ Days + (1 | grp / subgrp) + (1 | Subject),
+   data = sleepstudy
+ )
+ icc(model, by_group = TRUE)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: lme4
Loading required package: Matrix
> model <- lme4::lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
> icc(model)
# Intraclass Correlation Coefficient

    Adjusted ICC: 0.910
  Unadjusted ICC: 0.311
> data(sleepstudy, package = "lme4")
> set.seed(12345)
> sleepstudy$grp <- sample(1:5, size = 180, replace = TRUE)
> sleepstudy$subgrp <- NA
> for (i in 1:5) {
+     filter_group <- sleepstudy$grp == i
+     sleepstudy$subgrp[filter_group] <- sample(1:30, size = sum(filter_group), replace = TRUE)
+ }
> model <- lme4::lmer(Reaction ~ Days + (1 | grp/subgrp) + (1 | Subject), 
+     data = sleepstudy)
> icc(model, by_group = TRUE)
# ICC by Group

Group      |   ICC
------------------
subgrp:grp | 0.017
Subject    | 0.589
grp        | 0.001
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:lme4’, ‘package:Matrix’

> nameEx("item_difficulty")
> ### * item_difficulty
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: item_difficulty
> ### Title: Difficulty of Questionnaire Items
> ### Aliases: item_difficulty
> 
> ### ** Examples
> 
> data(mtcars)
> x <- mtcars[, c("cyl", "gear", "carb", "hp")]
> item_difficulty(x)
Item Difficulty

Item | Difficulty | Ideal
-------------------------
cyl  |       0.02 |  0.50
gear |       0.01 |  0.50
carb |       0.01 |  0.50
hp   |       0.44 |  0.50
> 
> 
> 
> cleanEx()
> nameEx("item_discrimination")
> ### * item_discrimination
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: item_discrimination
> ### Title: Discrimination of Questionnaire Items
> ### Aliases: item_discrimination
> 
> ### ** Examples
> 
> data(mtcars)
> x <- mtcars[, c("cyl", "gear", "carb", "hp")]
> item_discrimination(x)
Item Discrimination

Item | Discrimination
---------------------
cyl  |           0.83
gear |          -0.13
carb |           0.75
hp   |           0.88
> 
> 
> 
> cleanEx()
> nameEx("item_intercor")
> ### * item_intercor
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: item_intercor
> ### Title: Mean Inter-Item-Correlation
> ### Aliases: item_intercor
> 
> ### ** Examples
> 
> data(mtcars)
> x <- mtcars[, c("cyl", "gear", "carb", "hp")]
> item_intercor(x)
[1] 0.294155
> 
> 
> 
> cleanEx()
> nameEx("item_reliability")
> ### * item_reliability
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: item_reliability
> ### Title: Reliability Test for Items or Scales
> ### Aliases: item_reliability
> 
> ### ** Examples
> 
> data(mtcars)
> x <- mtcars[, c("cyl", "gear", "carb", "hp")]
> item_reliability(x)
  term alpha_if_deleted item_discrimination
1  cyl            0.048               0.826
2 gear            0.110              -0.127
3 carb            0.058               0.751
4   hp            0.411               0.881
> 
> 
> 
> cleanEx()
> nameEx("item_split_half")
> ### * item_split_half
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: item_split_half
> ### Title: Split-Half Reliability
> ### Aliases: item_split_half
> 
> ### ** Examples
> 
> data(mtcars)
> x <- mtcars[, c("cyl", "gear", "carb", "hp")]
> item_split_half(x)
$splithalf
[1] 0.9070215

$spearmanbrown
[1] 0.9512441

> 
> 
> 
> cleanEx()
> nameEx("looic")
> ### * looic
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: looic
> ### Title: LOO-related Indices for Bayesian regressions.
> ### Aliases: looic
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("rstanarm")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: rstanarm
Loading required package: Rcpp
This is rstanarm version 2.32.1
- See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!
- Default priors may change, so it's safest to specify priors, even if equivalent to the defaults.
- For execution on a local, multicore CPU with excess RAM we recommend calling
  options(mc.cores = parallel::detectCores())
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:rstanarm’, ‘package:Rcpp’

> nameEx("model_performance")
> ### * model_performance
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance
> ### Title: Model Performance
> ### Aliases: model_performance performance
> 
> ### ** Examples
> 
> model <- lm(mpg ~ wt + cyl, data = mtcars)
> model_performance(model)
# Indices of model performance

AIC     |    AICc |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma
---------------------------------------------------------------
156.010 | 157.492 | 161.873 | 0.830 |     0.819 | 2.444 | 2.568
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> model_performance(model)
# Indices of model performance

AIC    |   AICc |    BIC | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log
---------------------------------------------------------------------------
31.298 | 32.155 | 35.695 |     0.478 | 0.359 | 1.000 |    0.395 |   -14.903

AIC    | Score_spherical |   PCP
--------------------------------
31.298 |           0.095 | 0.743
> 
> 
> 
> cleanEx()
> nameEx("model_performance.kmeans")
> ### * model_performance.kmeans
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance.kmeans
> ### Title: Model summary for k-means clustering
> ### Aliases: model_performance.kmeans
> 
> ### ** Examples
> 
> # a 2-dimensional example
> x <- rbind(
+   matrix(rnorm(100, sd = 0.3), ncol = 2),
+   matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2)
+ )
> colnames(x) <- c("x", "y")
> model <- kmeans(x, 2)
> model_performance(model)
# Indices of model performance

Sum_Squares_Total | Sum_Squares_Within | Sum_Squares_Between | Iterations
-------------------------------------------------------------------------
60.991            |             14.918 |              46.073 |      1.000
> 
> 
> 
> cleanEx()
> nameEx("model_performance.lavaan")
> ### * model_performance.lavaan
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance.lavaan
> ### Title: Performance of lavaan SEM / CFA Models
> ### Aliases: model_performance.lavaan
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("lavaan")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ # Confirmatory Factor Analysis (CFA) ---------
+ data(HolzingerSwineford1939, package = "lavaan")
+ structure <- " visual  =~ x1 + x2 + x3
+                textual =~ x4 + x5 + x6
+                speed   =~ x7 + x8 + x9 "
+ model <- lavaan::cfa(structure, data = HolzingerSwineford1939)
+ model_performance(model)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: lavaan
This is lavaan 0.6-19
lavaan is FREE software! Please report any bugs.
> data(HolzingerSwineford1939, package = "lavaan")
> structure <- " visual  =~ x1 + x2 + x3\n               textual =~ x4 + x5 + x6\n               speed   =~ x7 + x8 + x9 "
> model <- lavaan::cfa(structure, data = HolzingerSwineford1939)
> model_performance(model)
# Indices of model performance

Chi2(24) | p (Chi2) | Baseline(36) | p (Baseline) |   GFI |  AGFI |   NFI
-------------------------------------------------------------------------
85.306   |   < .001 |      918.852 |       < .001 | 0.943 | 0.894 | 0.907

Chi2(24) |  NNFI |   CFI | RMSEA |      RMSEA  CI | p (RMSEA) |   RMR |  SRMR
-----------------------------------------------------------------------------
85.306   | 0.896 | 0.931 | 0.092 | [0.071, 0.114] |    < .001 | 0.082 | 0.065

Chi2(24) |   RFI |  PNFI |   IFI |   RNI | Loglikelihood |      AIC |      BIC | BIC_adjusted
---------------------------------------------------------------------------------------------
85.306   | 0.861 | 0.605 | 0.931 | 0.931 |     -3737.745 | 7517.490 | 7595.339 |     7528.739
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:lavaan’

> nameEx("model_performance.lm")
> ### * model_performance.lm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance.lm
> ### Title: Performance of Regression Models
> ### Aliases: model_performance.lm
> 
> ### ** Examples
> 
> model <- lm(mpg ~ wt + cyl, data = mtcars)
> model_performance(model)
# Indices of model performance

AIC     |    AICc |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma
---------------------------------------------------------------
156.010 | 157.492 | 161.873 | 0.830 |     0.819 | 2.444 | 2.568
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> model_performance(model)
# Indices of model performance

AIC    |   AICc |    BIC | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log
---------------------------------------------------------------------------
31.298 | 32.155 | 35.695 |     0.478 | 0.359 | 1.000 |    0.395 |   -14.903

AIC    | Score_spherical |   PCP
--------------------------------
31.298 |           0.095 | 0.743
> 
> 
> 
> cleanEx()
> nameEx("model_performance.merMod")
> ### * model_performance.merMod
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance.merMod
> ### Title: Performance of Mixed Models
> ### Aliases: model_performance.merMod
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("lme4")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ model <- lme4::lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)
+ model_performance(model)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: lme4
Loading required package: Matrix
> model <- lme4::lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)
> model_performance(model)
# Indices of model performance

AIC    |   AICc |    BIC | R2 (cond.) | R2 (marg.) |   ICC |  RMSE | Sigma
--------------------------------------------------------------------------
77.320 | 77.595 | 89.362 |      0.972 |      0.096 | 0.969 | 0.279 | 0.283
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:lme4’, ‘package:Matrix’

> nameEx("model_performance.rma")
> ### * model_performance.rma
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance.rma
> ### Title: Performance of Meta-Analysis Models
> ### Aliases: model_performance.rma
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("metafor") && require("metadat")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ data(dat.bcg, package = "metadat")
+ dat <- metafor::escalc(
+   measure = "RR",
+   ai = tpos,
+   bi = tneg,
+   ci = cpos,
+   di = cneg,
+   data = dat.bcg
+ )
+ model <- metafor::rma(yi, vi, data = dat, method = "REML")
+ model_performance(model)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: metafor
Loading required package: Matrix
Loading required package: metadat
Loading required package: numDeriv

Loading the 'metafor' package (version 4.8-0). For an
introduction to the package please type: help(metafor)

> data(dat.bcg, package = "metadat")
> dat <- metafor::escalc(measure = "RR", ai = tpos, bi = tneg, ci = cpos, 
+     di = cneg, data = dat.bcg)
> model <- metafor::rma(yi, vi, data = dat, method = "REML")
> model_performance(model)
# Indices of model performance

AIC    |    BIC |    I2 |     H2 |  TAU2 | CochransQ | p (CochransQ) | df
-------------------------------------------------------------------------
29.376 | 30.505 | 0.922 | 12.856 | 0.313 |   152.233 |        < .001 | 12

AIC    | Omnibus | p (Omnibus)
------------------------------
29.376 |  15.796 |      < .001
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:metafor’, ‘package:numDeriv’, ‘package:metadat’,
  ‘package:Matrix’

> nameEx("model_performance.stanreg")
> ### * model_performance.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance.stanreg
> ### Title: Performance of Bayesian Models
> ### Aliases: model_performance.stanreg model_performance.BFBayesFactor
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("rstanarm") && require("rstantools")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: rstanarm
Loading required package: Rcpp
This is rstanarm version 2.32.1
- See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!
- Default priors may change, so it's safest to specify priors, even if equivalent to the defaults.
- For execution on a local, multicore CPU with excess RAM we recommend calling
  options(mc.cores = parallel::detectCores())
Loading required package: rstantools
This is rstantools version 2.4.0
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:rstantools’, ‘package:rstanarm’, ‘package:Rcpp’

> nameEx("performance_accuracy")
> ### * performance_accuracy
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_accuracy
> ### Title: Accuracy of predictions from model fit
> ### Aliases: performance_accuracy
> 
> ### ** Examples
> 
> model <- lm(mpg ~ wt + cyl, data = mtcars)
> performance_accuracy(model)
# Accuracy of Model Predictions

Accuracy (95% CI): 89.40% [83.83%, 97.00%]
Method: Correlation between observed and predicted
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> performance_accuracy(model)
# Accuracy of Model Predictions

Accuracy (95% CI): 91.67% [69.17%, 100.00%]
Method: Area under Curve
> 
> 
> 
> cleanEx()
> nameEx("performance_aicc")
> ### * performance_aicc
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_aicc
> ### Title: Compute the AIC or second-order AIC
> ### Aliases: performance_aicc performance_aic performance_aic.default
> ###   performance_aic.lmerMod
> 
> ### ** Examples
> 
> m <- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
> AIC(m)
[1] 159.1051
> performance_aicc(m)
[1] 162.4651
> 
> # correct AIC for models with transformed response variable
> data("mtcars")
> mtcars$mpg <- floor(mtcars$mpg)
> model <- lm(log(mpg) ~ factor(cyl), mtcars)
> 
> # wrong AIC, not corrected for log-transformation
> AIC(model)
[1] -19.67061
> 
> # performance_aic() correctly detects transformed response and
> # returns corrected AIC
> performance_aic(model)
[1] 168.2152
> 
> ## Not run: 
> ##D # there are a few exceptions where the corrected log-likelihood values
> ##D # cannot be returned. The following exampe gives a warning.
> ##D model <- lm(1 / mpg ~ factor(cyl), mtcars)
> ##D performance_aic(model)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("performance_cv")
> ### * performance_cv
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_cv
> ### Title: Cross-validated model performance
> ### Aliases: performance_cv
> 
> ### ** Examples
> 
> model <- lm(mpg ~ wt + cyl, data = mtcars)
> performance_cv(model)
# Cross-validation performance (30% holdout method)

MSE | RMSE |   R2
-----------------
5.5 |  2.4 | 0.83
> 
> 
> 
> 
> cleanEx()
> nameEx("performance_hosmer")
> ### * performance_hosmer
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_hosmer
> ### Title: Hosmer-Lemeshow goodness-of-fit test
> ### Aliases: performance_hosmer
> 
> ### ** Examples
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> performance_hosmer(model)
# Hosmer-Lemeshow Goodness-of-Fit Test

  Chi-squared: 5.137
           df: 8    
      p-value: 0.743

Summary: model seems to fit well.
> 
> 
> 
> cleanEx()
> nameEx("performance_logloss")
> ### * performance_logloss
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_logloss
> ### Title: Log Loss
> ### Aliases: performance_logloss
> 
> ### ** Examples
> 
> data(mtcars)
> m <- glm(formula = vs ~ hp + wt, family = binomial, data = mtcars)
> performance_logloss(m)
[1] 0.2517054
> 
> 
> 
> cleanEx()
> nameEx("performance_mae")
> ### * performance_mae
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_mae
> ### Title: Mean Absolute Error of Models
> ### Aliases: performance_mae mae
> 
> ### ** Examples
> 
> data(mtcars)
> m <- lm(mpg ~ hp + gear, data = mtcars)
> performance_mae(m)
[1] 2.545822
> 
> 
> 
> cleanEx()
> nameEx("performance_mse")
> ### * performance_mse
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_mse
> ### Title: Mean Square Error of Linear Models
> ### Aliases: performance_mse mse
> 
> ### ** Examples
> 
> data(mtcars)
> m <- lm(mpg ~ hp + gear, data = mtcars)
> performance_mse(m)
[1] 8.752858
> 
> 
> 
> cleanEx()
> nameEx("performance_pcp")
> ### * performance_pcp
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_pcp
> ### Title: Percentage of Correct Predictions
> ### Aliases: performance_pcp
> 
> ### ** Examples
> 
> data(mtcars)
> m <- glm(formula = vs ~ hp + wt, family = binomial, data = mtcars)
> performance_pcp(m)
# Percentage of Correct Predictions from Logistic Regression Model

  Full model: 83.75% [70.96% - 96.53%]
  Null model: 50.78% [33.46% - 68.10%]

# Likelihood-Ratio-Test

  Chi-squared: 27.751
  df:  2.000
  p-value:  0.000

> performance_pcp(m, method = "Gelman-Hill")
# Percentage of Correct Predictions from Logistic Regression Model

  Full model: 87.50% [76.04% - 98.96%]
  Null model: 56.25% [39.06% - 73.44%]

# Likelihood-Ratio-Test

  Chi-squared: 27.751
  df:  2.000
  p-value:  0.000

> 
> 
> 
> cleanEx()
> nameEx("performance_reliability")
> ### * performance_reliability
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_reliability
> ### Title: Random Effects Reliability
> ### Aliases: performance_reliability performance_dvour
> 
> ### ** Examples
> 
> ## Don't show: 
> if (all(insight::check_if_installed(c("lme4", "glmmTMB"), quietly = TRUE))) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ url <- "https://raw.githubusercontent.com/easystats/circus/refs/heads/main/data/illusiongame.csv"
+ df <- read.csv(url)
+ 
+ m <- lme4::lmer(RT ~ (1 | Participant), data = df)
+ performance_reliability(m)
+ performance_dvour(m)
+ 
+ m <- glmmTMB::glmmTMB(RT ~ (1 | Participant), data = df)
+ performance_reliability(m)
+ performance_dvour(m)
+ 
+ m <- lme4::lmer(RT ~ (1 | Participant) + (1 | Trial), data = df)
+ performance_reliability(m)
+ performance_dvour(m)
+ 
+ m <- glmmTMB::glmmTMB(RT ~ (1 | Participant) + (1 | Trial), data = df)
+ performance_reliability(m)
+ performance_dvour(m)
+ 
+ ## Don't show: 
+ }) # examplesIf
> url <- "https://raw.githubusercontent.com/easystats/circus/refs/heads/main/data/illusiongame.csv"
> df <- read.csv(url)
> m <- lme4::lmer(RT ~ (1 | Participant), data = df)
> performance_reliability(m)
        Group   Parameter Reliability
1 Participant (Intercept)    0.155448
> performance_dvour(m)
        Group   Parameter    D_vour
1 Participant (Intercept) 0.9781019
> m <- glmmTMB::glmmTMB(RT ~ (1 | Participant), data = df)
> performance_reliability(m)
        Group   Parameter Reliability
1 Participant (Intercept)   0.1528589
> performance_dvour(m)
        Group   Parameter    D_vour
1 Participant (Intercept) 0.9603575
> m <- lme4::lmer(RT ~ (1 | Participant) + (1 | Trial), data = df)
> performance_reliability(m)
        Group   Parameter Reliability
1       Trial (Intercept) 0.005897166
2 Participant (Intercept) 0.156391605
> performance_dvour(m)
        Group   Parameter    D_vour
1 Participant (Intercept) 0.9777044
2       Trial (Intercept) 0.5664226
> m <- glmmTMB::glmmTMB(RT ~ (1 | Participant) + (1 | Trial), data = df)
> performance_reliability(m)
Cannot extract confidence intervals for random variance parameters from
  models with more than one grouping factor.
        Group   Parameter Reliability
1 Participant (Intercept)  0.15386342
2       Trial (Intercept)  0.00588784
> performance_dvour(m)
Cannot extract confidence intervals for random variance parameters from
  models with more than one grouping factor.
        Group   Parameter    D_vour
1 Participant (Intercept) 0.9604671
2       Trial (Intercept) 0.5602238
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("performance_rmse")
> ### * performance_rmse
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_rmse
> ### Title: Root Mean Squared Error
> ### Aliases: performance_rmse rmse
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("nlme")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ data(Orthodont, package = "nlme")
+ m <- nlme::lme(distance ~ age, data = Orthodont)
+ 
+ # RMSE
+ performance_rmse(m, normalized = FALSE)
+ 
+ # normalized RMSE
+ performance_rmse(m, normalized = TRUE)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: nlme
> data(Orthodont, package = "nlme")
> m <- nlme::lme(distance ~ age, data = Orthodont)
> performance_rmse(m, normalized = FALSE)
[1] 1.086327
> performance_rmse(m, normalized = TRUE)
[1] 0.07242178
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:nlme’

> nameEx("performance_roc")
> ### * performance_roc
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_roc
> ### Title: Simple ROC curve
> ### Aliases: performance_roc
> 
> ### ** Examples
> 
> library(bayestestR)
> data(iris)
> 
> set.seed(123)
> iris$y <- rbinom(nrow(iris), size = 1, .3)
> folds <- sample(nrow(iris), size = nrow(iris) / 8, replace = FALSE)
> test_data <- iris[folds, ]
> train_data <- iris[-folds, ]
> 
> model <- glm(y ~ Sepal.Length + Sepal.Width, data = train_data, family = "binomial")
> as.data.frame(performance_roc(model, new_data = test_data))
   Sensitivity Specificity   Model
1    0.0000000  0.00000000 Model 1
2    0.1428571  0.00000000 Model 1
3    0.1428571  0.09090909 Model 1
4    0.1428571  0.18181818 Model 1
5    0.1428571  0.27272727 Model 1
6    0.1428571  0.36363636 Model 1
7    0.2857143  0.36363636 Model 1
8    0.2857143  0.45454545 Model 1
9    0.2857143  0.54545455 Model 1
10   0.2857143  0.63636364 Model 1
11   0.2857143  0.72727273 Model 1
12   0.4285714  0.72727273 Model 1
13   0.5714286  0.72727273 Model 1
14   0.5714286  0.81818182 Model 1
15   0.7142857  0.81818182 Model 1
16   0.8571429  0.81818182 Model 1
17   0.8571429  0.90909091 Model 1
18   1.0000000  0.90909091 Model 1
19   1.0000000  1.00000000 Model 1
20   1.0000000  1.00000000 Model 1
> as.numeric(performance_roc(model))
[1] 0.540825
> 
> roc <- performance_roc(model, new_data = test_data)
> area_under_curve(roc$Specificity, roc$Sensitivity)
[1] 0.3766234
> 
> if (interactive()) {
+   m1 <- glm(y ~ Sepal.Length + Sepal.Width, data = iris, family = "binomial")
+   m2 <- glm(y ~ Sepal.Length + Petal.Width, data = iris, family = "binomial")
+   m3 <- glm(y ~ Sepal.Length + Species, data = iris, family = "binomial")
+   performance_roc(m1, m2, m3)
+ 
+   # if you have `see` package installed, you can also plot comparison of
+   # ROC curves for different models
+   if (require("see")) plot(performance_roc(m1, m2, m3))
+ }
> 
> 
> 
> cleanEx()

detaching ‘package:bayestestR’

> nameEx("performance_rse")
> ### * performance_rse
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_rse
> ### Title: Residual Standard Error for Linear Models
> ### Aliases: performance_rse
> 
> ### ** Examples
> 
> data(mtcars)
> m <- lm(mpg ~ hp + gear, data = mtcars)
> performance_rse(m)
[1] 3.107785
> 
> 
> 
> cleanEx()
> nameEx("performance_score")
> ### * performance_score
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_score
> ### Title: Proper Scoring Rules
> ### Aliases: performance_score
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("glmmTMB")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ ## Dobson (1990) Page 93: Randomized Controlled Trial :
+ counts <- c(18, 17, 15, 20, 10, 20, 25, 13, 12)
+ outcome <- gl(3, 1, 9)
+ treatment <- gl(3, 3)
+ model <- glm(counts ~ outcome + treatment, family = poisson())
+ 
+ performance_score(model)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: glmmTMB
> counts <- c(18, 17, 15, 20, 10, 20, 25, 13, 12)
> outcome <- gl(3, 1, 9)
> treatment <- gl(3, 3)
> model <- glm(counts ~ outcome + treatment, family = poisson())
> performance_score(model)
# Proper Scoring Rules

logarithmic: -2.5979
  quadratic:  0.2095
  spherical:  0.3238
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:glmmTMB’

> nameEx("r2")
> ### * r2
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2
> ### Title: Compute the model's R2
> ### Aliases: r2 r2.default r2.mlm r2.merMod
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("lme4")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ # Pseudo r-quared for GLM
+ model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
+ r2(model)
+ 
+ # r-squared including confidence intervals
+ model <- lm(mpg ~ wt + hp, data = mtcars)
+ r2(model, ci = 0.95)
+ 
+ model <- lme4::lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
+ r2(model)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: lme4
Loading required package: Matrix
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> r2(model)
# R2 for Logistic Regression
  Tjur's R2: 0.478
> model <- lm(mpg ~ wt + hp, data = mtcars)
> r2(model, ci = 0.95)
       R2: 0.827 [0.654, 0.906]
  adj. R2: 0.815 [0.632, 0.899]
> model <- lme4::lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
> r2(model)
# R2 for Mixed Models

  Conditional R2: 0.969
     Marginal R2: 0.658
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:lme4’, ‘package:Matrix’

> nameEx("r2_bayes")
> ### * r2_bayes
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_bayes
> ### Title: Bayesian R2
> ### Aliases: r2_bayes r2_posterior r2_posterior.brmsfit
> ###   r2_posterior.stanreg r2_posterior.BFBayesFactor
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("rstanarm") && require("rstantools") && require("brms") && require("RcppEigen")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ library(performance)
+ 
+ ## Don't show: 
+ }) # examplesIf
Loading required package: rstanarm
Loading required package: Rcpp
This is rstanarm version 2.32.1
- See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!
- Default priors may change, so it's safest to specify priors, even if equivalent to the defaults.
- For execution on a local, multicore CPU with excess RAM we recommend calling
  options(mc.cores = parallel::detectCores())
Loading required package: rstantools
This is rstantools version 2.4.0
Loading required package: brms
Loading 'brms' package (version 2.22.0). Useful instructions
can be found by typing help('brms'). A more detailed introduction
to the package is available through vignette('brms_overview').

Attaching package: ‘brms’

The following objects are masked from ‘package:rstanarm’:

    dirichlet, exponential, get_y, lasso, ngrps

The following object is masked from ‘package:stats’:

    ar

Loading required package: RcppEigen
> library(performance)
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:RcppEigen’, ‘package:brms’, ‘package:rstantools’,
  ‘package:rstanarm’, ‘package:Rcpp’

> nameEx("r2_coxsnell")
> ### * r2_coxsnell
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_coxsnell
> ### Title: Cox & Snell's R2
> ### Aliases: r2_coxsnell
> 
> ### ** Examples
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> r2_coxsnell(model)
Cox & Snell's R2 
       0.4401407 
> 
> 
> 
> 
> cleanEx()
> nameEx("r2_efron")
> ### * r2_efron
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_efron
> ### Title: Efron's R2
> ### Aliases: r2_efron
> 
> ### ** Examples
> 
> ## Dobson (1990) Page 93: Randomized Controlled Trial:
> counts <- c(18, 17, 15, 20, 10, 20, 25, 13, 12) #
> outcome <- gl(3, 1, 9)
> treatment <- gl(3, 3)
> model <- glm(counts ~ outcome + treatment, family = poisson())
> 
> r2_efron(model)
[1] 0.5265152
> 
> 
> 
> cleanEx()
> nameEx("r2_ferrari")
> ### * r2_ferrari
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_ferrari
> ### Title: Ferrari's and Cribari-Neto's R2
> ### Aliases: r2_ferrari r2_ferrari.default
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("betareg")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ data("GasolineYield", package = "betareg")
+ model <- betareg::betareg(yield ~ batch + temp, data = GasolineYield)
+ r2_ferrari(model)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: betareg
> data("GasolineYield", package = "betareg")
> model <- betareg::betareg(yield ~ batch + temp, data = GasolineYield)
> r2_ferrari(model)
# R2 for Generalized Linear Regression
  Ferrari's R2: 0.962
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:betareg’

> nameEx("r2_kullback")
> ### * r2_kullback
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_kullback
> ### Title: Kullback-Leibler R2
> ### Aliases: r2_kullback r2_kullback.glm
> 
> ### ** Examples
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> r2_kullback(model)
Kullback-Leibler R2 
          0.3834362 
> 
> 
> 
> cleanEx()
> nameEx("r2_loo")
> ### * r2_loo
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_loo
> ### Title: LOO-adjusted R2
> ### Aliases: r2_loo r2_loo_posterior r2_loo_posterior.brmsfit
> ###   r2_loo_posterior.stanreg
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("rstanarm") && require("rstantools")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ model <- suppressWarnings(rstanarm::stan_glm(
+   mpg ~ wt + cyl,
+   data = mtcars,
+   chains = 1,
+   iter = 500,
+   refresh = 0,
+   show_messages = FALSE
+ ))
+ r2_loo(model)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: rstanarm
Loading required package: Rcpp
This is rstanarm version 2.32.1
- See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!
- Default priors may change, so it's safest to specify priors, even if equivalent to the defaults.
- For execution on a local, multicore CPU with excess RAM we recommend calling
  options(mc.cores = parallel::detectCores())
Loading required package: rstantools
This is rstantools version 2.4.0
> model <- suppressWarnings(rstanarm::stan_glm(mpg ~ wt + cyl, data = mtcars, 
+     chains = 1, iter = 500, refresh = 0, show_messages = FALSE))
> r2_loo(model)
Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.

# LOO-adjusted R2 with Compatibility Interval

  Conditional R2: 0.802 (95% CI [0.706, 0.898])
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:rstantools’, ‘package:rstanarm’, ‘package:Rcpp’

> nameEx("r2_mcfadden")
> ### * r2_mcfadden
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_mcfadden
> ### Title: McFadden's R2
> ### Aliases: r2_mcfadden
> 
> ### ** Examples
> 
> if (require("mlogit")) {
+   data("Fishing", package = "mlogit")
+   Fish <- mlogit.data(Fishing, varying = c(2:9), shape = "wide", choice = "mode")
+ 
+   model <- mlogit(mode ~ price + catch, data = Fish)
+   r2_mcfadden(model)
+ }
Loading required package: mlogit
Loading required package: dfidx
The tidyverse part of the package is now in the tidydfidx package
so that the dfidx package now depends only on a small set of packages

McFadden's R2 
      0.17823 
> 
> 
> 
> cleanEx()

detaching ‘package:mlogit’, ‘package:dfidx’

> nameEx("r2_mckelvey")
> ### * r2_mckelvey
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_mckelvey
> ### Title: McKelvey & Zavoinas R2
> ### Aliases: r2_mckelvey
> 
> ### ** Examples
> 
> ## Dobson (1990) Page 93: Randomized Controlled Trial:
> counts <- c(18, 17, 15, 20, 10, 20, 25, 13, 12) #
> outcome <- gl(3, 1, 9)
> treatment <- gl(3, 3)
> model <- glm(counts ~ outcome + treatment, family = poisson())
> 
> r2_mckelvey(model)
McKelvey's R2 
    0.3776292 
> 
> 
> 
> cleanEx()
> nameEx("r2_mlm")
> ### * r2_mlm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_mlm
> ### Title: Multivariate R2
> ### Aliases: r2_mlm
> 
> ### ** Examples
> 
> model <- lm(cbind(qsec, drat) ~ wt + mpg + cyl, data = mtcars)
> r2_mlm(model)
 Symmetric Rxy Asymmetric Pxy 
     0.8573111      0.5517522 
> 
> model_swap <- lm(cbind(wt, mpg, cyl) ~ qsec + drat, data = mtcars)
> r2_mlm(model_swap)
 Symmetric Rxy Asymmetric Pxy 
     0.8573111      0.3678348 
> 
> 
> 
> 
> cleanEx()
> nameEx("r2_nagelkerke")
> ### * r2_nagelkerke
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_nagelkerke
> ### Title: Nagelkerke's R2
> ### Aliases: r2_nagelkerke
> 
> ### ** Examples
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> r2_nagelkerke(model)
Nagelkerke's R2 
      0.5899593 
> 
> 
> 
> cleanEx()
> nameEx("r2_nakagawa")
> ### * r2_nakagawa
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_nakagawa
> ### Title: Nakagawa's R2 for mixed models
> ### Aliases: r2_nakagawa
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("lme4")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ model <- lme4::lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
+ r2_nakagawa(model)
+ r2_nakagawa(model, by_group = TRUE)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: lme4
Loading required package: Matrix
> model <- lme4::lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
> r2_nakagawa(model)
# R2 for Mixed Models

  Conditional R2: 0.969
     Marginal R2: 0.658
> r2_nakagawa(model, by_group = TRUE)
# Explained Variance by Level

Level   |     R2
----------------
Level 1 |  0.569
Species | -0.853

> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:lme4’, ‘package:Matrix’

> nameEx("r2_somers")
> ### * r2_somers
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_somers
> ### Title: Somers' Dxy rank correlation for binary outcomes
> ### Aliases: r2_somers
> 
> ### ** Examples
> 
> 
> 
> 
> 
> cleanEx()
> nameEx("r2_tjur")
> ### * r2_tjur
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_tjur
> ### Title: Tjur's R2 - coefficient of determination (D)
> ### Aliases: r2_tjur
> 
> ### ** Examples
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> r2_tjur(model)
Tjur's R2 
0.4776926 
> 
> 
> 
> 
> cleanEx()
> nameEx("r2_xu")
> ### * r2_xu
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_xu
> ### Title: Xu' R2 (Omega-squared)
> ### Aliases: r2_xu
> 
> ### ** Examples
> 
> model <- lm(Sepal.Length ~ Petal.Length + Species, data = iris)
> r2_xu(model)
  Xu's R2 
0.8367238 
> 
> 
> 
> cleanEx()
> nameEx("r2_zeroinflated")
> ### * r2_zeroinflated
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_zeroinflated
> ### Title: R2 for models with zero-inflation
> ### Aliases: r2_zeroinflated
> 
> ### ** Examples
> 
> 
> 
> 
> cleanEx()
> nameEx("simulate_residuals")
> ### * simulate_residuals
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simulate_residuals
> ### Title: Simulate randomized quantile residuals from a model
> ### Aliases: simulate_residuals residuals.performance_simres
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("DHARMa")) (if (getRversion() >= "3.4") withAutoprint else force)({ # examplesIf
+ ## End(Don't show)
+ m <- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
+ simulate_residuals(m)
+ 
+ # extract residuals
+ head(residuals(simulate_residuals(m)))
+ ## Don't show: 
+ }) # examplesIf
Loading required package: DHARMa
This is DHARMa 0.4.7. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')
> m <- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
> simulate_residuals(m)
Simulated residuals from a model of class `lm` based on 250 simulations.
  Use `check_residuals()` to check uniformity of residuals or
  `residuals()` to extract simulated residuals. It is recommended to refer
  to `?DHARMa::simulateResiudals` and `vignette("DHARMa")` for more
  information about different settings in particular situations or for
  particular models.
> head(residuals(simulate_residuals(m)))
[1] 0.356 0.448 0.096 0.568 0.668 0.204
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching ‘package:DHARMa’

> nameEx("test_performance")
> ### * test_performance
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: test_bf
> ### Title: Test if models are different
> ### Aliases: test_bf test_bf.default test_likelihoodratio test_lrt
> ###   test_performance test_vuong test_wald
> 
> ### ** Examples
> 
> # Nested Models
> # -------------
> m1 <- lm(Sepal.Length ~ Petal.Width, data = iris)
> m2 <- lm(Sepal.Length ~ Petal.Width + Species, data = iris)
> m3 <- lm(Sepal.Length ~ Petal.Width * Species, data = iris)
> 
> test_performance(m1, m2, m3)
Name | Model |    BF |   Omega2 | p (Omega2) |   LR | p (LR)
------------------------------------------------------------
m1   |    lm |       |          |            |      |       
m2   |    lm | 0.007 | 9.54e-04 |      0.935 | 0.15 |  0.919
m3   |    lm | 0.037 |     0.02 |      0.081 | 3.41 |  0.099
Models were detected as nested (in terms of fixed parameters) and are compared in sequential order.
> 
> test_bf(m1, m2, m3)
Bayes Factors for Model Comparison

     Model                       BF
[m2] Petal.Width + Species    0.007
[m3] Petal.Width * Species 2.64e-04

* Against Denominator: [m1] Petal.Width
*   Bayes Factor Type: BIC approximation> test_wald(m1, m2, m3) # Equivalent to anova(m1, m2, m3)
Name | Model |  df | df_diff |    F |     p
-------------------------------------------
m1   |    lm | 148 |         |      |      
m2   |    lm | 146 |    2.00 | 0.08 | 0.927
m3   |    lm | 144 |    2.00 | 1.66 | 0.195
Models were detected as nested (in terms of fixed parameters) and are compared in sequential order.
> 
> # Equivalent to lmtest::lrtest(m1, m2, m3)
> test_likelihoodratio(m1, m2, m3, estimator = "ML")
# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)

Name | Model | df | df_diff | Chi2 |     p
------------------------------------------
m1   |    lm |  3 |         |      |      
m2   |    lm |  5 |       2 | 0.15 | 0.926
m3   |    lm |  7 |       2 | 3.41 | 0.182
> 
> # Equivalent to anova(m1, m2, m3, test='LRT')
> test_likelihoodratio(m1, m2, m3, estimator = "OLS")
# Likelihood-Ratio-Test (LRT) for Model Comparison (OLS-estimator)

Name | Model | df | df_diff | Chi2 |     p
------------------------------------------
m1   |    lm |  3 |         |      |      
m2   |    lm |  5 |       2 | 0.15 | 0.927
m3   |    lm |  7 |       2 | 3.31 | 0.191
> 
> if (require("CompQuadForm")) {
+   test_vuong(m1, m2, m3) # nonnest2::vuongtest(m1, m2, nested=TRUE)
+ 
+   # Non-nested Models
+   # -----------------
+   m1 <- lm(Sepal.Length ~ Petal.Width, data = iris)
+   m2 <- lm(Sepal.Length ~ Petal.Length, data = iris)
+   m3 <- lm(Sepal.Length ~ Species, data = iris)
+ 
+   test_performance(m1, m2, m3)
+   test_bf(m1, m2, m3)
+   test_vuong(m1, m2, m3) # nonnest2::vuongtest(m1, m2)
+ }
Loading required package: CompQuadForm
Name | Model | Omega2 | p (Omega2) |    LR | p (LR)
---------------------------------------------------
m1   |    lm |        |            |       |       
m2   |    lm |   0.19 |     < .001 | -4.57 | < .001
m3   |    lm |   0.12 |     < .001 |  2.51 | 0.006 
Each model is compared to m1.
> 
> # Tweak the output
> # ----------------
> test_performance(m1, m2, m3, include_formula = TRUE)
Name |                           Model |      BF | Omega2 | p (Omega2) |    LR | p (LR)
---------------------------------------------------------------------------------------
m1   |  lm(Sepal.Length ~ Petal.Width) |         |        |            |       |       
m2   | lm(Sepal.Length ~ Petal.Length) |  > 1000 |   0.19 |     < .001 | -4.57 | < .001
m3   |      lm(Sepal.Length ~ Species) | < 0.001 |   0.12 |     < .001 |  2.51 | 0.006 
Each model is compared to m1.
> 
> 
> # SEM / CFA (lavaan objects)
> # --------------------------
> # Lavaan Models
> if (require("lavaan")) {
+   structure <- " visual  =~ x1 + x2 + x3
+                  textual =~ x4 + x5 + x6
+                  speed   =~ x7 + x8 + x9
+ 
+                   visual ~~ textual + speed "
+   m1 <- lavaan::cfa(structure, data = HolzingerSwineford1939)
+ 
+   structure <- " visual  =~ x1 + x2 + x3
+                  textual =~ x4 + x5 + x6
+                  speed   =~ x7 + x8 + x9
+ 
+                   visual ~~ 0 * textual + speed "
+   m2 <- lavaan::cfa(structure, data = HolzingerSwineford1939)
+ 
+   structure <- " visual  =~ x1 + x2 + x3
+                  textual =~ x4 + x5 + x6
+                  speed   =~ x7 + x8 + x9
+ 
+                   visual ~~ 0 * textual + 0 * speed "
+   m3 <- lavaan::cfa(structure, data = HolzingerSwineford1939)
+ 
+   test_likelihoodratio(m1, m2, m3)
+ 
+   # Different Model Types
+   # ---------------------
+   if (require("lme4") && require("mgcv")) {
+     m1 <- lm(Sepal.Length ~ Petal.Length + Species, data = iris)
+     m2 <- lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
+     m3 <- gam(Sepal.Length ~ s(Petal.Length, by = Species) + Species, data = iris)
+ 
+     test_performance(m1, m2, m3)
+   }
+ }
Loading required package: lavaan
This is lavaan 0.6-19
lavaan is FREE software! Please report any bugs.
Loading required package: lme4
Loading required package: Matrix
Loading required package: mgcv
Loading required package: nlme

Attaching package: ‘nlme’

The following object is masked from ‘package:lme4’:

    lmList

This is mgcv 1.9-1. For overview type 'help("mgcv-package")'.
Name |   Model |      BF
------------------------
m1   |      lm |        
m2   | lmerMod | < 0.001
m3   |     gam |   0.038
Each model is compared to m1.
> 
> 
> 
> 
> ### * <FOOTER>
> ###
> cleanEx()

detaching ‘package:mgcv’, ‘package:nlme’, ‘package:lme4’,
  ‘package:Matrix’, ‘package:lavaan’, ‘package:CompQuadForm’

> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  18.36 3.406 18.37 0 0.003 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
