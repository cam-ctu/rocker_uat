
R version 4.3.0 (2023-04-21) -- "Already Tomorrow"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "parallelly"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('parallelly')
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("as.cluster")
> ### * as.cluster
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: as.cluster
> ### Title: Coerce an Object to a Cluster Object
> ### Aliases: as.cluster as.cluster.cluster as.cluster.list
> ###   as.cluster.SOCKnode as.cluster.SOCK0node as.cluster.RichSOCKnode
> ###   c.cluster
> 
> ### ** Examples
> 
> cl1 <- makeClusterPSOCK(2, dryrun = TRUE)
----------------------------------------------------------------------
Manually, start worker #1 on local machine ‘localhost’ with:

  '/usr/local/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions = "no-delay")' -e 'workRSOCK <- tryCatch(parallel:::.workRSOCK, error=function(e) parallel:::.slaveRSOCK); workRSOCK()' MASTER=localhost PORT=11394 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential

----------------------------------------------------------------------
Manually, start worker #2 on local machine ‘localhost’ with:

  '/usr/local/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions = "no-delay")' -e 'workRSOCK <- tryCatch(parallel:::.workRSOCK, error=function(e) parallel:::.slaveRSOCK); workRSOCK()' MASTER=localhost PORT=11394 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential

> cl2 <- makeClusterPSOCK(c("n1", "server.remote.org"), dryrun = TRUE)
----------------------------------------------------------------------
Manually, (i) login into external machine ‘n1’:

  '/usr/bin/ssh' -R 11168:localhost:11168 n1

and (ii) start worker #1 from there:

  '/usr/local/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions = "no-delay")' -e 'workRSOCK <- tryCatch(parallel:::.workRSOCK, error=function(e) parallel:::.slaveRSOCK); workRSOCK()' MASTER=localhost PORT=11168 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential

Alternatively, start worker #1 from the local machine by combining both steps in a single call:

  '/usr/bin/ssh' -R 11168:localhost:11168 n1 "'/usr/local/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions = \"no-delay\")' -e 'workRSOCK <- tryCatch(parallel:::.workRSOCK, error=function(e) parallel:::.slaveRSOCK); workRSOCK()' MASTER=localhost PORT=11168 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential"

----------------------------------------------------------------------
Manually, (i) login into external machine ‘server.remote.org’:

  '/usr/bin/ssh' -R 11169:localhost:11168 server.remote.org

and (ii) start worker #2 from there:

  'Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions = "no-delay")' -e 'workRSOCK <- tryCatch(parallel:::.workRSOCK, error=function(e) parallel:::.slaveRSOCK); workRSOCK()' MASTER=localhost PORT=11169 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential

Alternatively, start worker #2 from the local machine by combining both steps in a single call:

  '/usr/bin/ssh' -R 11169:localhost:11168 server.remote.org "'Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions = \"no-delay\")' -e 'workRSOCK <- tryCatch(parallel:::.workRSOCK, error=function(e) parallel:::.slaveRSOCK); workRSOCK()' MASTER=localhost PORT=11169 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential"

> cl <- c(cl1, cl2)
Warning: The combined cluster contains 1 duplicated nodes
> print(cl)
Socket cluster with 2 nodes where 2 nodes are on host ‘NA’ (R version and platform not queried)
> 
> 
> 
> cleanEx()
> nameEx("autoStopCluster")
> ### * autoStopCluster
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: autoStopCluster
> ### Title: Automatically Stop a Cluster when Garbage Collected
> ### Aliases: autoStopCluster
> 
> ### ** Examples
> 
> cl <- makeClusterPSOCK(2, dryrun = TRUE)
----------------------------------------------------------------------
Manually, start worker #1 on local machine ‘localhost’ with:

  '/usr/local/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions = "no-delay")' -e 'workRSOCK <- tryCatch(parallel:::.workRSOCK, error=function(e) parallel:::.slaveRSOCK); workRSOCK()' MASTER=localhost PORT=11098 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential

----------------------------------------------------------------------
Manually, start worker #2 on local machine ‘localhost’ with:

  '/usr/local/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions = "no-delay")' -e 'workRSOCK <- tryCatch(parallel:::.workRSOCK, error=function(e) parallel:::.slaveRSOCK); workRSOCK()' MASTER=localhost PORT=11098 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential

> cl <- autoStopCluster(cl)
> print(cl)
Socket cluster with 1 nodes where 1 node is on host ‘NA’ (R version and platform not queried). This cluster is registered to be automatically stopped by the garbage collector
> rm(list = "cl")
> gc()
         used (Mb) gc trigger (Mb) max used (Mb)
Ncells 403754 21.6     836960 44.7   664134 35.5
Vcells 746011  5.7    8388608 64.0  1814272 13.9
> 
> 
> 
> cleanEx()
> nameEx("availableConnections")
> ### * availableConnections
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: availableConnections
> ### Title: Number of Available and Free Connections
> ### Aliases: availableConnections freeConnections
> 
> ### ** Examples
> 
> total <- availableConnections()
> message("You can have ", total, " connections open in this R installation")
You can have 128 connections open in this R installation
> free <- freeConnections()
> message("There are ", free, " connections remaining")
There are 125 connections remaining
> 
> 
> 
> 
> cleanEx()
> nameEx("availableCores")
> ### * availableCores
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: availableCores
> ### Title: Get Number of Available Cores on The Current Machine
> ### Aliases: availableCores
> 
> ### ** Examples
> 
> message(paste("Number of cores available:", availableCores()))
Number of cores available: 4
> 
> ## Not run: 
> ##D options(mc.cores = 2L)
> ##D message(paste("Number of cores available:", availableCores()))
> ## End(Not run)
> 
> ## Not run: 
> ##D ## IMPORTANT: availableCores() may return 1L
> ##D options(mc.cores = 1L)
> ##D ncores <- availableCores() - 1      ## ncores = 0
> ##D ncores <- availableCores(omit = 1)  ## ncores = 1
> ##D message(paste("Number of cores to use:", ncores))
> ## End(Not run)
> 
> ## Not run: 
> ##D ## Use 75% of the cores on the system but never more than four
> ##D options(parallelly.availableCores.custom = function() {
> ##D   ncores <- max(parallel::detectCores(), 1L, na.rm = TRUE)
> ##D   ncores <- min(as.integer(0.75 * ncores), 4L)
> ##D   max(1L, ncores)
> ##D })
> ##D message(paste("Number of cores available:", availableCores()))
> ##D 
> ##D ## Use 50% of the cores according to availableCores(), e.g.
> ##D ## allocated by a job scheduler or cgroups.
> ##D ## Note that it is safe to call availableCores() here.
> ##D options(parallelly.availableCores.custom = function() {
> ##D   0.50 * parallelly::availableCores()
> ##D })
> ##D message(paste("Number of cores available:", availableCores()))
> ## End(Not run)
> 
> 
> 
> 
> cleanEx()
> nameEx("availableWorkers")
> ### * availableWorkers
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: availableWorkers
> ### Title: Get Set of Available Workers
> ### Aliases: availableWorkers
> 
> ### ** Examples
> 
> message(paste("Available workers:",
+         paste(sQuote(availableWorkers()), collapse = ", ")))
Available workers: ‘localhost’, ‘localhost’, ‘localhost’, ‘localhost’
> 
> ## Not run: 
> ##D options(mc.cores = 2L)
> ##D message(paste("Available workers:",
> ##D         paste(sQuote(availableWorkers()), collapse = ", ")))
> ## End(Not run)
> 
> ## Not run: 
> ##D ## Always use two workers on host 'n1' and one on host 'n2'
> ##D options(parallelly.availableWorkers.custom = function() {
> ##D   c("n1", "n1", "n2")
> ##D })
> ##D message(paste("Available workers:",
> ##D         paste(sQuote(availableWorkers()), collapse = ", ")))
> ## End(Not run)
> 
> ## Not run: 
> ##D ## A 50% random subset of the available workers.
> ##D ## Note that it is safe to call availableWorkers() here.
> ##D options(parallelly.availableWorkers.custom = function() {
> ##D   workers <- parallelly::availableWorkers()
> ##D   sample(workers, size = 0.50 * length(workers))
> ##D })
> ##D message(paste("Available workers:",
> ##D         paste(sQuote(availableWorkers()), collapse = ", ")))
> ## End(Not run)
> 
> 
> 
> 
> cleanEx()
> nameEx("cloneNode")
> ### * cloneNode
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cloneNode
> ### Title: Clone one or more nodes
> ### Aliases: cloneNode
> 
> ### ** Examples
> 
> 
> 
> 
> 
> cleanEx()
> nameEx("cpuLoad")
> ### * cpuLoad
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cpuLoad
> ### Title: Get the Recent CPU Load
> ### Aliases: cpuLoad
> ### Keywords: internal
> 
> ### ** Examples
> 
> loadavg <- cpuLoad()
> print(loadavg)
 1min  5min 15min 
 1.32  1.62  1.51 
> 
> 
> 
> cleanEx()
> nameEx("freeCores")
> ### * freeCores
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: freeCores
> ### Title: Get the Average Number of Free CPU Cores
> ### Aliases: freeCores
> ### Keywords: internal
> 
> ### ** Examples
> 
> free <- freeCores()
> print(free)
[1] 2
attr(,"loadavg")
 1min  5min 15min 
 1.32  1.62  1.51 
attr(,"maxCores")
system 
     4 
attr(,"memory")
[1] "5min"
attr(,"fraction")
[1] 0.9
> 
> ## Not run: 
> ##D ## Make availableCores() agile to the system load
> ##D options(parallelly.availableCores.custom = function() freeCores())
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("isConnectionValid")
> ### * isConnectionValid
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: isConnectionValid
> ### Title: Checks if a Connection is Valid
> ### Aliases: isConnectionValid connectionId
> 
> ### ** Examples
> 
> ## R represents connections as plain indices
> as.integer(stdin())          ## int 0
[1] 0
> as.integer(stdout())         ## int 1
[1] 1
> as.integer(stderr())         ## int 2
[1] 2
> 
> ## The first three connections always exist and are always valid
> isConnectionValid(stdin())   ## TRUE
[1] TRUE
> connectionId(stdin())        ## 0L
[1] 0
> isConnectionValid(stdout())  ## TRUE
[1] TRUE
> connectionId(stdout())       ## 1L
[1] 1
> isConnectionValid(stderr())  ## TRUE
[1] TRUE
> connectionId(stderr())       ## 2L
[1] 2
> 
> ## Connections cannot be serialized
> con <- file(tempfile(), open = "w")
> x <- list(value = 42, stderr = stderr(), con = con)
> y <- unserialize(serialize(x, connection = NULL))
> isConnectionValid(y$stderr)  ## TRUE
[1] TRUE
> connectionId(y$stderr)       ##  2L
[1] 2
> isConnectionValid(y$con)     ## FALSE with attribute 'reason'
[1] FALSE
attr(,"reason")
[1] "Connection (connection: index=3, description=\"/tmp/Rtmp9415JC/file1aaec111f6c9a\", class=\"file\", mode=\"w\", text=\"text\", opened=\"opened\", can read=\"no\", can write=\"yes\", id=-1) is no longer valid. It differ from the currently registered R connection with the same index 3 (connection: index=3, description=\"/tmp/Rtmp9415JC/file1aaec111f6c9a\", class=\"file\", mode=\"w\", text=\"text\", opened=\"opened\", can read=\"no\", can write=\"yes\", id=202, raw_id=\"<pointer: 0xca>\")"
> connectionId(y$con)          ## -1L
[1] -1
> close(con)
> 
> 
> 
> 
> cleanEx()
> nameEx("isNodeAlive")
> ### * isNodeAlive
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: isNodeAlive
> ### Title: Check whether or not the cluster nodes are alive
> ### Aliases: isNodeAlive
> 
> ### ** Examples
> 
> 
> 
> 
> 
> cleanEx()
> nameEx("killNode")
> ### * killNode
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: killNode
> ### Title: Terminate one or more cluster nodes using process signaling
> ### Aliases: killNode
> 
> ### ** Examples
> 
> ## Don't show: 
> if (.Platform$OS.type != "windows" || interactive()) {
+ ## End(Don't show)
+ cl <- makeClusterPSOCK(2)
+ print(isNodeAlive(cl))  ## [1] TRUE TRUE
+ 
+ res <- killNode(cl)
+ print(res)
+ 
+ ## It might take a moment before the background
+ ## workers are shutdown after having been signaled
+ Sys.sleep(1.0)
+ 
+ print(isNodeAlive(cl))  ## [1] FALSE FALSE
+ ## Don't show: 
+ }
[1] TRUE TRUE
[1] TRUE TRUE
[1] TRUE TRUE
> ## End(Don't show)
> 
> 
> 
> 
> cleanEx()
> nameEx("makeClusterMPI")
> ### * makeClusterMPI
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: makeClusterMPI
> ### Title: Create a Message Passing Interface (MPI) Cluster of R Workers
> ###   for Parallel Processing
> ### Aliases: makeClusterMPI
> 
> ### ** Examples
> 
> cleanEx()
> nameEx("makeClusterPSOCK")
> ### * makeClusterPSOCK
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: makeClusterPSOCK
> ### Title: Create a PSOCK Cluster of R Workers for Parallel Processing
> ### Aliases: makeClusterPSOCK makeNodePSOCK
> 
> ### ** Examples
> 
> ## NOTE: Drop 'dryrun = TRUE' below in order to actually connect.  Add
> ## 'verbose = TRUE' if you run into problems and need to troubleshoot.
> 
> ## ---------------------------------------------------------------
> ## Section 1. Setting up parallel workers on the local machine
> ## ---------------------------------------------------------------
> ## EXAMPLE: Two workers on the local machine
> workers <- c("localhost", "localhost")
> cl <- makeClusterPSOCK(workers, dryrun = TRUE, quiet = TRUE)
> 
> 
> ## EXAMPLE: Launch 124 workers on MS Windows 10, where half are
> ## running on CPU Group #0 and half on CPU Group #1.  
> ## (https://lovickconsulting.com/2021/11/18/
> ##  running-r-clusters-on-an-amd-threadripper-3990x-in-windows-10-2/)
> ncores <- 124
> cpu_groups <- c(0, 1)
> cl <- lapply(cpu_groups, FUN = function(cpu_group) {
+     parallelly::makeClusterPSOCK(ncores %/% length(cpu_groups),
+       rscript = I(c(
+         Sys.getenv("COMSPEC"), "/c", "start", "/B",
+         "/NODE", cpu_group, "/AFFINITY", "0xFFFFFFFFFFFFFFFE",
+         "*"
+       )),
+       dryrun = TRUE, quiet = TRUE
+     )
+ })
Warning in for (i in seq_along(cenv$extra)) { :
  closing unused connection 5 (<-localhost:11867)
Warning in for (i in seq_along(cenv$extra)) { :
  closing unused connection 4 (<-localhost:11867)
> ## merge the two 62-node clusters into one with 124 nodes
> cl <- do.call(c, cl)
Warning: The combined cluster contains 61 duplicated nodes
> 
> 
> ## ---------------------------------------------------------------
> ## Section 2. Setting up parallel workers on remote machines
> ## ---------------------------------------------------------------
> ## EXAMPLE: Three remote workers
> ## Setup of three R workers on two remote machines are set up
> workers <- c("n1.remote.org", "n2.remote.org", "n1.remote.org")
> cl <- makeClusterPSOCK(workers, dryrun = TRUE, quiet = TRUE)
> 
> 
> ## EXAMPLE: Two remote workers running on MS Windows.  Because the
> ## remote workers are MS Windows machines, we need to use
> ## rscript_sh = "cmd".
> workers <- c("mswin1.remote.org", "mswin2.remote.org")
> cl <- makeClusterPSOCK(workers, rscript_sh = "cmd", dryrun = TRUE, quiet = TRUE)
> 
> 
> ## EXAMPLE: Local and remote workers
> ## Same setup when the two machines are on the local network and
> ## have identical software setups
> cl <- makeClusterPSOCK(
+   workers,
+   revtunnel = FALSE, homogeneous = TRUE,
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> ## EXAMPLE: Three remote workers 'n1', 'n2', and 'n3' that can only be
> ## accessed via jumphost 'login.remote.org'
> workers <- c("n1", "n2", "n1")
> cl <- makeClusterPSOCK(
+   workers,
+   rshopts = c("-J", "login.remote.org"),
+   homogeneous = FALSE,
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> ## EXAMPLE: Remote worker running on Linux from MS Windows machine
> ## Connect to remote Unix machine 'remote.server.org' on port 2200
> ## as user 'bob' from a MS Windows machine with PuTTY installed.
> ## Using the explicit special rshcmd = "<putty-plink>", will force
> ## makeClusterPSOCK() to search for and use the PuTTY plink software,
> ## preventing it from using other SSH clients on the system search PATH.
> cl <- makeClusterPSOCK(
+   "remote.server.org", user = "bob",
+   rshcmd = "<putty-plink>",
+   rshopts = c("-P", 2200, "-i", "C:/Users/bobby/.ssh/putty.ppk"),
+   dryrun = TRUE, quiet = TRUE
+ )
Warning in find_rshcmd(which = which, must_work = !localMachine && !manual &&  :
  Failed to locate a default SSH client (checked: ‘putty-plink’). Please specify one via argument 'rshcmd'. Will still try with ‘ssh’.
> 
> 
> ## EXAMPLE: Remote workers with specific setup
> ## Setup of remote worker with more detailed control on
> ## authentication and reverse SSH tunneling
> cl <- makeClusterPSOCK(
+   "remote.server.org", user = "johnny",
+   ## Manual configuration of reverse SSH tunneling
+   revtunnel = FALSE,
+   rshopts = c("-v", "-R 11000:gateway:11942"),
+   master = "gateway", port = 11942,
+   ## Run Rscript nicely and skip any startup scripts
+   rscript = c("nice", "/path/to/Rscript"),
+   rscript_args = c("--no-init-file"),
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> ## EXAMPLE: Remote worker running on Linux from RStudio on MS Windows
> ## Connect to remote Unix machine 'remote.server.org' on port 2200
> ## as user 'bob' from a MS Windows machine via RStudio's SSH client.
> ## Using the explicit special rshcmd = "<rstudio-ssh>", will force
> ## makeClusterPSOCK() to use the SSH client that comes with RStudio,
> ## preventing it from using other SSH clients on the system search PATH.
> cl <- makeClusterPSOCK(
+   "remote.server.org:2200", user = "bob", rshcmd = "<rstudio-ssh>",
+   dryrun = TRUE, quiet = TRUE
+ )
Warning in find_rshcmd(which = which, must_work = !localMachine && !manual &&  :
  Failed to locate a default SSH client (checked: ‘rstudio-ssh’). Please specify one via argument 'rshcmd'. Will still try with ‘ssh’.
> 
> 
> ## ---------------------------------------------------------------
> ## Section 3. Setting up parallel workers on HPC cluster
> ## ---------------------------------------------------------------
> ## EXAMPLE: 'Grid Engine' is a high-performance compute (HPC) job
> ## scheduler where one can request compute resources on multiple nodes,
> ## each running multiple cores. Examples of Grid Engine schedulers are
> ## Oracle Grid Engine (formerly Sun Grid Engine), Univa Grid Engine,
> ## and Son of Grid Engine - all commonly referred to as SGE schedulers.
> ## Each SGE cluster may have its own configuration with their own way
> ## of requesting parallel slots. Here are a few examples:
> ##
> ##   ## Request 18 slots on a single host
> ##   qsub -pe smp 18 script.sh
> ##
> ##   ## Request 18 slots on one or more hosts
> ##   qsub -pe mpi 18 script.sh
> ##
> ## This will launch the job script 'script.sh' on one host, while have
> ## reserved in total 18 slots (CPU cores) on this host and possible
> ## other hosts.
> ##
> ## This example shows how to use the SGE command 'qrsh' to launch
> ## 18 parallel workers from R, which is assumed to have been launched
> ## by 'script.sh'.
> cl <- makeClusterPSOCK(
+   availableWorkers(),
+   rshcmd = "qrsh", rshopts = c("-inherit", "-nostdin", "-V"),
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> ## EXAMPLE: The 'Fujitsu Technical Computing Suite' is a high-performance
> ## compute (HPC) job scheduler where one can request compute resources on
> ## multiple nodes, each running multiple cores.  For example,
> ##
> ##   pjsub -L vnode=3 -L vnode-core=18 script.sh
> ##
> ## reserves 18 cores on three nodes. The job script runs on the first
> ## with enviroment variables set to infer the other nodes, resulting in
> ## availableWorkers() to return 3 * 18 workers. When the HPC environment
> ## does not support SSH between compute nodes, one can use the 'pjrsh'
> ## command to launch the parallel workers.
> cl <- makeClusterPSOCK(
+   availableWorkers(),
+   rshcmd = "pjrsh",
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> 
> ## ---------------------------------------------------------------
> ## Section 4. Setting up remote parallel workers in the cloud
> ## ---------------------------------------------------------------
> ## EXAMPLE: Remote worker running on AWS
> ## Launching worker on Amazon AWS EC2 running one of the
> ## Amazon Machine Images (AMI) provided by RStudio
> ## (https://www.louisaslett.com/RStudio_AMI/)
> public_ip <- "1.2.3.4"
> ssh_private_key_file <- "~/.ssh/my-private-aws-key.pem"
> cl <- makeClusterPSOCK(
+   ## Public IP number of EC2 instance
+   public_ip,
+   ## User name (always 'ubuntu')
+   user = "ubuntu",
+   ## Use private SSH key registered with AWS
+   rshopts = c(
+     "-o", "StrictHostKeyChecking=no",
+     "-o", "IdentitiesOnly=yes",
+     "-i", ssh_private_key_file
+   ),
+   ## Set up .libPaths() for the 'ubuntu' user
+   ## and then install the future package
+   rscript_startup = quote(local({
+     p <- Sys.getenv("R_LIBS_USER")
+     dir.create(p, recursive = TRUE, showWarnings = FALSE)
+     .libPaths(p)
+     install.packages("future")
+   })),
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> ## EXAMPLE: Remote worker running on GCE
> ## Launching worker on Google Cloud Engine (GCE) running a
> ## container based VM (with a #cloud-config specification)
> public_ip <- "1.2.3.4"
> user <- "johnny"
> ssh_private_key_file <- "~/.ssh/google_compute_engine"
> cl <- makeClusterPSOCK(
+   ## Public IP number of GCE instance
+   public_ip,
+   ## User name (== SSH key label (sic!))
+   user = user,
+   ## Use private SSH key registered with GCE
+   rshopts = c(
+     "-o", "StrictHostKeyChecking=no",
+     "-o", "IdentitiesOnly=yes",
+     "-i", ssh_private_key_file
+   ),
+   ## Launch Rscript inside Docker container
+   rscript = c(
+     "docker", "run", "--net=host", "rocker/r-parallel",
+     "Rscript"
+   ),
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> 
> ## ---------------------------------------------------------------
> ## Section 5. Parallel workers running locally inside virtual
> ## machines, Linux containers, etc.
> ## ---------------------------------------------------------------
> ## EXAMPLE: Two workers running in Docker on the local machine
> ## Setup of 2 Docker workers running rocker/r-parallel
> cl <- makeClusterPSOCK(
+   rep("localhost", times = 2L),
+   ## Launch Rscript inside Docker container
+   rscript = c(
+     "docker", "run", "--net=host", "rocker/r-parallel",
+     "Rscript"
+   ),
+   ## IMPORTANT: Because Docker runs inside a virtual machine (VM) on macOS
+   ## and MS Windows (not Linux), when the R worker tries to connect back to
+   ## the default 'localhost' it will fail, because the main R session is
+   ## not running in the VM, but outside on the host.  To reach the host on
+   ## macOS and MS Windows, make sure to use master = "host.docker.internal"
+   master = if (.Platform$OS.type == "unix") NULL else "host.docker.internal",
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> ## EXAMPLE: Two workers running via Linux container 'rocker/r-parallel' from
> ## DockerHub on the local machine using Apptainer (formerly Singularity)
> cl <- makeClusterPSOCK(
+   rep("localhost", times = 2L),
+   ## Launch Rscript inside Linux container
+   rscript = c(
+     "apptainer", "exec", "docker://rocker/r-parallel",
+     "Rscript"
+   ),
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> ## EXAMPLE: One worker running in udocker on the local machine
> ## Setup of a single udocker.py worker running rocker/r-parallel
> cl <- makeClusterPSOCK(
+   "localhost",
+   ## Launch Rscript inside Docker container (using udocker)
+   rscript = c(
+     "udocker.py", "run", "rocker/r-parallel",
+     "Rscript"
+   ), 
+   ## Manually launch parallel workers
+   ## (need double shQuote():s because udocker.py drops one level)
+   rscript_args = c(
+     "-e", shQuote(shQuote("parallel:::.workRSOCK()"))
+   ),
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> ## EXAMPLE: One worker running in Wine for Linux on the local machine
> ## To install R for MS Windows in Wine, do something like:
> ##   winecfg  # In GUI, set 'Windows version' to 'Windows 10'
> ##   wget https://cran.r-project.org/bin/windows/base/R-4.2.3-win.exe
> ##   wine R-4.2.3-win.exe /SILENT
> ## Prevent packages from being installed to R's system library:
> ##   chmod ugo-w "$HOME/.wine/drive_c/Program Files/R/R-4.2.3/library/"
> ## Verify it works:
> ##   wine "C:/Program Files/R/R-4.2.3/bin/x64/Rscript.exe" --version
> cl <- makeClusterPSOCK(1L,
+   rscript = c(
+     ## Silence Wine warnings
+     "WINEDEBUG=fixme-all",
+     ## Don't pass LC_* and R_LIBS* environments from host to Wine
+     sprintf("%s=", grep("^(LC_|R_LIBS)", names(Sys.getenv()), value = TRUE)),
+     "wine",
+     "C:/Program Files/R/R-4.2.3/bin/x64/Rscript.exe"
+   ),
+   dryrun = TRUE, quiet = TRUE
+ )
> 
> 
> 
> cleanEx()
> nameEx("parallelly.options")
> ### * parallelly.options
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: parallelly.options
> ### Title: Options Used by the 'parallelly' Package
> ### Aliases: parallelly.options parallelly.debug
> ###   parallelly.availableCores.custom parallelly.availableCores.methods
> ###   parallelly.availableCores.min parallelly.availableCores.fallback
> ###   parallelly.availableCores.omit parallelly.availableCores.system
> ###   parallelly.availableWorkers.methods
> ###   parallelly.availableWorkers.custom parallelly.fork.enable
> ###   parallelly.supportsMulticore.disableOn
> ###   parallelly.supportsMulticore.unstable
> ###   R_PARALLELLY_AVAILABLECORES_FALLBACK R_PARALLELLY_AVAILABLECORES_OMIT
> ###   R_PARALLELLY_AVAILABLECORES_SYSTEM R_PARALLELLY_AVAILABLECORES_MIN
> ###   R_PARALLELLY_FORK_ENABLE R_PARALLELLY_SUPPORTSMULTICORE_DISABLEON
> ###   R_PARALLELLY_SUPPORTSMULTICORE_UNSTABLE future.availableCores.custom
> ###   future.availableCores.methods future.availableCores.fallback
> ###   future.availableCores.system future.availableWorkers.methods
> ###   future.availableWorkers.custom future.fork.enable
> ###   future.supportsMulticore.unstable R_FUTURE_AVAILABLECORES_FALLBACK
> ###   R_FUTURE_AVAILABLECORES_SYSTEM R_FUTURE_FORK_ENABLE
> ###   R_FUTURE_SUPPORTSMULTICORE_UNSTABLE
> ###   parallelly.makeNodePSOCK.setup_strategy
> ###   parallelly.makeNodePSOCK.validate
> ###   parallelly.makeNodePSOCK.connectTimeout
> ###   parallelly.makeNodePSOCK.timeout parallelly.makeNodePSOCK.useXDR
> ###   parallelly.makeNodePSOCK.socketOptions
> ###   parallelly.makeNodePSOCK.rshcmd parallelly.makeNodePSOCK.rshopts
> ###   parallelly.makeNodePSOCK.tries parallelly.makeNodePSOCK.tries.delay
> ###   R_PARALLELLY_MAKENODEPSOCK_SETUP_STRATEGY
> ###   R_PARALLELLY_MAKENODEPSOCK_VALIDATE
> ###   R_PARALLELLY_MAKENODEPSOCK_CONNECTTIMEOUT
> ###   R_PARALLELLY_MAKENODEPSOCK_TIMEOUT R_PARALLELLY_MAKENODEPSOCK_USEXDR
> ###   R_PARALLELLY_MAKENODEPSOCK_SOCKETOPTIONS
> ###   R_PARALLELLY_MAKENODEPSOCK_RSHCMD R_PARALLELLY_MAKENODEPSOCK_RSHOPTS
> ###   R_PARALLELLY_MAKENODEPSOCK_TRIES
> ###   R_PARALLELLY_MAKENODEPSOCK_TRIES_DELAY
> 
> ### ** Examples
> 
> # Set an R option:
> options(parallelly.availableCores.fallback = 1L)
> 
> 
> 
> 
> 
> cleanEx()
> nameEx("supportsMulticore")
> ### * supportsMulticore
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: supportsMulticore
> ### Title: Check If Forked Processing ("multicore") is Supported
> ### Aliases: supportsMulticore
> 
> ### ** Examples
> 
> ## Check whether or not forked processing is supported
> supportsMulticore()
[1] TRUE
> 
> 
> 
> 
> ### * <FOOTER>
> ###
> cleanEx()
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  0.308 0.026 1.881 0.306 0.335 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
