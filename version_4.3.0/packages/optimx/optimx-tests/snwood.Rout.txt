
R version 4.3.0 (2023-04-21) -- "Already Tomorrow"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> require(optimx)
Loading required package: optimx
> #Example: Wood function
> #
> wood.f <- function(x){
+   res <- 100*(x[1]^2-x[2])^2+(1-x[1])^2+90*(x[3]^2-x[4])^2+(1-x[3])^2+
+     10.1*((1-x[2])^2+(1-x[4])^2)+19.8*(1-x[2])*(1-x[4])
+   return(res)
+ }
> #gradient:
> wood.g <- function(x){
+   g1 <- 400*x[1]^3-400*x[1]*x[2]+2*x[1]-2
+   g2 <- -200*x[1]^2+220.2*x[2]+19.8*x[4]-40
+   g3 <- 360*x[3]^3-360*x[3]*x[4]+2*x[3]-2
+   g4 <- -180*x[3]^2+200.2*x[4]+19.8*x[2]-40
+   return(c(g1,g2,g3,g4))
+ }
> #hessian:
> wood.h <- function(x){
+   h11 <- 1200*x[1]^2-400*x[2]+2;    h12 <- -400*x[1]; h13 <- h14 <- 0
+   h22 <- 220.2; h23 <- 0;    h24 <- 19.8
+   h33 <- 1080*x[3]^2-360*x[4]+2;    h34 <- -360*x[3]
+   h44 <- 200.2
+   H <- matrix(c(h11,h12,h13,h14,h12,h22,h23,h24,
+                 h13,h23,h33,h34,h14,h24,h34,h44),ncol=4)
+   return(H)
+ }
> 
> wood.fgh <- function(x){
+       fval <- wood.f(x)
+       gval <- wood.g(x)
+       hval <- wood.h(x)
+       attr(fval,"gradient") <- gval
+       attr(fval,"hessian")<- hval
+       fval
+ }
>  
> #################################################
> x0 <- c(-3,-1,-3,-1) # Wood standard start
> 
> # library(snewton)
> cat("This FAILS to find minimum\n")
This FAILS to find minimum
> wd <- snewton(x0, fn=wood.f, gr=wood.g, hess=wood.h, control=list(trace=1))
0   1   0   fbest= 19192 
Gradient projection =  -35111.91 
1   2   1   fbest= 1291.439 
Gradient projection =  -1748.969 
2   3   2   fbest= 295.9513 
Gradient projection =  -376.8133 
3   4   3   fbest= 67.68559 
Gradient projection =  -84.58005 
4   5   4   fbest= 17.33661 
Gradient projection =  -14.90304 
5   6   5   fbest= 8.689077 
Gradient projection =  -1.467156 
6   7   6   fbest= 7.892798 
Gradient projection =  -0.03184003 
7   8   7   fbest= 7.876516 
Gradient projection =  0.001054892 
8   9   8   fbest= 7.875255 
Gradient projection =  0.4054431 
9   13   9   fbest= 7.872773 
Gradient projection =  -0.01694465 
10   14   10   fbest= 7.865633 
Gradient projection =  -0.04328606 
11   15   11   fbest= 7.83484 
Gradient projection =  -0.2624784 
12   18   12   fbest= 7.824584 
Gradient projection =  -0.2491789 
13   20   13   fbest= 7.800297 
Gradient projection =  -0.1497639 
14   21   14   fbest= 7.692242 
Gradient projection =  -0.4213491 
15   23   15   fbest= 7.6193 
Gradient projection =  -0.3589344 
16   25   16   fbest= 7.553482 
Gradient projection =  -0.4765439 
17   27   17   fbest= 7.466637 
Gradient projection =  -0.5791609 
18   29   18   fbest= 7.36127 
Gradient projection =  -0.6791919 
19   31   19   fbest= 7.237694 
Gradient projection =  -0.7851201 
20   33   20   fbest= 7.094844 
Gradient projection =  -0.8943914 
21   35   21   fbest= 6.932114 
Gradient projection =  -1.004506 
22   37   22   fbest= 6.749355 
Gradient projection =  -1.112611 
23   39   23   fbest= 6.54694 
Gradient projection =  -1.21558 
24   41   24   fbest= 6.32581 
Gradient projection =  -1.31008 
25   43   25   fbest= 6.087517 
Gradient projection =  -1.392648 
26   45   26   fbest= 5.834241 
Gradient projection =  -1.459773 
27   47   27   fbest= 5.568808 
Gradient projection =  -1.507982 
28   49   28   fbest= 5.294674 
Gradient projection =  -1.533991 
29   51   29   fbest= 5.015896 
Gradient projection =  -1.534959 
30   53   30   fbest= 4.737046 
Gradient projection =  -1.509 
31   55   31   fbest= 4.463032 
Gradient projection =  -1.456013 
32   57   32   fbest= 4.198769 
Gradient projection =  -1.378712 
33   59   33   fbest= 3.948653 
Gradient projection =  -1.283254 
34   61   34   fbest= 3.715944 
Gradient projection =  -1.178576 
35   63   35   fbest= 3.502264 
Gradient projection =  -1.074274 
36   65   36   fbest= 3.307499 
Gradient projection =  -0.9781538 
37   67   37   fbest= 3.130135 
Gradient projection =  -0.8949017 
38   69   38   fbest= 2.967822 
Gradient projection =  -0.8262399 
39   71   39   fbest= 2.817911 
Gradient projection =  -0.7718522 
40   73   40   fbest= 2.677817 
Gradient projection =  -0.7303443 
41   75   41   fbest= 2.545212 
Gradient projection =  -0.699909 
42   77   42   fbest= 2.418092 
Gradient projection =  -0.6786873 
43   79   43   fbest= 2.294795 
Gradient projection =  -0.6649234 
44   81   44   fbest= 2.173973 
Gradient projection =  -0.6570044 
45   83   45   fbest= 2.054571 
Gradient projection =  -0.6534481 
46   85   46   fbest= 1.935801 
Gradient projection =  -0.6528721 
47   87   47   fbest= 1.817127 
Gradient projection =  -0.6539652 
48   89   48   fbest= 1.698249 
Gradient projection =  -0.6554675 
49   91   49   fbest= 1.579096 
Gradient projection =  -0.6561669 
50   93   50   fbest= 1.459818 
Gradient projection =  -0.6549099 
51   95   51   fbest= 1.340774 
Gradient projection =  -0.6506273 
52   97   52   fbest= 1.222516 
Gradient projection =  -0.6423714 
53   99   53   fbest= 1.105769 
Gradient projection =  -0.6293617 
54   101   54   fbest= 0.9914002 
Gradient projection =  -0.6110329 
55   103   55   fbest= 0.8803785 
Gradient projection =  -0.5870819 
56   105   56   fbest= 0.773727 
Gradient projection =  -0.557506 
57   106   57   fbest= 0.7624271 
Gradient projection =  -1.016074 
58   107   58   fbest= 0.2213491 
Gradient projection =  -0.4245304 
59   109   59   fbest= 0.1464941 
Gradient projection =  -0.2105171 
60   110   60   fbest= 0.1177979 
Gradient projection =  -0.2209695 
61   111   61   fbest= 0.004807252 
Gradient projection =  -0.009211707 
62   112   62   fbest= 0.000297515 
Gradient projection =  -0.0005929099 
63   113   63   fbest= 1.028332e-07 
Gradient projection =  -2.056065e-07 
64   114   64   fbest= 1.604976e-13 
Gradient projection =  -3.209951e-13 
65   115   65   fbest= 8.588487e-26 
Gradient projection =  -1.666568e-25 
66   116   66   fbest= 2.156548e-29 
Gradient projection =  -5.332521e-29 
67   117   67   fbest= 1.011344e-28 
Gradient projection =  -8.318836e-28 
68   118   68   fbest= 1.194077e-28 
Gradient projection =  -3.718689e-28 
69   119   69   fbest= 1.142616e-29 
Gradient projection =  -5.482682e-29 
No progress before linesearch! 
> print(wd)
$par
[1] 1 1 1 1

$value
[1] 1.142616e-29

$grad
[1] -2.442491e-15 -7.105427e-15  3.108624e-15  0.000000e+00

$Hess
     [,1]   [,2] [,3]   [,4]
[1,]  802 -400.0    0    0.0
[2,] -400  220.2    0   19.8
[3,]    0    0.0  722 -360.0
[4,]    0   19.8 -360  200.2

$counts
$counts$niter
[1] 70

$counts$nfn
[1] 119

$counts$ngr
[1] 70

$counts$nhess
[1] 70


$convcode
[1] 92

$message
[1] "No progress before linesearch!"

> cat("  with optimr\n")
  with optimr
> wdo <- optimr(x0, fn=wood.f, gr=wood.g, hess=wood.h, method="snewton", control=list(trace=1))
Parameter scaling:[1] 1 1 1 1
0   1   0   fbest= 19192 
Gradient projection =  -35111.91 
1   2   1   fbest= 1291.439 
Gradient projection =  -1748.969 
2   3   2   fbest= 295.9513 
Gradient projection =  -376.8133 
3   4   3   fbest= 67.68559 
Gradient projection =  -84.58005 
4   5   4   fbest= 17.33661 
Gradient projection =  -14.90304 
5   6   5   fbest= 8.689077 
Gradient projection =  -1.467156 
6   7   6   fbest= 7.892798 
Gradient projection =  -0.03184003 
7   8   7   fbest= 7.876516 
Gradient projection =  0.001054892 
8   9   8   fbest= 7.875255 
Gradient projection =  0.4054431 
9   13   9   fbest= 7.872773 
Gradient projection =  -0.01694465 
10   14   10   fbest= 7.865633 
Gradient projection =  -0.04328606 
11   15   11   fbest= 7.83484 
Gradient projection =  -0.2624784 
12   18   12   fbest= 7.824584 
Gradient projection =  -0.2491789 
13   20   13   fbest= 7.800297 
Gradient projection =  -0.1497639 
14   21   14   fbest= 7.692242 
Gradient projection =  -0.4213491 
15   23   15   fbest= 7.6193 
Gradient projection =  -0.3589344 
16   25   16   fbest= 7.553482 
Gradient projection =  -0.4765439 
17   27   17   fbest= 7.466637 
Gradient projection =  -0.5791609 
18   29   18   fbest= 7.36127 
Gradient projection =  -0.6791919 
19   31   19   fbest= 7.237694 
Gradient projection =  -0.7851201 
20   33   20   fbest= 7.094844 
Gradient projection =  -0.8943914 
21   35   21   fbest= 6.932114 
Gradient projection =  -1.004506 
22   37   22   fbest= 6.749355 
Gradient projection =  -1.112611 
23   39   23   fbest= 6.54694 
Gradient projection =  -1.21558 
24   41   24   fbest= 6.32581 
Gradient projection =  -1.31008 
25   43   25   fbest= 6.087517 
Gradient projection =  -1.392648 
26   45   26   fbest= 5.834241 
Gradient projection =  -1.459773 
27   47   27   fbest= 5.568808 
Gradient projection =  -1.507982 
28   49   28   fbest= 5.294674 
Gradient projection =  -1.533991 
29   51   29   fbest= 5.015896 
Gradient projection =  -1.534959 
30   53   30   fbest= 4.737046 
Gradient projection =  -1.509 
31   55   31   fbest= 4.463032 
Gradient projection =  -1.456013 
32   57   32   fbest= 4.198769 
Gradient projection =  -1.378712 
33   59   33   fbest= 3.948653 
Gradient projection =  -1.283254 
34   61   34   fbest= 3.715944 
Gradient projection =  -1.178576 
35   63   35   fbest= 3.502264 
Gradient projection =  -1.074274 
36   65   36   fbest= 3.307499 
Gradient projection =  -0.9781538 
37   67   37   fbest= 3.130135 
Gradient projection =  -0.8949017 
38   69   38   fbest= 2.967822 
Gradient projection =  -0.8262399 
39   71   39   fbest= 2.817911 
Gradient projection =  -0.7718522 
40   73   40   fbest= 2.677817 
Gradient projection =  -0.7303443 
41   75   41   fbest= 2.545212 
Gradient projection =  -0.699909 
42   77   42   fbest= 2.418092 
Gradient projection =  -0.6786873 
43   79   43   fbest= 2.294795 
Gradient projection =  -0.6649234 
44   81   44   fbest= 2.173973 
Gradient projection =  -0.6570044 
45   83   45   fbest= 2.054571 
Gradient projection =  -0.6534481 
46   85   46   fbest= 1.935801 
Gradient projection =  -0.6528721 
47   87   47   fbest= 1.817127 
Gradient projection =  -0.6539652 
48   89   48   fbest= 1.698249 
Gradient projection =  -0.6554675 
49   91   49   fbest= 1.579096 
Gradient projection =  -0.6561669 
50   93   50   fbest= 1.459818 
Gradient projection =  -0.6549099 
51   95   51   fbest= 1.340774 
Gradient projection =  -0.6506273 
52   97   52   fbest= 1.222516 
Gradient projection =  -0.6423714 
53   99   53   fbest= 1.105769 
Gradient projection =  -0.6293617 
54   101   54   fbest= 0.9914002 
Gradient projection =  -0.6110329 
55   103   55   fbest= 0.8803785 
Gradient projection =  -0.5870819 
56   105   56   fbest= 0.773727 
Gradient projection =  -0.557506 
57   106   57   fbest= 0.7624271 
Gradient projection =  -1.016074 
58   107   58   fbest= 0.2213491 
Gradient projection =  -0.4245304 
59   109   59   fbest= 0.1464941 
Gradient projection =  -0.2105171 
60   110   60   fbest= 0.1177979 
Gradient projection =  -0.2209695 
61   111   61   fbest= 0.004807252 
Gradient projection =  -0.009211707 
62   112   62   fbest= 0.000297515 
Gradient projection =  -0.0005929099 
63   113   63   fbest= 1.028332e-07 
Gradient projection =  -2.056065e-07 
64   114   64   fbest= 1.604976e-13 
Gradient projection =  -3.209951e-13 
65   115   65   fbest= 8.588487e-26 
Gradient projection =  -1.666568e-25 
66   116   66   fbest= 2.156548e-29 
Gradient projection =  -5.332521e-29 
67   117   67   fbest= 1.011344e-28 
Gradient projection =  -8.318836e-28 
68   118   68   fbest= 1.194077e-28 
Gradient projection =  -3.718689e-28 
69   119   69   fbest= 1.142616e-29 
Gradient projection =  -5.482682e-29 
No progress before linesearch! 
> print(wdo)
$par
[1] 1 1 1 1

$value
[1] 1.142616e-29

$counts
[1] 119  70

$convergence
[1] 92

$message
[1] "No progress before linesearch!"

attr(,"gradient")
[1] -2.442491e-15 -7.105427e-15  3.108624e-15  0.000000e+00
> 
> wdm <- snewtonm(x0, fn=wood.f, gr=wood.g, hess=wood.h, control=list(trace=1))
  f0= 19192   at  [1] -3 -1 -3 -1
1   1   0  fbest= 19192 
 lambda = 0.0001220703   fval= 1291.437 
2   2   1  fbest= 1291.437 
 lambda = 1.831055e-05   fval= 295.9512 
3   3   2  fbest= 295.9512 
 lambda = 2.746582e-06   fval= 67.68561 
4   4   3  fbest= 67.68561 
 lambda = 4.119873e-07   fval= 17.33662 
5   5   4  fbest= 17.33662 
 lambda = 6.17981e-08   fval= 8.689077 
6   6   5  fbest= 8.689077 
 lambda = 9.269714e-09   fval= 7.892798 
7   7   6  fbest= 7.892798 
 lambda = 1.390457e-09   fval= 7.876516 
8   8   7  fbest= 7.876516 
 lambda = 2.085686e-10   fval= 7.87719 
 lambda = 0.001220703   fval= 7.877199 
 lambda = 0.01220703   fval= 7.877309 
 lambda = 0.1220703   fval= 8.086469 
 lambda = 1.220703   fval= 7.876389 
13   13   8  fbest= 7.876389 
 lambda = 0.1831055   fval= 7.874695 
14   14   9  fbest= 7.874695 
 lambda = 0.02746582   fval= 7.86493 
15   15   10  fbest= 7.86493 
 lambda = 0.004119873   fval= 7.960279 
 lambda = 0.04119873   fval= 7.880975 
 lambda = 0.4119873   fval= 7.852834 
18   18   11  fbest= 7.852834 
 lambda = 0.0617981   fval= 2687428 
 lambda = 0.617981   fval= 7.83364 
20   20   12  fbest= 7.83364 
 lambda = 0.09269714   fval= 10.04037 
 lambda = 0.9269714   fval= 7.80479 
22   22   13  fbest= 7.80479 
 lambda = 0.1390457   fval= 187.1183 
 lambda = 1.390457   fval= 7.760677 
24   24   14  fbest= 7.760677 
 lambda = 0.2085686   fval= 39.79228 
 lambda = 2.085686   fval= 7.694405 
26   26   15  fbest= 7.694405 
 lambda = 0.3128529   fval= 71.47948 
 lambda = 3.128529   fval= 7.593398 
28   28   16  fbest= 7.593398 
 lambda = 0.4692793   fval= 29.76551 
 lambda = 4.692793   fval= 7.440723 
30   30   17  fbest= 7.440723 
 lambda = 0.7039189   fval= 15.78816 
 lambda = 7.039189   fval= 7.220427 
32   32   18  fbest= 7.220427 
 lambda = 1.055878   fval= 9.872978 
 lambda = 10.55878   fval= 6.945088 
34   34   19  fbest= 6.945088 
 lambda = 1.583818   fval= 8.791386 
 lambda = 15.83818   fval= 6.677653 
36   36   20  fbest= 6.677653 
 lambda = 2.375726   fval= 8.252204 
 lambda = 23.75726   fval= 6.477078 
38   38   21  fbest= 6.477078 
 lambda = 3.56359   fval= 6.868378 
 lambda = 35.6359   fval= 6.345119 
40   40   22  fbest= 6.345119 
 lambda = 5.345384   fval= 6.009281 
41   41   23  fbest= 6.009281 
 lambda = 0.8018077   fval= 5.126601 
42   42   24  fbest= 5.126601 
 lambda = 0.1202711   fval= 14.61183 
 lambda = 1.202711   fval= 5.0219 
44   44   25  fbest= 5.0219 
 lambda = 0.1804067   fval= 3.691554 
45   45   26  fbest= 3.691554 
 lambda = 0.02706101   fval= 5.793891 
 lambda = 0.2706101   fval= 4.183769 
 lambda = 2.706101   fval= 3.31558 
48   48   27  fbest= 3.31558 
 lambda = 0.4059151   fval= 3.195488 
49   49   28  fbest= 3.195488 
 lambda = 0.06088727   fval= 2.456016 
50   50   29  fbest= 2.456016 
 lambda = 0.00913309   fval= 19.57353 
 lambda = 0.0913309   fval= 15.43651 
 lambda = 0.913309   fval= 3.729664 
 lambda = 9.13309   fval= 2.268927 
54   54   30  fbest= 2.268927 
 lambda = 1.369964   fval= 5.355945 
 lambda = 13.69964   fval= 2.115327 
56   56   31  fbest= 2.115327 
 lambda = 2.054945   fval= 10.1671 
 lambda = 20.54945   fval= 1.988546 
58   58   32  fbest= 1.988546 
 lambda = 3.082418   fval= 10.44886 
 lambda = 30.82418   fval= 1.889195 
60   60   33  fbest= 1.889195 
 lambda = 4.623627   fval= 5.077595 
 lambda = 46.23627   fval= 1.815587 
62   62   34  fbest= 1.815587 
 lambda = 6.935441   fval= 2.080748 
 lambda = 69.35441   fval= 1.763332 
64   64   35  fbest= 1.763332 
 lambda = 10.40316   fval= 1.492527 
65   65   36  fbest= 1.492527 
 lambda = 1.560474   fval= 1.124371 
66   66   37  fbest= 1.124371 
 lambda = 0.2340711   fval= 1.485749 
 lambda = 2.340711   fval= 0.9137214 
68   68   38  fbest= 0.9137214 
 lambda = 0.3511067   fval= 0.5280731 
69   69   39  fbest= 0.5280731 
 lambda = 0.052666   fval= 1.525743 
 lambda = 0.52666   fval= 0.6554124 
 lambda = 5.2666   fval= 0.3958719 
72   72   40  fbest= 0.3958719 
 lambda = 0.78999   fval= 0.2303101 
73   73   41  fbest= 0.2303101 
 lambda = 0.1184985   fval= 0.08047485 
74   74   42  fbest= 0.08047485 
 lambda = 0.01777478   fval= 0.03236792 
75   75   43  fbest= 0.03236792 
 lambda = 0.002666216   fval= 0.001857496 
76   76   44  fbest= 0.001857496 
 lambda = 0.0003999324   fval= 4.536306e-05 
77   77   45  fbest= 4.536306e-05 
 lambda = 5.998987e-05   fval= 6.363907e-09 
78   78   46  fbest= 6.363907e-09 
 lambda = 8.99848e-06   fval= 6.401255e-16 
79   79   47  fbest= 6.401255e-16 
 lambda = 1.349772e-06   fval= 3.086122e-28 
80   80   48  fbest= 3.086122e-28 
 lambda = 2.024658e-07   fval= 6.819949e-29 
81   81   49  fbest= 6.819949e-29 
 lambda = 3.036987e-08   fval= 7.345355e-28 
 lambda = 0.001220703   fval= 7.36446e-28 
 lambda = 0.01220703   fval= 7.128702e-28 
 lambda = 0.1220703   fval= 5.082224e-28 
 lambda = 1.220703   fval= 4.924341e-29 
86   86   50  fbest= 4.924341e-29 
 lambda = 0.1831055   fval= 1.246154e-30 
87   87   51  fbest= 1.246154e-30 
 lambda = 0.02746582   fval= 1.138918e-29 
 lambda = 0.2746582   fval= 1.138918e-29 
 lambda = 2.746582   fval= 1.138918e-29 
 lambda = 27.46582   fval= 5.428349e-30 
> print(wdm)
$par
[1] 1 1 1 1

$value
[1] 1.246154e-30

$grad
[1]  0.000000e+00 -1.421085e-14 -2.220446e-16 -1.421085e-14

$Hess
     [,1]   [,2] [,3]   [,4]
[1,]  802 -400.0    0    0.0
[2,] -400  220.2    0   19.8
[3,]    0    0.0  722 -360.0
[4,]    0   19.8 -360  200.2

$counts
$counts$niter
[1] 92

$counts$nfn
[1] 91

$counts$ngr
[1] 52

$counts$nhess
[1] 52


$convcode
[1] 0

$message
[1] "snewtonm: Normal exit"

> 
> cat("\n\n nlm() gives similar results\n")


 nlm() gives similar results
> t1nlm <- nlm(wood.fgh, x0, print.level=1)
iteration = 0
Step:
[1] 0 0 0 0
Parameter:
[1] -3 -1 -3 -1
Function Value
[1] 19192
Gradient:
[1] -12008  -2080 -10808  -1880

iteration = 100
Parameter:
[1] -1.0316067  1.0740774 -0.9012710  0.8239815
Function Value
[1] 7.874467
Gradient:
[1]  0.007517820 -0.015797320 -0.008937001  0.015745111

Iteration limit exceeded.  Algorithm failed.

> print(t1nlm)
$minimum
[1] 7.874467

$estimate
[1] -1.0316067  1.0740774 -0.9012710  0.8239815

$gradient
[1]  0.007517820 -0.015797320 -0.008937001  0.015745111

$code
[1] 4

$iterations
[1] 100

> 
> 
> ## BUT ... it looks like nlminb is NOT using a true Newton-type method
> t1nlminb <- nlminb(x0, wood.f, gradient=wood.g, hessian=wood.h, control=list(trace=1))
  0:     19192.000: -3.00000 -1.00000 -3.00000 -1.00000
  1:     7844.8110: -2.34188 -0.814182 -2.36728 -0.827234
  2:     1216.1133: -1.68443 0.393908 -1.69404 0.313883
  3:     63.588133: -1.45306  1.71905 -1.44613  1.65143
  4:     16.494685: -1.19893  1.31181 -1.19548  1.29854
  5:     8.5754053: -1.04247  1.05440 -1.02968  1.02406
  6:     7.8893787: -0.984105 0.972760 -0.971950 0.949965
  7:     7.8769236: -0.977607 0.965750 -0.960225 0.933163
  8:     7.8762403: -1.00695  1.02307 -0.929896 0.875292
  9:     7.8736524: -1.06370  1.13800 -0.867196 0.759942
 10:     7.8639782: -1.11594  1.25222 -0.798496 0.645011
 11:     7.8548631: -1.13591  1.29937 -0.765236 0.596982
 12:     7.8409865: -1.21945  1.48926 -0.637546 0.403740
 13:     7.7765044: -1.25895  1.59258 -0.545841 0.302611
 14:     7.7110154: -1.29377  1.68164 -0.448823 0.206860
 15:     7.6479639: -1.36018  1.85456 -0.237404 0.0279485
 16:     7.3414193: -1.36613  1.87495 -0.131228 0.0197128
 17:     7.1459204: -1.36939  1.88395 -0.0220586 0.00419477
 18:     6.8499981: -1.37092  1.88810 0.199369 0.00469949
 19:     6.2503936: -1.33300  1.78413 0.360771 0.116495
 20:     5.7947116: -1.29523  1.68459 0.513971 0.245855
 21:     5.3563474: -1.24407  1.55349 0.629984 0.387008
 22:     4.7857877: -1.13048  1.27366 0.840203 0.665704
 23:     4.0497195: -0.992126 0.973269 0.983984 0.954618
 24:     3.5179818: -0.841522 0.692665  1.12885  1.25650
 25:     3.0488024: -0.658857 0.407011  1.24823  1.54704
 26:     2.6325343: -0.500037 0.229669  1.31902  1.73685
 27:     2.3059389: -0.307769 0.0630001  1.38020  1.90295
 28:     1.9350808: -0.174234 0.0178386  1.39533  1.94834
 29:     1.6534354: -0.0296107 -0.0129818  1.40343  1.97124
 30:     1.5716753: 0.234877 -0.00937673  1.40482  1.97512
 31:    0.94438690: 0.306481 0.0937164  1.36921  1.87497
 32:    0.74178203: 0.438677 0.174107  1.34892  1.82029
 33:    0.53974471: 0.526746 0.269899  1.31329  1.72450
 34:    0.40832177: 0.737124 0.500274  1.22372  1.49026
 35:    0.12697466: 0.792936 0.627489  1.16789  1.36128
 36:   0.058109409: 0.874374 0.757557  1.11579  1.24255
 37:   0.014841604: 0.942386 0.883727  1.05723  1.11444
 38:  0.0015171246: 0.983721 0.966104  1.01742  1.03352
 39: 2.9694242e-05: 0.997648 0.995118  1.00255  1.00487
 40: 1.6239262e-08: 0.999951 0.999896  1.00006  1.00010
 41: 5.1701713e-15:  1.00000  1.00000  1.00000  1.00000
 42: 1.4404033e-27:  1.00000  1.00000  1.00000  1.00000
 43: 7.3028059e-28:  1.00000  1.00000  1.00000  1.00000
 44: 4.7923300e-29:  1.00000  1.00000  1.00000  1.00000
 45: 4.7923300e-29:  1.00000  1.00000  1.00000  1.00000
> print(t1nlminb)
$par
[1] 1 1 1 1

$objective
[1] 4.79233e-29

$convergence
[1] 0

$iterations
[1] 45

$evaluations
function gradient 
      56       45 

$message
[1] "X-convergence (3)"

> # and call them from optimx (i.e., test this gives same results)
> 
> t1nlmo <- optimr(x0, wood.f, wood.g, hess=wood.h, method="nlm", control=list(trace=1))
Parameter scaling:[1] 1 1 1 1
iteration = 0
Step:
[1] 0 0 0 0
Parameter:
[1] -3 -1 -3 -1
Function Value
[1] 19192
Gradient:
[1] -12008  -2080 -10808  -1880

iteration = 1
Step:
[1] 0.3031804 7.1764779 0.3366407 6.8648041
Parameter:
[1] -2.696820  6.176478 -2.663359  5.864804
Function Value
[1] 1291.439
Gradient:
[1] -1190.06577   -18.38367 -1185.39530   -20.39885

iteration = 2
Step:
[1]  0.8004660 -3.5411163  0.7835229 -3.3003803
Parameter:
[1] -1.896354  2.635362 -1.879836  2.564424
Function Value
[1] 295.9513
Gradient:
[1] -734.5958 -128.1492 -661.7661 -110.5035

iteration = 3
Step:
[1]  0.3717359 -0.6307749  0.4048288 -0.7541032
Parameter:
[1] -1.524618  2.004587 -1.475008  1.810321
Function Value
[1] 67.68559
Gradient:
[1] -200.12258  -27.63751 -198.93958  -29.49954

iteration = 4
Step:
[1]  0.3094376 -0.6813323  0.2912302 -0.5577128
Parameter:
[1] -1.215180  1.323254 -1.183777  1.252608
Function Value
[1] 17.33661
Gradient:
[1] -78.99793 -19.15032 -67.74657 -15.26670

iteration = 5
Step:
[1]  0.1493372 -0.2198873  0.1651241 -0.2534905
Parameter:
[1] -1.0658430  1.1033671 -1.0186533  0.9991172
Function Value
[1] 8.689077
Gradient:
[1] -18.053415  -4.460318 -18.169516  -4.907877

iteration = 6
Step:
[1]  0.06562338 -0.09986141  0.06090227 -0.07716611
Parameter:
[1] -1.0002196  1.0035057 -0.9577510  0.9219511
Function Value
[1] 7.892798
Gradient:
[1] -2.7736335 -0.8612857 -2.3073614 -0.6676356

iteration = 7
Step:
[1]  0.0036594560 -0.0003950329  0.0170860102 -0.0260521194
Parameter:
[1] -0.9965602  1.0031106 -0.9406650  0.8958990
Function Value
[1] 7.876516
Gradient:
[1] -0.015475627 -0.002678324 -0.139924452 -0.052547714

iteration = 8
Step:
[1] -9.272886e-05  2.263663e-04  5.663846e-04 -6.719679e-04
Parameter:
[1] -0.9966529  1.0033370 -0.9400986  0.8952270
Function Value
[1] 7.876489
Gradient:
[1]  0.001268571 -0.003103114 -0.007948729  0.009148742

iteration = 9
Step:
[1] -0.0002047373  0.0004109509  0.0003134420 -0.0005766157
Parameter:
[1] -0.9968577  1.0037480 -0.9397852  0.8946504
Function Value
[1] 7.87648
Gradient:
[1]  0.002798133 -0.005657908 -0.004343699  0.007909307

iteration = 10
Step:
[1] -0.0002375267  0.0004735367  0.0002815016 -0.0005259364
Parameter:
[1] -0.9970952  1.0042215 -0.9395037  0.8941245
Function Value
[1] 7.876471
Gradient:
[1]  0.003243316 -0.006522071 -0.003897567  0.007216982

iteration = 11
Step:
[1] -0.0002491228  0.0004959998  0.0002741322 -0.0005129949
Parameter:
[1] -0.9973443  1.0047175 -0.9392295  0.8936115
Function Value
[1] 7.876462
Gradient:
[1]  0.003400533 -0.006832277 -0.003794860  0.007040015

iteration = 12
Step:
[1] -0.0002542303  0.0005060686  0.0002736064 -0.0005121416
Parameter:
[1] -0.9975985  1.0052236 -0.9389559  0.8930993
Function Value
[1] 7.876453
Gradient:
[1]  0.003469761 -0.006971354 -0.003787563  0.007028457

iteration = 13
Step:
[1] -0.0002573491  0.0005123395  0.0002751978 -0.0005150559
Parameter:
[1] -0.9978559  1.0057359 -0.9386807  0.8925843
Function Value
[1] 7.876444
Gradient:
[1]  0.003512038 -0.007057990 -0.003809776  0.007068462

iteration = 14
Step:
[1] -0.0002598679  0.0005174676  0.0002774602 -0.0005191630
Parameter:
[1] -0.9981157  1.0062534 -0.9384033  0.8920651
Function Value
[1] 7.876435
Gradient:
[1]  0.003546182 -0.007128845 -0.003841344  0.007124794

iteration = 15
Step:
[1] -0.0002622152  0.0005222726  0.0002799475 -0.0005236685
Parameter:
[1] -0.9983780  1.0067756 -0.9381233  0.8915414
Function Value
[1] 7.876425
Gradient:
[1]  0.003578000 -0.007195243 -0.003876052  0.007186579

iteration = 16
Step:
[1] -0.0002645234  0.0005270081  0.0002825222 -0.0005283274
Parameter:
[1] -0.9986425  1.0073026 -0.9378408  0.8910131
Function Value
[1] 7.876415
Gradient:
[1]  0.003609287 -0.007260685 -0.003911984  0.007250464

iteration = 17
Step:
[1] -0.0002668337  0.0005317526  0.0002851420 -0.0005330645
Parameter:
[1] -0.9989093  1.0078344 -0.9375557  0.8904800
Function Value
[1] 7.876406
Gradient:
[1]  0.003640597 -0.007326257 -0.003948550  0.007315420

iteration = 18
Step:
[1] -0.0002691587  0.0005365308  0.0002877940 -0.0005378568
Parameter:
[1] -0.9991785  1.0083709 -0.9372679  0.8899422
Function Value
[1] 7.876396
Gradient:
[1]  0.003672104 -0.007392298 -0.003985573  0.007381133

iteration = 19
Step:
[1] -0.0002715027  0.0005413505  0.0002904746 -0.0005426977
Parameter:
[1] -0.9994500  1.0089123 -0.9369774  0.8893995
Function Value
[1] 7.876385
Gradient:
[1]  0.003703864 -0.007458917 -0.004023000  0.007447511

iteration = 20
Step:
[1] -0.0002738669  0.0005462146  0.0002931828 -0.0005475853
Parameter:
[1] -0.9997238  1.0094585 -0.9366842  0.8888519
Function Value
[1] 7.876375
Gradient:
[1]  0.003735895 -0.007526153 -0.004060818  0.007514530

iteration = 21
Step:
[1] -0.0002762519  0.0005511241  0.0002959185 -0.0005525196
Parameter:
[1] -1.0000001  1.0100096 -0.9363883  0.8882994
Function Value
[1] 7.876364
Gradient:
[1]  0.003768205 -0.007594023 -0.004099026  0.007582188

iteration = 22
Step:
[1] -0.0002786581  0.0005560799  0.0002986820 -0.0005575007
Parameter:
[1] -1.0002788  1.0105657 -0.9360896  0.8877419
Function Value
[1] 7.876354
Gradient:
[1]  0.003800798 -0.007662537 -0.004137629  0.007650488

iteration = 23
Step:
[1] -0.0002810858  0.0005610825  0.0003014734 -0.0005625292
Parameter:
[1] -1.0005598  1.0111268 -0.9357881  0.8871793
Function Value
[1] 7.876343
Gradient:
[1]  0.003833677 -0.007731703 -0.004176629  0.007719436

iteration = 24
Step:
[1] -0.0002835350  0.0005661323  0.0003042933 -0.0005676054
Parameter:
[1] -1.0008434  1.0116929 -0.9354838  0.8866117
Function Value
[1] 7.876331
Gradient:
[1]  0.003866846 -0.007801527 -0.004216031  0.007789040

iteration = 25
Step:
[1] -0.0002860061  0.0005712301  0.0003071418 -0.0005727300
Parameter:
[1] -1.0011294  1.0122641 -0.9351767  0.8860390
Function Value
[1] 7.87632
Gradient:
[1]  0.003900306 -0.007872018 -0.004255842  0.007859305

iteration = 26
Step:
[1] -0.0002884993  0.0005763761  0.0003100194 -0.0005779035
Parameter:
[1] -1.0014179  1.0128405 -0.9348667  0.8854611
Function Value
[1] 7.876309
Gradient:
[1]  0.003934061 -0.007943182 -0.004296065  0.007930241

iteration = 27
Step:
[1] -0.0002910148  0.0005815710  0.0003129264 -0.0005831263
Parameter:
[1] -1.0017089  1.0134221 -0.9345537  0.8848780
Function Value
[1] 7.876297
Gradient:
[1]  0.003968114 -0.008015028 -0.004336705  0.008001853

iteration = 28
Step:
[1] -0.0002935527  0.0005868154  0.0003158632 -0.0005883990
Parameter:
[1] -1.0020025  1.0140089 -0.9342379  0.8842896
Function Value
[1] 7.876285
Gradient:
[1]  0.004002468 -0.008087562 -0.004377769  0.008074149

iteration = 29
Step:
[1] -0.0002961134  0.0005921097  0.0003188300 -0.0005937223
Parameter:
[1] -1.0022986  1.0146010 -0.9339191  0.8836959
Function Value
[1] 7.876273
Gradient:
[1]  0.004037125 -0.008160793 -0.004419261  0.008147137

iteration = 30
Step:
[1] -0.0002986971  0.0005974545  0.0003218274 -0.0005990965
Parameter:
[1] -1.0025973  1.0151985 -0.9335972  0.8830968
Function Value
[1] 7.87626
Gradient:
[1]  0.004072089 -0.008234728 -0.004461187  0.008220824

iteration = 31
Step:
[1] -0.0003013039  0.0006028503  0.0003248556 -0.0006045224
Parameter:
[1] -1.0028986  1.0158013 -0.9332724  0.8824922
Function Value
[1] 7.876247
Gradient:
[1]  0.004107363 -0.008309374 -0.004503552  0.008295219

iteration = 32
Step:
[1] -0.0003039341  0.0006082978  0.0003279150 -0.0006100005
Parameter:
[1] -1.0032025  1.0164096 -0.9329445  0.8818822
Function Value
[1] 7.876235
Gradient:
[1]  0.004142949 -0.008384741 -0.004546361  0.008370329

iteration = 33
Step:
[1] -0.0003065881  0.0006137974  0.0003310061 -0.0006155313
Parameter:
[1] -1.0035091  1.0170234 -0.9326135  0.8812667
Function Value
[1] 7.876221
Gradient:
[1]  0.004178851 -0.008460836 -0.004589621  0.008446162

iteration = 34
Step:
[1] -0.0003092659  0.0006193498  0.0003341293 -0.0006211154
Parameter:
[1] -1.0038184  1.0176428 -0.9322793  0.8806456
Function Value
[1] 7.876208
Gradient:
[1]  0.004215071 -0.008537667 -0.004633337  0.008522726

iteration = 35
Step:
[1] -0.0003119678  0.0006249556  0.0003372848 -0.0006267535
Parameter:
[1] -1.0041303  1.0182677 -0.9319420  0.8800188
Function Value
[1] 7.876194
Gradient:
[1]  0.004251614 -0.008615242 -0.004677516  0.008600030

iteration = 36
Step:
[1] -0.0003146942  0.0006306153  0.0003404732 -0.0006324462
Parameter:
[1] -1.0044450  1.0188983 -0.9316016  0.8793864
Function Value
[1] 7.876181
Gradient:
[1]  0.004288482 -0.008693571 -0.004722162  0.008678081

iteration = 37
Step:
[1] -0.0003174451  0.0006363296  0.0003436948 -0.0006381941
Parameter:
[1] -1.0047625  1.0195347 -0.9312579  0.8787482
Function Value
[1] 7.876166
Gradient:
[1]  0.004325679 -0.008772661 -0.004767283  0.008756889

iteration = 38
Step:
[1] -0.0003202210  0.0006420991  0.0003469502 -0.0006439977
Parameter:
[1] -1.0050827  1.0201768 -0.9309109  0.8781042
Function Value
[1] 7.876152
Gradient:
[1]  0.004363207 -0.008852522 -0.004812883  0.008836462

iteration = 39
Step:
[1] -0.0003230220  0.0006479244  0.0003502396 -0.0006498578
Parameter:
[1] -1.0054057  1.0208247 -0.9305607  0.8774543
Function Value
[1] 7.876137
Gradient:
[1]  0.004401071 -0.008933163 -0.004858971  0.008916809

iteration = 40
Step:
[1] -0.0003258484  0.0006538061  0.0003535635 -0.0006557750
Parameter:
[1] -1.0057316  1.0214785 -0.9302071  0.8767986
Function Value
[1] 7.876122
Gradient:
[1]  0.004439273 -0.009014591 -0.004905551  0.008997938

iteration = 41
Step:
[1] -0.0003287005  0.0006597449  0.0003569225 -0.0006617500
Parameter:
[1] -1.0060603  1.0221382 -0.9298502  0.8761368
Function Value
[1] 7.876107
Gradient:
[1]  0.004477817 -0.009096817 -0.004952631  0.009079859

iteration = 42
Step:
[1] -0.0003315786  0.0006657415  0.0003603168 -0.0006677834
Parameter:
[1] -1.0063918  1.0228040 -0.9294899  0.8754690
Function Value
[1] 7.876092
Gradient:
[1]  0.004516707 -0.009179850 -0.005000217  0.009162581

iteration = 43
Step:
[1] -0.0003344828  0.0006717964  0.0003637471 -0.0006738759
Parameter:
[1] -1.0067263  1.0234758 -0.9291261  0.8747952
Function Value
[1] 7.876076
Gradient:
[1]  0.004555946 -0.009263700 -0.005048315  0.009246113

iteration = 44
Step:
[1] -0.0003374135  0.0006779105  0.0003672137 -0.0006800281
Parameter:
[1] -1.0070637  1.0241537 -0.9287589  0.8741151
Function Value
[1] 7.87606
Gradient:
[1]  0.004595537 -0.009348375 -0.005096934  0.009330464

iteration = 45
Step:
[1] -0.0003403710  0.0006840843  0.0003707172 -0.0006862409
Parameter:
[1] -1.0074041  1.0248378 -0.9283882  0.8734289
Function Value
[1] 7.876044
Gradient:
[1]  0.004635485 -0.009433886 -0.005146079  0.009415645

iteration = 46
Step:
[1] -0.0003433556  0.0006903185  0.0003742580 -0.0006925149
Parameter:
[1] -1.0077475  1.0255281 -0.9280139  0.8727364
Function Value
[1] 7.876027
Gradient:
[1]  0.004675793 -0.009520242 -0.005195758  0.009501665

iteration = 47
Step:
[1] -0.0003463675  0.0006966140  0.0003778365 -0.0006988507
Parameter:
[1] -1.0080938  1.0262247 -0.9276361  0.8720375
Function Value
[1] 7.87601
Gradient:
[1]  0.004716465 -0.009607454 -0.005245978  0.009588534

iteration = 48
Step:
[1] -0.0003494070  0.0007029713  0.0003814534 -0.0007052493
Parameter:
[1] -1.0084432  1.0269277 -0.9272546  0.8713323
Function Value
[1] 7.875993
Gradient:
[1]  0.004757504 -0.009695531 -0.005296747  0.009676262

iteration = 49
Step:
[1] -0.0003524744  0.0007093912  0.0003851092 -0.0007117112
Parameter:
[1] -1.0087957  1.0276371 -0.9268695  0.8706206
Function Value
[1] 7.875975
Gradient:
[1]  0.004798915 -0.009784485 -0.005348071  0.009764860

iteration = 50
Step:
[1] -0.0003555701  0.0007158745  0.0003888042 -0.0007182373
Parameter:
[1] -1.0091513  1.0283529 -0.9264807  0.8699023
Function Value
[1] 7.875958
Gradient:
[1]  0.004840701 -0.009874326 -0.005399959  0.009854337

iteration = 51
Step:
[1] -0.0003586943  0.0007224220  0.0003925391 -0.0007248283
Parameter:
[1] -1.0095100  1.0290754 -0.9260882  0.8691775
Function Value
[1] 7.875939
Gradient:
[1]  0.004882867 -0.009965065 -0.005452419  0.009944704

iteration = 52
Step:
[1] -0.0003618473  0.0007290343  0.0003963145 -0.0007314851
Parameter:
[1] -1.0098718  1.0298044 -0.9256919  0.8684460
Function Value
[1] 7.875921
Gradient:
[1]  0.004925416 -0.010056712 -0.005505458  0.010035973

iteration = 53
Step:
[1] -0.0003650296  0.0007357122  0.0004001307 -0.0007382083
Parameter:
[1] -1.0102368  1.0305401 -0.9252918  0.8677078
Function Value
[1] 7.875902
Gradient:
[1]  0.004968353 -0.010149278 -0.005559084  0.010128154

iteration = 54
Step:
[1] -0.0003682412  0.0007424566  0.0004039885 -0.0007449989
Parameter:
[1] -1.0106051  1.0312826 -0.9248878  0.8669628
Function Value
[1] 7.875883
Gradient:
[1]  0.005011681 -0.010242776 -0.005613306  0.010221257

iteration = 55
Step:
[1] -0.0003714827  0.0007492683  0.0004078884 -0.0007518576
Parameter:
[1] -1.0109766  1.0320318 -0.9244799  0.8662109
Function Value
[1] 7.875863
Gradient:
[1]  0.005055406 -0.010337216 -0.005668132  0.010315296

iteration = 56
Step:
[1] -0.0003747544  0.0007561480  0.0004118309 -0.0007587852
Parameter:
[1] -1.0113513  1.0327880 -0.9240680  0.8654522
Function Value
[1] 7.875843
Gradient:
[1]  0.005099531 -0.010432610 -0.005723570  0.010410280

iteration = 57
Step:
[1] -0.0003780565  0.0007630967  0.0004158167 -0.0007657827
Parameter:
[1] -1.0117294  1.0335511 -0.9236522  0.8646864
Function Value
[1] 7.875823
Gradient:
[1]  0.00514406 -0.01052897 -0.00577963  0.01050622

iteration = 58
Step:
[1] -0.0003813894  0.0007701151  0.0004198463 -0.0007728509
Parameter:
[1] -1.0121108  1.0343212 -0.9232324  0.8639135
Function Value
[1] 7.875802
Gradient:
[1]  0.005188999 -0.010626308 -0.005836320  0.010603134

iteration = 59
Step:
[1] -0.0003847535  0.0007772041  0.0004239204 -0.0007799907
Parameter:
[1] -1.0124955  1.0350984 -0.9228085  0.8631335
Function Value
[1] 7.875781
Gradient:
[1]  0.005234351 -0.010724636 -0.005893650  0.010701028

iteration = 60
Step:
[1] -0.0003881491  0.0007843647  0.0004280396 -0.0007872030
Parameter:
[1] -1.0128837  1.0358828 -0.9223804  0.8623463
Function Value
[1] 7.875759
Gradient:
[1]  0.005280121 -0.010823968 -0.005951628  0.010799915

iteration = 61
Step:
[1] -0.0003915765  0.0007915976  0.0004322045 -0.0007944886
Parameter:
[1] -1.0132752  1.0366744 -0.9219482  0.8615518
Function Value
[1] 7.875738
Gradient:
[1]  0.005326315 -0.010924315 -0.006010264  0.010899809

iteration = 62
Step:
[1] -0.0003950362  0.0007989038  0.0004364157 -0.0008018485
Parameter:
[1] -1.0136703  1.0374733 -0.9215118  0.8607500
Function Value
[1] 7.875715
Gradient:
[1]  0.005372935 -0.011025691 -0.006069568  0.011000723

iteration = 63
Step:
[1] -0.0003985285  0.0008062842  0.0004406740 -0.0008092837
Parameter:
[1] -1.0140688  1.0382796 -0.9210711  0.8599407
Function Value
[1] 7.875692
Gradient:
[1]  0.005419989 -0.011128109 -0.006129549  0.011102669

iteration = 64
Step:
[1] -0.0004020538  0.0008137397  0.0004449800 -0.0008167951
Parameter:
[1] -1.0144709  1.0390933 -0.9206261  0.8591239
Function Value
[1] 7.875669
Gradient:
[1]  0.005467479 -0.011231582 -0.006190217  0.011205661

iteration = 65
Step:
[1] -0.0004056125  0.0008212714  0.0004493344 -0.0008243837
Parameter:
[1] -1.0148765  1.0399146 -0.9201768  0.8582995
Function Value
[1] 7.875646
Gradient:
[1]  0.005515412 -0.011336124 -0.006251583  0.011309712

iteration = 66
Step:
[1] -0.0004092048  0.0008288802  0.0004537379 -0.0008320505
Parameter:
[1] -1.0152857  1.0407434 -0.9197231  0.8574675
Function Value
[1] 7.875622
Gradient:
[1]  0.005563793 -0.011441749 -0.006313658  0.011414836

iteration = 67
Step:
[1] -0.0004128314  0.0008365670  0.0004581911 -0.0008397965
Parameter:
[1] -1.0156985  1.0415800 -0.9192649  0.8566277
Function Value
[1] 7.875597
Gradient:
[1]  0.005612625 -0.011548472 -0.006376450  0.011521047

iteration = 68
Step:
[1] -0.0004164925  0.0008443329  0.0004626949 -0.0008476227
Parameter:
[1] -1.0161150  1.0424243 -0.9188022  0.8557801
Function Value
[1] 7.875572
Gradient:
[1]  0.005661916 -0.011656306 -0.006439973  0.011628358

iteration = 69
Step:
[1] -0.0004201885  0.0008521789  0.0004672500 -0.0008555302
Parameter:
[1] -1.0165352  1.0432765 -0.9183349  0.8549245
Function Value
[1] 7.875547
Gradient:
[1]  0.005711670 -0.011765267 -0.006504236  0.011736786

iteration = 70
Step:
[1] -0.0004239200  0.0008601061  0.0004718571 -0.0008635200
Parameter:
[1] -1.0169591  1.0441366 -0.9178631  0.8540610
Function Value
[1] 7.875521
Gradient:
[1]  0.005761892 -0.011875369 -0.006569251  0.011846343

iteration = 71
Step:
[1] -0.0004276872  0.0008681155  0.0004765171 -0.0008715933
Parameter:
[1] -1.0173868  1.0450047 -0.9173866  0.8531894
Function Value
[1] 7.875495
Gradient:
[1]  0.005812588 -0.011986627 -0.006635030  0.011957046

iteration = 72
Step:
[1] -0.0004314907  0.0008762082  0.0004812306 -0.0008797512
Parameter:
[1] -1.0178183  1.0458810 -0.9169053  0.8523097
Function Value
[1] 7.875468
Gradient:
[1]  0.005863763 -0.012099058 -0.006701583  0.012068909

iteration = 73
Step:
[1] -0.0004353308  0.0008843853  0.0004859985 -0.0008879947
Parameter:
[1] -1.0182536  1.0467653 -0.9164193  0.8514217
Function Value
[1] 7.875441
Gradient:
[1]  0.005915424 -0.012212678 -0.006768925  0.012181949

iteration = 74
Step:
[1] -0.0004392080  0.0008926479  0.0004908217 -0.0008963251
Parameter:
[1] -1.0186928  1.0476580 -0.9159285  0.8505254
Function Value
[1] 7.875413
Gradient:
[1]  0.005967576 -0.012327501 -0.006837065  0.012296181

iteration = 75
Step:
[1] -0.0004431229  0.0009009972  0.0004957009 -0.0009047435
Parameter:
[1] -1.0191360  1.0485590 -0.9154328  0.8496206
Function Value
[1] 7.875384
Gradient:
[1]  0.006020226 -0.012443546 -0.006906018  0.012411621

iteration = 76
Step:
[1] -0.0004470757  0.0009094343  0.0005006370 -0.0009132511
Parameter:
[1] -1.0195830  1.0494684 -0.9149322  0.8487074
Function Value
[1] 7.875355
Gradient:
[1]  0.006073378 -0.012560828 -0.006975796  0.012528286

iteration = 77
Step:
[1] -0.0004510671  0.0009179605  0.0005056310 -0.0009218491
Parameter:
[1] -1.0200341  1.0503864 -0.9144265  0.8477855
Function Value
[1] 7.875326
Gradient:
[1]  0.006127039 -0.012679366 -0.007046412  0.012646193

iteration = 78
Step:
[1] -0.0004550974  0.0009265770  0.0005106836 -0.0009305388
Parameter:
[1] -1.0204892  1.0513130 -0.9139159  0.8468550
Function Value
[1] 7.875296
Gradient:
[1]  0.006181216 -0.012799175 -0.007117880  0.012765358

iteration = 79
Step:
[1] -0.0004591673  0.0009352849  0.0005157959 -0.0009393215
Parameter:
[1] -1.0209484  1.0522482 -0.9134001  0.8459156
Function Value
[1] 7.875265
Gradient:
[1]  0.006235915 -0.012920275 -0.007190213  0.012885800

iteration = 80
Step:
[1] -0.0004632771  0.0009440856  0.0005209687 -0.0009481984
Parameter:
[1] -1.0214116  1.0531923 -0.9128791  0.8449675
Function Value
[1] 7.875234
Gradient:
[1]  0.006291142 -0.013042684 -0.007263425  0.013007537

iteration = 81
Step:
[1] -0.0004674274  0.0009529803  0.0005262029 -0.0009571708
Parameter:
[1] -1.0218791  1.0541453 -0.9123529  0.8440103
Function Value
[1] 7.875202
Gradient:
[1]  0.006346904 -0.013166419 -0.007337531  0.013130586

iteration = 82
Step:
[1] -0.0004716187  0.0009619704  0.0005314997 -0.0009662402
Parameter:
[1] -1.0223507  1.0551073 -0.9118214  0.8430440
Function Value
[1] 7.87517
Gradient:
[1]  0.006403208 -0.013291501 -0.007412545  0.013254966

iteration = 83
Step:
[1] -0.0004758516  0.0009710572  0.0005368599 -0.0009754079
Parameter:
[1] -1.0228265  1.0560783 -0.9112845  0.8420686
Function Value
[1] 7.875137
Gradient:
[1]  0.006460060 -0.013417948 -0.007488482  0.013380696

iteration = 84
Step:
[1] -0.0004801265  0.0009802420  0.0005422846 -0.0009846752
Parameter:
[1] -1.0233067  1.0570586 -0.9107422  0.8410840
Function Value
[1] 7.875103
Gradient:
[1]  0.006517467 -0.013545780 -0.007565358  0.013507795

iteration = 85
Step:
[1] -0.0004844441  0.0009895263  0.0005477749 -0.0009940437
Parameter:
[1] -1.0237911  1.0580481 -0.9101945  0.8400899
Function Value
[1] 7.875069
Gradient:
[1]  0.006575437 -0.013675017 -0.007643188  0.013636284

iteration = 86
Step:
[1] -0.0004888048  0.0009989115  0.0005533317 -0.0010035147
Parameter:
[1] -1.0242799  1.0590470 -0.9096411  0.8390864
Function Value
[1] 7.875034
Gradient:
[1]  0.006633978 -0.013805680 -0.007721988  0.013766182

iteration = 87
Step:
[1] -0.0004932093  0.0010083990  0.0005589562 -0.0010130898
Parameter:
[1] -1.0247731  1.0600554 -0.9090822  0.8380733
Function Value
[1] 7.874998
Gradient:
[1]  0.006693095 -0.013937790 -0.007801775  0.013897510

iteration = 88
Step:
[1] -0.0004976581  0.0010179903  0.0005646495 -0.0010227705
Parameter:
[1] -1.0252708  1.0610734 -0.9085175  0.8370505
Function Value
[1] 7.874962
Gradient:
[1]  0.006752797 -0.014071369 -0.007882565  0.014030289

iteration = 89
Step:
[1] -0.0005021519  0.0010276870  0.0005704127 -0.0010325583
Parameter:
[1] -1.0257729  1.0621011 -0.9079471  0.8360180
Function Value
[1] 7.874925
Gradient:
[1]  0.006813092 -0.014206437 -0.007964376  0.014164540

iteration = 90
Step:
[1] -0.0005066912  0.0010374905  0.0005762470 -0.0010424548
Parameter:
[1] -1.0262796  1.0631386 -0.9073709  0.8349755
Function Value
[1] 7.874887
Gradient:
[1]  0.006873988 -0.014343019 -0.008047224  0.014300286

iteration = 91
Step:
[1] -0.0005112766  0.0010474024  0.0005821536 -0.0010524617
Parameter:
[1] -1.0267909  1.0641860 -0.9067887  0.8339231
Function Value
[1] 7.874849
Gradient:
[1]  0.006935492 -0.014481136 -0.008131130  0.014437548

iteration = 92
Step:
[1] -0.0005159088  0.0010574244  0.0005881337 -0.0010625806
Parameter:
[1] -1.0273068  1.0652434 -0.9062006  0.8328605
Function Value
[1] 7.87481
Gradient:
[1]  0.006997612 -0.014620812 -0.008216109  0.014576351

iteration = 93
Step:
[1] -0.0005205885  0.0010675581  0.0005941886 -0.0010728131
Parameter:
[1] -1.0278274  1.0663110 -0.9056064  0.8317877
Function Value
[1] 7.87477
Gradient:
[1]  0.007060358 -0.014762070 -0.008302183  0.014716716

iteration = 94
Step:
[1] -0.0005253163  0.0010778052  0.0006003195 -0.0010831611
Parameter:
[1] -1.0283527  1.0673888 -0.9050061  0.8307045
Function Value
[1] 7.874729
Gradient:
[1]  0.007123737 -0.014904936 -0.008389369  0.014858668

iteration = 95
Step:
[1] -0.0005300928  0.0010881674  0.0006065277 -0.0010936263
Parameter:
[1] -1.0288828  1.0684769 -0.9043996  0.8296109
Function Value
[1] 7.874687
Gradient:
[1]  0.007187759 -0.015049434 -0.008477688  0.015002231

iteration = 96
Step:
[1] -0.0005349188  0.0010986465  0.0006128146 -0.0011042104
Parameter:
[1] -1.0294177  1.0695756 -0.9037867  0.8285067
Function Value
[1] 7.874645
Gradient:
[1]  0.007252432 -0.015195590 -0.008567159  0.015147431

iteration = 97
Step:
[1] -0.0005397950  0.0011092442  0.0006191815 -0.0011149154
Parameter:
[1] -1.0299575  1.0706848 -0.9031676  0.8273918
Function Value
[1] 7.874602
Gradient:
[1]  0.007317765 -0.015343429 -0.008657805  0.015294292

iteration = 98
Step:
[1] -0.0005447220  0.0011199623  0.0006256299 -0.0011257431
Parameter:
[1] -1.0305022  1.0718048 -0.9025419  0.8262660
Function Value
[1] 7.874558
Gradient:
[1]  0.007383768 -0.015492979 -0.008749646  0.015442842

iteration = 99
Step:
[1] -0.0005497006  0.0011308029  0.0006321612 -0.0011366954
Parameter:
[1] -1.0310519  1.0729356 -0.9019098  0.8251293
Function Value
[1] 7.874513
Gradient:
[1]  0.007450449 -0.015644267 -0.008842704  0.015593105

iteration = 100
Step:
[1] -0.0005547316  0.0011417677  0.0006387768 -0.0011477743
Parameter:
[1] -1.0316067  1.0740774 -0.9012710  0.8239815
Function Value
[1] 7.874467
Gradient:
[1]  0.007517820 -0.015797320 -0.008937001  0.015745111

iteration = 101
Step:
[1] -0.0005598156  0.0011528587  0.0006454783 -0.0011589818
Parameter:
[1] -1.0321665  1.0752302 -0.9006255  0.8228226
Function Value
[1] 7.87442
Gradient:
[1]  0.007585890 -0.015952168 -0.009032561  0.015898886

iteration = 102
Step:
[1] -0.0005649536  0.0011640780  0.0006522673 -0.0011703200
Parameter:
[1] -1.0327314  1.0763943 -0.8999732  0.8216522
Function Value
[1] 7.874373
Gradient:
[1]  0.007654668 -0.016108840 -0.009129407  0.016054460

iteration = 103
Step:
[1] -0.0005701463  0.0011754276  0.0006591452 -0.0011817910
Parameter:
[1] -1.0333016  1.0775697 -0.8993141  0.8204705
Function Value
[1] 7.874324
Gradient:
[1]  0.007724165 -0.016267365 -0.009227564  0.016211861

iteration = 104
Step:
[1] -0.0005753945  0.0011869095  0.0006661138 -0.0011933970
Parameter:
[1] -1.0338770  1.0787566 -0.8986480  0.8192771
Function Value
[1] 7.874275
Gradient:
[1]  0.007794393 -0.016427774 -0.009327055  0.016371120

iteration = 105
Step:
[1] -0.0005806990  0.0011985260  0.0006731747 -0.0012051401
Parameter:
[1] -1.0344577  1.0799552 -0.8979748  0.8180719
Function Value
[1] 7.874224
Gradient:
[1]  0.007865361 -0.016590098 -0.009427907  0.016532267

iteration = 106
Step:
[1] -0.0005860608  0.0012102793  0.0006803296 -0.0012170227
Parameter:
[1] -1.0350437  1.0811654 -0.8972945  0.8168549
Function Value
[1] 7.874173
Gradient:
[1]  0.007937081 -0.016754370 -0.009530146  0.016695333

iteration = 107
Step:
[1] -0.0005914806  0.0012221715  0.0006875803 -0.0012290470
Parameter:
[1] -1.0356352  1.0823876 -0.8966069  0.8156258
Function Value
[1] 7.87412
Gradient:
[1]  0.008009563 -0.016920623 -0.009633799  0.016860351

iteration = 108
Step:
[1] -0.0005969594  0.0012342050  0.0006949285 -0.0012412154
Parameter:
[1] -1.0362322  1.0836218 -0.8959120  0.8143846
Function Value
[1] 7.874067
Gradient:
[1]  0.008082821 -0.017088890 -0.009738893  0.017027353

iteration = 109
Step:
[1] -0.0006024981  0.0012463821  0.0007023762 -0.0012535303
Parameter:
[1] -1.0368347  1.0848682 -0.8952096  0.8131311
Function Value
[1] 7.874012
Gradient:
[1]  0.008156865 -0.017259206 -0.009845457  0.017196373

iteration = 110
Step:
[1] -0.0006080976  0.0012587053  0.0007099252 -0.0012659942
Parameter:
[1] -1.0374428  1.0861269 -0.8944997  0.8118651
Function Value
[1] 7.873957
Gradient:
[1]  0.008231708 -0.017431606 -0.009953519  0.017367446

iteration = 111
Step:
[1] -0.0006137589  0.0012711770  0.0007175775 -0.0012786098
Parameter:
[1] -1.0380565  1.0873981 -0.8937821  0.8105865
Function Value
[1] 7.8739
Gradient:
[1]  0.008307362 -0.017606127 -0.010063110  0.017540606

iteration = 112
Step:
[1] -0.000619483  0.001283800  0.000725335 -0.001291379
Parameter:
[1] -1.0386760  1.0886819 -0.8930568  0.8092951
Function Value
[1] 7.873842
Gradient:
[1]  0.00838384 -0.01778281 -0.01017426  0.01771589

iteration = 113
Step:
[1] -0.0006252708  0.0012965763  0.0007331998 -0.0013043060
Parameter:
[1] -1.0393013  1.0899785 -0.8923236  0.8079908
Function Value
[1] 7.873783
Gradient:
[1]  0.008461154 -0.017961680 -0.010287001  0.017893337

iteration = 114
Step:
[1] -0.0006311235  0.0013095091  0.0007411741 -0.0013173922
Parameter:
[1] -1.0399324  1.0912880 -0.8915824  0.8066734
Function Value
[1] 7.873722
Gradient:
[1]  0.008539319 -0.018142789 -0.010401365  0.018072983

iteration = 115
Step:
[1] -0.000637042  0.001322601  0.000749260 -0.001330641
Parameter:
[1] -1.0405695  1.0926106 -0.8908331  0.8053428
Function Value
[1] 7.873661
Gradient:
[1]  0.008618348 -0.018326174 -0.010517386  0.018254867

iteration = 116
Step:
[1] -0.0006430275  0.0013358547  0.0007574597 -0.0013440547
Parameter:
[1] -1.0412125  1.0939464 -0.8900757  0.8039987
Function Value
[1] 7.873598
Gradient:
[1]  0.008698255 -0.018511875 -0.010635098  0.018439029

iteration = 117
Step:
[1] -0.0006490811  0.0013492731  0.0007657754 -0.0013576368
Parameter:
[1] -1.0418616  1.0952957 -0.8893099  0.8026411
Function Value
[1] 7.873534
Gradient:
[1]  0.008779055 -0.018699934 -0.010754536  0.018625511

iteration = 118
Step:
[1] -0.0006552038  0.0013628592  0.0007742097 -0.0013713902
Parameter:
[1] -1.0425168  1.0966586 -0.8885357  0.8012697
Function Value
[1] 7.873468
Gradient:
[1]  0.008860761 -0.018890396 -0.010875738  0.018814355

iteration = 119
Step:
[1] -0.0006613969  0.0013766160  0.0007827648 -0.0013853180
Parameter:
[1] -1.0431782  1.0980352 -0.8877529  0.7998844
Function Value
[1] 7.873401
Gradient:
[1]  0.00894339 -0.01908330 -0.01099874  0.01900560

iteration = 120
Step:
[1] -0.0006676616  0.0013905465  0.0007914433 -0.0013994234
Parameter:
[1] -1.0438458  1.0994257 -0.8869615  0.7984850
Function Value
[1] 7.873333
Gradient:
[1]  0.009026957 -0.019278703 -0.011123578  0.019199301

iteration = 121
Step:
[1] -0.0006739991  0.0014046540  0.0008002477 -0.0014137097
Parameter:
[1] -1.0445198  1.1008304 -0.8861612  0.7970712
Function Value
[1] 7.873264
Gradient:
[1]  0.009111477 -0.019476642 -0.011250296  0.019395493

iteration = 122
Step:
[1] -0.0006804106  0.0014189418  0.0008091806 -0.0014281802
Parameter:
[1] -1.0452002  1.1022493 -0.8853520  0.7956431
Function Value
[1] 7.873193
Gradient:
[1]  0.009196967 -0.019677168 -0.011378933  0.019594228

iteration = 123
Step:
[1] -0.0006868974  0.0014334130  0.0008182448 -0.0014428383
Parameter:
[1] -1.0458871  1.1036827 -0.8845338  0.7942002
Function Value
[1] 7.87312
Gradient:
[1]  0.009283444 -0.019880330 -0.011509530  0.019795551

iteration = 124
Step:
[1] -0.000693461  0.001448071  0.000827443 -0.001457688
Parameter:
[1] -1.0465806  1.1051308 -0.8837064  0.7927425
Function Value
[1] 7.873046
Gradient:
[1]  0.009370924 -0.020086180 -0.011642131  0.019999514

iteration = 125
Step:
[1] -0.0007001025  0.0014629201  0.0008367781 -0.0014727320
Parameter:
[1] -1.0472807  1.1065937 -0.8828696  0.7912698
Function Value
[1] 7.872971
Gradient:
[1]  0.009459426 -0.020294770 -0.011776782  0.020206166

iteration = 126
Step:
[1] -0.0007068235  0.0014779631  0.0008462531 -0.0014879749
Parameter:
[1] -1.0479875  1.1080717 -0.8820233  0.7897818
Function Value
[1] 7.872894
Gradient:
[1]  0.009548967 -0.020506153 -0.011913527  0.020415560

iteration = 127
Step:
[1] -0.0007136253  0.0014932039  0.0008558710 -0.0015034203
Parameter:
[1] -1.0487011  1.1095649 -0.8811675  0.7882784
Function Value
[1] 7.872815
Gradient:
[1]  0.009639567 -0.020720384 -0.012052413  0.020627749

iteration = 128
Step:
[1] -0.0007205095  0.0015086465  0.0008656349 -0.0015190720
Parameter:
[1] -1.0494217  1.1110735 -0.8803018  0.7867593
Function Value
[1] 7.872734
Gradient:
[1]  0.009731244 -0.020937522 -0.012193491  0.020842789

iteration = 129
Step:
[1] -0.0007274775  0.0015242946  0.0008755480 -0.0015349343
Parameter:
[1] -1.0501491  1.1125978 -0.8794263  0.7852244
Function Value
[1] 7.872652
Gradient:
[1]  0.009824017 -0.021157623 -0.012336810  0.021060735

iteration = 130
Step:
[1] -0.0007345309  0.0015401525  0.0008856137 -0.0015510112
Parameter:
[1] -1.0508837  1.1141380 -0.8785407  0.7836734
Function Value
[1] 7.872569
Gradient:
[1]  0.009917907 -0.021380747 -0.012482422  0.021281646

iteration = 131
Step:
[1] -0.0007416713  0.0015562242  0.0008958354 -0.0015673070
Parameter:
[1] -1.0516253  1.1156942 -0.8776448  0.7821061
Function Value
[1] 7.872483
Gradient:
[1]  0.01001293 -0.02160696 -0.01263038  0.02150558

iteration = 132
Step:
[1] -0.0007489003  0.0015725140  0.0009062166 -0.0015838262
Parameter:
[1] -1.0523742  1.1172667 -0.8767386  0.7805223
Function Value
[1] 7.872395
Gradient:
[1]  0.01010912 -0.02183632 -0.01278074  0.02173260

iteration = 133
Step:
[1] -0.0007562197  0.0015890263  0.0009167610 -0.0016005734
Parameter:
[1] -1.0531305  1.1188557 -0.8758218  0.7789217
Function Value
[1] 7.872306
Gradient:
[1]  0.01020649 -0.02206889 -0.01293356  0.02196278

iteration = 134
Step:
[1] -0.0007636311  0.0016057656  0.0009274723 -0.0016175531
Parameter:
[1] -1.0538941  1.1204615 -0.8748944  0.7773041
Function Value
[1] 7.872215
Gradient:
[1]  0.01030506 -0.02230475 -0.01308890  0.02219616

iteration = 135
Step:
[1] -0.0007711364  0.0016227366  0.0009383544 -0.0016347702
Parameter:
[1] -1.0546652  1.1220842 -0.8739560  0.7756694
Function Value
[1] 7.872122
Gradient:
[1]  0.01040486 -0.02254396 -0.01324681  0.02243283

iteration = 136
Step:
[1] -0.0007787374  0.0016399441  0.0009494113 -0.0016522296
Parameter:
[1] -1.0554440  1.1237242 -0.8730066  0.7740171
Function Value
[1] 7.872026
Gradient:
[1]  0.01050590 -0.02278659 -0.01340737  0.02267285

iteration = 137
Step:
[1] -0.0007864360  0.0016573930  0.0009606472 -0.0016699366
Parameter:
[1] -1.0562304  1.1253816 -0.8720460  0.7723472
Function Value
[1] 7.871929
Gradient:
[1]  0.01060822 -0.02303272 -0.01357064  0.02291629

iteration = 138
Step:
[1] -0.0007942341  0.0016750884  0.0009720662 -0.0016878962
Parameter:
[1] -1.0570246  1.1270567 -0.8710739  0.7706593
Function Value
[1] 7.87183
Gradient:
[1]  0.01071185 -0.02328242 -0.01373668  0.02316323

iteration = 139
Step:
[1] -0.0008021337  0.0016930355  0.0009836727 -0.0017061140
Parameter:
[1] -1.0578268  1.1287497 -0.8700902  0.7689532
Function Value
[1] 7.871728
Gradient:
[1]  0.01081679 -0.02353577 -0.01390556  0.02341374

iteration = 140
Step:
[1] -0.0008101369  0.0017112397  0.0009954715 -0.0017245954
Parameter:
[1] -1.0586369  1.1304609 -0.8690947  0.7672286
Function Value
[1] 7.871624
Gradient:
[1]  0.01092309 -0.02379286 -0.01407736  0.02366789

iteration = 141
Step:
[1] -0.0008182459  0.0017297066  0.0010074670 -0.0017433464
Parameter:
[1] -1.0594551  1.1321907 -0.8680873  0.7654852
Function Value
[1] 7.871518
Gradient:
[1]  0.01103077 -0.02405376 -0.01425214  0.02392578

iteration = 142
Step:
[1] -0.0008264628  0.0017484418  0.0010196642 -0.0017623727
Parameter:
[1] -1.0602816  1.1339391 -0.8670676  0.7637229
Function Value
[1] 7.87141
Gradient:
[1]  0.01113986 -0.02431856 -0.01443000  0.02418748

iteration = 143
Step:
[1] -0.0008347898  0.0017674513  0.0010320681 -0.0017816805
Parameter:
[1] -1.0611164  1.1357065 -0.8660355  0.7619412
Function Value
[1] 7.871299
Gradient:
[1]  0.01125038 -0.02458735 -0.01461100  0.02445307

iteration = 144
Step:
[1] -0.0008432294  0.0017867412  0.0010446839 -0.0018012761
Parameter:
[1] -1.0619596  1.1374933 -0.8649909  0.7601399
Function Value
[1] 7.871185
Gradient:
[1]  0.01136237 -0.02486023 -0.01479523  0.02472265

iteration = 145
Step:
[1] -0.0008517838  0.0018063177  0.0010575170 -0.0018211660
Parameter:
[1] -1.0628114  1.1392996 -0.8639333  0.7583187
Function Value
[1] 7.87107
Gradient:
[1]  0.01147586 -0.02513728 -0.01498277  0.02499631

iteration = 146
Step:
[1] -0.0008604557  0.0018261874  0.0010705728 -0.0018413570
Parameter:
[1] -1.0636719  1.1411258 -0.8628628  0.7564774
Function Value
[1] 7.870951
Gradient:
[1]  0.01159088 -0.02541860 -0.01517371  0.02527414

iteration = 147
Step:
[1] -0.0008692474  0.0018463568  0.0010838573 -0.0018618559
Parameter:
[1] -1.0645411  1.1429721 -0.8617789  0.7546155
Function Value
[1] 7.87083
Gradient:
[1]  0.01170747 -0.02570430 -0.01536815  0.02555623

iteration = 148
Step:
[1] -0.0008781617  0.0018668330  0.0010973762 -0.0018826699
Parameter:
[1] -1.0654193  1.1448390 -0.8606815  0.7527329
Function Value
[1] 7.870706
Gradient:
[1]  0.01182565 -0.02599447 -0.01556618  0.02584269

iteration = 149
Step:
[1] -0.0008872013  0.0018876229  0.0011111358 -0.0019038063
Parameter:
[1] -1.0663065  1.1467266 -0.8595704  0.7508291
Function Value
[1] 7.870579
Gradient:
[1]  0.01194546 -0.02628923 -0.01576790  0.02613362

iteration = 150
Step:
[1] -0.0008963689  0.0019087340  0.0011251424 -0.0019252729
Parameter:
[1] -1.0672029  1.1486353 -0.8584453  0.7489038
Function Value
[1] 7.870449
Gradient:
[1]  0.01206695 -0.02658869 -0.01597340  0.02642912

iteration = 151
Step:
[1] -0.0009056675  0.0019301739  0.0011394027 -0.0019470775
Parameter:
[1] -1.0681085  1.1505655 -0.8573059  0.7469567
Function Value
[1] 7.870317
Gradient:
[1]  0.01219014 -0.02689296 -0.01618280  0.02672931

iteration = 152
Step:
[1] -0.0009151001  0.0019519503  0.0011539235 -0.0019692282
Parameter:
[1] -1.0690236  1.1525175 -0.8561519  0.7449875
Function Value
[1] 7.870181
Gradient:
[1]  0.01231507 -0.02720217 -0.01639621  0.02703431

iteration = 153
Step:
[1] -0.0009246697  0.0019740715  0.0011687119 -0.0019917334
Parameter:
[1] -1.0699483  1.1544915 -0.8549832  0.7429957
Function Value
[1] 7.870042
Gradient:
[1]  0.01244179 -0.02751642 -0.01661373  0.02734422

iteration = 154
Step:
[1] -0.0009343795  0.0019965458  0.0011837753 -0.0020146020
Parameter:
[1] -1.0708827  1.1564881 -0.8537995  0.7409811
Function Value
[1] 7.8699
Gradient:
[1]  0.01257033 -0.02783586 -0.01683550  0.02765917

iteration = 155
Step:
[1] -0.0009442328  0.0020193819  0.0011991214 -0.0020378428
Parameter:
[1] -1.0718269  1.1585075 -0.8526003  0.7389433
Function Value
[1] 7.869755
Gradient:
[1]  0.01270075 -0.02816061 -0.01706162  0.02797929

iteration = 156
Step:
[1] -0.0009542332  0.0020425887  0.0012147580 -0.0020614653
Parameter:
[1] -1.0727811  1.1605500 -0.8513856  0.7368818
Function Value
[1] 7.869606
Gradient:
[1]  0.01283307 -0.02849082 -0.01729224  0.02830471

iteration = 157
Step:
[1] -0.0009643839  0.0020661755  0.0012306935 -0.0020854790
Parameter:
[1] -1.0737455  1.1626162 -0.8501549  0.7347964
Function Value
[1] 7.869453
Gradient:
[1]  0.01296736 -0.02882661 -0.01752748  0.02863555

iteration = 158
Step:
[1] -0.0009746888  0.0020901520  0.0012469363 -0.0021098939
Parameter:
[1] -1.0747202  1.1647064 -0.8489079  0.7326865
Function Value
[1] 7.869297
Gradient:
[1]  0.01310365 -0.02916815 -0.01776748  0.02897197

iteration = 159
Step:
[1] -0.0009851516  0.0021145280  0.0012634954 -0.0021347204
Parameter:
[1] -1.0757054  1.1668209 -0.8476444  0.7305517
Function Value
[1] 7.869137
Gradient:
[1]  0.01324199 -0.02951557 -0.01801239  0.02931411

iteration = 160
Step:
[1] -0.0009957761  0.0021393139  0.0012803800 -0.0021599693
Parameter:
[1] -1.0767011  1.1689602 -0.8463641  0.7283918
Function Value
[1] 7.868974
Gradient:
[1]  0.01338244 -0.02986904 -0.01826235  0.02966212

iteration = 161
Step:
[1] -0.001006567  0.002164520  0.001297600 -0.002185652
Parameter:
[1] -1.0777077  1.1711247 -0.8450665  0.7262061
Function Value
[1] 7.868806
Gradient:
[1]  0.01352505 -0.03022873 -0.01851753  0.03001615

iteration = 162
Step:
[1] -0.001017527  0.002190158  0.001315165 -0.002211779
Parameter:
[1] -1.0787252  1.1733149 -0.8437513  0.7239943
Function Value
[1] 7.868634
Gradient:
[1]  0.01366987 -0.03059480 -0.01877808  0.03037636

iteration = 163
Step:
[1] -0.001028662  0.002216240  0.001333085 -0.002238363
Parameter:
[1] -1.0797539  1.1755311 -0.8424182  0.7217560
Function Value
[1] 7.868458
Gradient:
[1]  0.01381695 -0.03096742 -0.01904417  0.03074292

iteration = 164
Step:
[1] -0.001039975  0.002242776  0.001351371 -0.002265416
Parameter:
[1] -1.0807939  1.1777739 -0.8410668  0.7194906
Function Value
[1] 7.868278
Gradient:
[1]  0.01396636 -0.03134678 -0.01931599  0.03111601

iteration = 165
Step:
[1] -0.001051473  0.002269779  0.001370036 -0.002292952
Parameter:
[1] -1.0818453  1.1800437 -0.8396968  0.7171976
Function Value
[1] 7.868093
Gradient:
[1]  0.01411816 -0.03173308 -0.01959371  0.03149581

iteration = 166
Step:
[1] -0.001063158  0.002297263  0.001389089 -0.002320982
Parameter:
[1] -1.0829085  1.1823410 -0.8383077  0.7148766
Function Value
[1] 7.867904
Gradient:
[1]  0.01427240 -0.03212650 -0.01987753  0.03188250

iteration = 167
Step:
[1] -0.001075037  0.002325239  0.001408544 -0.002349523
Parameter:
[1] -1.0839835  1.1846662 -0.8368992  0.7125271
Function Value
[1] 7.867709
Gradient:
[1]  0.01442916 -0.03252726 -0.02016766  0.03227628

iteration = 168
Step:
[1] -0.001087115  0.002353723  0.001428413 -0.002378586
Parameter:
[1] -1.0850706  1.1870199 -0.8354708  0.7101485
Function Value
[1] 7.86751
Gradient:
[1]  0.01458849 -0.03293556 -0.02046429  0.03267734

iteration = 169
Step:
[1] -0.001099396  0.002382729  0.001448710 -0.002408189
Parameter:
[1] -1.0861700  1.1894026 -0.8340221  0.7077403
Function Value
[1] 7.867306
Gradient:
[1]  0.01475048 -0.03335164 -0.02076765  0.03308591

iteration = 170
Step:
[1] -0.001111888  0.002412271  0.001469448 -0.002438345
Parameter:
[1] -1.0872819  1.1918149 -0.8325526  0.7053020
Function Value
[1] 7.867097
Gradient:
[1]  0.01491519 -0.03377571 -0.02107797  0.03350219

iteration = 171
Step:
[1] -0.001124594  0.002442364  0.001490642 -0.002469072
Parameter:
[1] -1.0884065  1.1942573 -0.8310620  0.7028329
Function Value
[1] 7.866882
Gradient:
[1]  0.01508270 -0.03420802 -0.02139548  0.03392642

iteration = 172
Step:
[1] -0.001137522  0.002473026  0.001512307 -0.002500386
Parameter:
[1] -1.0895440  1.1967303 -0.8295497  0.7003325
Function Value
[1] 7.866662
Gradient:
[1]  0.01525308 -0.03464882 -0.02172044  0.03435883

iteration = 173
Step:
[1] -0.001150678  0.002504272  0.001534459 -0.002532305
Parameter:
[1] -1.0906947  1.1992346 -0.8280152  0.6978002
Function Value
[1] 7.866436
Gradient:
[1]  0.01542643 -0.03509837 -0.02205312  0.03479967

iteration = 174
Step:
[1] -0.001164068  0.002536120  0.001557114 -0.002564846
Parameter:
[1] -1.0918588  1.2017707 -0.8264581  0.6952354
Function Value
[1] 7.866203
Gradient:
[1]  0.01560281 -0.03555695 -0.02239378  0.03524919

iteration = 175
Step:
[1] -0.001177700  0.002568588  0.001580289 -0.002598029
Parameter:
[1] -1.0930365  1.2043393 -0.8248778  0.6926374
Function Value
[1] 7.865965
Gradient:
[1]  0.01578232 -0.03602483 -0.02274271  0.03570765

iteration = 176
Step:
[1] -0.001191579  0.002601696  0.001604003 -0.002631874
Parameter:
[1] -1.0942281  1.2069410 -0.8232738  0.6900055
Function Value
[1] 7.865721
Gradient:
[1]  0.01596506 -0.03650232 -0.02310022  0.03617535

iteration = 177
Step:
[1] -0.001205714  0.002635462  0.001628274 -0.002666400
Parameter:
[1] -1.0954338  1.2095764 -0.8216455  0.6873391
Function Value
[1] 7.865469
Gradient:
[1]  0.01615111 -0.03698971 -0.02346662  0.03665256

iteration = 178
Step:
[1] -0.001220113  0.002669907  0.001653123 -0.002701631
Parameter:
[1] -1.0966539  1.2122464 -0.8199924  0.6846374
Function Value
[1] 7.865211
Gradient:
[1]  0.01634058 -0.03748735 -0.02384225  0.03713959

iteration = 179
Step:
[1] -0.001234783  0.002705053  0.001678570 -0.002737587
Parameter:
[1] -1.0978887  1.2149514 -0.8183138  0.6818999
Function Value
[1] 7.864946
Gradient:
[1]  0.01653357 -0.03799555 -0.02422745  0.03763675

iteration = 180
Step:
[1] -0.001249732  0.002740921  0.001704636 -0.002774292
Parameter:
[1] -1.0991384  1.2176923 -0.8166092  0.6791256
Function Value
[1] 7.864674
Gradient:
[1]  0.01673019 -0.03851467 -0.02462259  0.03814438

iteration = 181
Step:
[1] -0.001264970  0.002777536  0.001731344 -0.002811771
Parameter:
[1] -1.1004034  1.2204699 -0.8148778  0.6763138
Function Value
[1] 7.864394
Gradient:
[1]  0.01693055 -0.03904508 -0.02502806  0.03866281

iteration = 182
Step:
[1] -0.001280505  0.002814921  0.001758719 -0.002850049
Parameter:
[1] -1.1016839  1.2232848 -0.8131191  0.6734637
Function Value
[1] 7.864106
Gradient:
[1]  0.01713477 -0.03958717 -0.02544426  0.03919241

iteration = 183
Step:
[1] -0.001296347  0.002853102  0.001786785 -0.002889153
Parameter:
[1] -1.1029802  1.2261379 -0.8113323  0.6705746
Function Value
[1] 7.86381
Gradient:
[1]  0.01734297 -0.04014134 -0.02587161  0.03973355

iteration = 184
Step:
[1] -0.001312506  0.002892105  0.001815569 -0.002929111
Parameter:
[1] -1.1042927  1.2290300 -0.8095168  0.6676455
Function Value
[1] 7.863506
Gradient:
[1]  0.01755528 -0.04070801 -0.02631058  0.04028662

iteration = 185
Step:
[1] -0.001328992  0.002931958  0.001845098 -0.002969951
Parameter:
[1] -1.1056217  1.2319619 -0.8076717  0.6646755
Function Value
[1] 7.863193
Gradient:
[1]  0.01777183 -0.04128763 -0.02676162  0.04085203

iteration = 186
Step:
[1] -0.001345816  0.002972690  0.001875402 -0.003011705
Parameter:
[1] -1.1069676  1.2349346 -0.8057963  0.6616638
Function Value
[1] 7.86287
Gradient:
[1]  0.01799276 -0.04188065 -0.02722524  0.04143022

iteration = 187
Step:
[1] -0.001362989  0.003014331  0.001906511 -0.003054404
Parameter:
[1] -1.1083305  1.2379490 -0.8038898  0.6586094
Function Value
[1] 7.862539
Gradient:
[1]  0.01821822 -0.04248756 -0.02770198  0.04202164

iteration = 188
Step:
[1] -0.001380524  0.003056914  0.001938458 -0.003098081
Parameter:
[1] -1.1097111  1.2410059 -0.8019513  0.6555113
Function Value
[1] 7.862197
Gradient:
[1]  0.01844837 -0.04310888 -0.02819237  0.04262675

iteration = 189
Step:
[1] -0.001398431  0.003100470  0.001971276 -0.003142772
Parameter:
[1] -1.1111095  1.2441064 -0.7999800  0.6523686
Function Value
[1] 7.861846
Gradient:
[1]  0.01868335 -0.04374513 -0.02869702  0.04324605

iteration = 190
Step:
[1] -0.001416725  0.003145036  0.002005002 -0.003188513
Parameter:
[1] -1.1125262  1.2472514 -0.7979750  0.6491801
Function Value
[1] 7.861484
Gradient:
[1]  0.01892335 -0.04439689 -0.02921654  0.04388005

iteration = 191
Step:
[1] -0.001435419  0.003190648  0.002039673 -0.003235343
Parameter:
[1] -1.1139616  1.2504420 -0.7959354  0.6459447
Function Value
[1] 7.86111
Gradient:
[1]  0.01916853 -0.04506475 -0.02975160  0.04452932

iteration = 192
Step:
[1] -0.001454527  0.003237344  0.002075329 -0.003283302
Parameter:
[1] -1.1154162  1.2536794 -0.7938600  0.6426614
Function Value
[1] 7.860726
Gradient:
[1]  0.01941909 -0.04574932 -0.03030288  0.04519440

iteration = 193
Step:
[1] -0.001474065  0.003285164  0.002112013 -0.003332434
Parameter:
[1] -1.116890  1.256965 -0.791748  0.639329
Function Value
[1] 7.860329
Gradient:
[1]  0.01967521 -0.04645126 -0.03087113  0.04587592

iteration = 194
Step:
[1] -0.001494047  0.003334150  0.002149769 -0.003382782
Parameter:
[1] -1.1183843  1.2602987 -0.7895982  0.6359462
Function Value
[1] 7.85992
Gradient:
[1]  0.01993710 -0.04717127 -0.03145713  0.04657449

iteration = 195
Step:
[1] -0.001514490  0.003384348  0.002188644 -0.003434393
Parameter:
[1] -1.1198988  1.2636830 -0.7874096  0.6325118
Function Value
[1] 7.859498
Gradient:
[1]  0.02020496 -0.04791007 -0.03206171  0.04729078

iteration = 196
Step:
[1] -0.001535411  0.003435804  0.002228689 -0.003487317
Parameter:
[1] -1.1214342  1.2671188 -0.7851809  0.6290245
Function Value
[1] 7.859063
Gradient:
[1]  0.02047904 -0.04866844 -0.03268575  0.04802549

iteration = 197
Step:
[1] -0.001556829  0.003488567  0.002269956 -0.003541607
Parameter:
[1] -1.1229910  1.2706074 -0.7829109  0.6254829
Function Value
[1] 7.858613
Gradient:
[1]  0.02075956 -0.04944717 -0.03333020  0.04877936

iteration = 198
Step:
[1] -0.001578763  0.003542689  0.002312502 -0.003597316
Parameter:
[1] -1.1245698  1.2741501 -0.7805984  0.6218856
Function Value
[1] 7.858149
Gradient:
[1]  0.02104676 -0.05024713 -0.03399605  0.04955317

iteration = 199
Step:
[1] -0.001601232  0.003598224  0.002356386 -0.003654504
Parameter:
[1] -1.1261710  1.2777483 -0.7782421  0.6182311
Function Value
[1] 7.857669
Gradient:
[1]  0.02134093 -0.05106922 -0.03468437  0.05034773

iteration = 200
Step:
[1] -0.001624259  0.003655230  0.002401672 -0.003713230
Parameter:
[1] -1.1277953  1.2814036 -0.7758404  0.6145178
Function Value
[1] 7.857173
Gradient:
[1]  0.02164231 -0.05191440 -0.03539629  0.05116390

iteration = 201
Step:
[1] -0.001647864  0.003713768  0.002448426 -0.003773559
Parameter:
[1] -1.1294431  1.2851173 -0.7733920  0.6107443
Function Value
[1] 7.856661
Gradient:
[1]  0.02195122 -0.05278369 -0.03613303  0.05200260

iteration = 202
Step:
[1] -0.001672073  0.003773902  0.002496722 -0.003835560
Parameter:
[1] -1.1311152  1.2888912 -0.7708952  0.6069087
Function Value
[1] 7.856131
Gradient:
[1]  0.02226796 -0.05367815 -0.03689587  0.05286480

iteration = 203
Step:
[1] -0.001696908  0.003835699  0.002546635 -0.003899304
Parameter:
[1] -1.1328121  1.2927269 -0.7683486  0.6030094
Function Value
[1] 7.855582
Gradient:
[1]  0.02259285 -0.05459894 -0.03768621  0.05375151

iteration = 204
Step:
[1] -0.001722398  0.003899231  0.002598247 -0.003964868
Parameter:
[1] -1.1345345  1.2966262 -0.7657504  0.5990445
Function Value
[1] 7.855014
Gradient:
[1]  0.02292623 -0.05554724 -0.03850553  0.05466382

iteration = 205
Step:
[1] -0.001748568  0.003964573  0.002651644 -0.004032332
Parameter:
[1] -1.1362831  1.3005907 -0.7630987  0.5950122
Function Value
[1] 7.854426
Gradient:
[1]  0.02326847 -0.05652436 -0.03935540  0.05560286

iteration = 206
Step:
[1] -0.001775450  0.004031807  0.002706919 -0.004101782
Parameter:
[1] -1.1380585  1.3046225 -0.7603918  0.5909104
Function Value
[1] 7.853817
Gradient:
[1]  0.02361995 -0.05753165 -0.04023754  0.05656984

iteration = 207
Step:
[1] -0.001803073  0.004101015  0.002764173 -0.004173308
Parameter:
[1] -1.1398616  1.3087236 -0.7576276  0.5867371
Function Value
[1] 7.853185
Gradient:
[1]  0.02398109 -0.05857058 -0.04115378  0.05756606

iteration = 208
Step:
[1] -0.001831470  0.004172290  0.002823511 -0.004247006
Parameter:
[1] -1.1416931  1.3128958 -0.7548041  0.5824901
Function Value
[1] 7.85253
Gradient:
[1]  0.02435230 -0.05964268 -0.04210609  0.05859287

iteration = 209
Step:
[1] -0.001860676  0.004245726  0.002885046 -0.004322979
Parameter:
[1] -1.1435537  1.3171416 -0.7519191  0.5781671
Function Value
[1] 7.85185
Gradient:
[1]  0.02473405 -0.06074960 -0.04309657  0.05965172

iteration = 210
Step:
[1] -0.001890728  0.004321424  0.002948902 -0.004401335
Parameter:
[1] -1.1454445  1.3214630 -0.7489702  0.5737658
Function Value
[1] 7.851145
Gradient:
[1]  0.02512683 -0.06189311 -0.04412753  0.06074416

iteration = 211
Step:
[1] -0.001921665  0.004399492  0.003015210 -0.004482190
Parameter:
[1] -1.1473661  1.3258625 -0.7459550  0.5692836
Function Value
[1] 7.850412
Gradient:
[1]  0.02553116 -0.06307510 -0.04520142  0.06187183

iteration = 212
Step:
[1] -0.001953529  0.004480045  0.003084110 -0.004565668
Parameter:
[1] -1.1493197  1.3303425 -0.7428708  0.5647179
Function Value
[1] 7.84965
Gradient:
[1]  0.02594758 -0.06429757 -0.04632090  0.06303646

iteration = 213
Step:
[1] -0.001986363  0.004563206  0.003155755 -0.004651898
Parameter:
[1] -1.1513060  1.3349057 -0.7397151  0.5600660
Function Value
[1] 7.848858
Gradient:
[1]  0.02637670 -0.06556267 -0.04748888  0.06423993

iteration = 214
Step:
[1] -0.002020214  0.004649103  0.003230309 -0.004741022
Parameter:
[1] -1.1533262  1.3395548 -0.7364848  0.5553250
Function Value
[1] 7.848033
Gradient:
[1]  0.02681912 -0.06687273 -0.04870847  0.06548422

iteration = 215
Step:
[1] -0.002055134  0.004737875  0.003307948 -0.004833188
Parameter:
[1] -1.1553814  1.3442927 -0.7331768  0.5504918
Function Value
[1] 7.847175
Gradient:
[1]  0.02727553 -0.06823022 -0.04998307  0.06677146

iteration = 216
Step:
[1] -0.002091174  0.004829672  0.003388864 -0.004928557
Parameter:
[1] -1.1574725  1.3491224 -0.7297880  0.5455633
Function Value
[1] 7.84628
Gradient:
[1]  0.02774663 -0.06963780 -0.05131638  0.06810390

iteration = 217
Step:
[1] -0.002128392  0.004924650  0.003473265 -0.005027300
Parameter:
[1] -1.1596009  1.3540470 -0.7263147  0.5405360
Function Value
[1] 7.845348
Gradient:
[1]  0.02823321 -0.07109834 -0.05271242  0.06948398

iteration = 218
Step:
[1] -0.002166848  0.005022979  0.003561374 -0.005129599
Parameter:
[1] -1.1617678  1.3590700 -0.7227533  0.5354064
Function Value
[1] 7.844375
Gradient:
[1]  0.02873608 -0.07261494 -0.05417557  0.07091431

iteration = 219
Step:
[1] -0.002206607  0.005124840  0.003653435 -0.005235652
Parameter:
[1] -1.1639744  1.3641949 -0.7190999  0.5301707
Function Value
[1] 7.843359
Gradient:
[1]  0.02925612 -0.07419091 -0.05571065  0.07239766

iteration = 220
Step:
[1] -0.002247739  0.005230427  0.003749714 -0.005345669
Parameter:
[1] -1.1662221  1.3694253 -0.7153502  0.5248251
Function Value
[1] 7.842297
Gradient:
[1]  0.02979428 -0.07582987 -0.05732290  0.07393704

iteration = 221
Step:
[1] -0.002290318  0.005339948  0.003850498 -0.005459877
Parameter:
[1] -1.1685125  1.3747652 -0.7114997  0.5193652
Function Value
[1] 7.841187
Gradient:
[1]  0.03035159 -0.07753571 -0.05901809  0.07553565

iteration = 222
Step:
[1] -0.002334423  0.005453627  0.003956105 -0.005578519
Parameter:
[1] -1.1708469  1.3802189 -0.7075436  0.5137867
Function Value
[1] 7.840024
Gradient:
[1]  0.03092914 -0.07931264 -0.06080255  0.07719696

iteration = 223
Step:
[1] -0.002380140  0.005571704  0.004066877 -0.005701859
Parameter:
[1] -1.1732270  1.3857906 -0.7034767  0.5080848
Function Value
[1] 7.838807
Gradient:
[1]  0.03152813 -0.08116525 -0.06268326  0.07892469

iteration = 224
Step:
[1] -0.002427561  0.005694436  0.004183191 -0.005830179
Parameter:
[1] -1.1756546  1.3914850 -0.6992935  0.5022546
Function Value
[1] 7.83753
Gradient:
[1]  0.03214983 -0.08309851 -0.06466792  0.08072286

iteration = 225
Step:
[1] -0.002476783  0.005822102  0.004305463 -0.005963784
Parameter:
[1] -1.1781314  1.3973071 -0.6949880  0.4962908
Function Value
[1] 7.83619
Gradient:
[1]  0.03279564 -0.08511784 -0.06676506  0.08259579

iteration = 226
Step:
[1] -0.002527912  0.005955001  0.004434145 -0.006103005
Parameter:
[1] -1.1806593  1.4032621 -0.6905539  0.4901878
Function Value
[1] 7.834782
Gradient:
[1]  0.03346707 -0.08722914 -0.06898412  0.08454818

iteration = 227
Step:
[1] -0.002581063  0.006093458  0.004569740 -0.006248199
Parameter:
[1] -1.1832403  1.4093556 -0.6859842  0.4839396
Function Value
[1] 7.833302
Gradient:
[1]  0.03416575 -0.08943887 -0.07133560  0.08658507

iteration = 228
Step:
[1] -0.002636359  0.006237821  0.004712800 -0.006399752
Parameter:
[1] -1.1858767  1.4155934 -0.6812714  0.4775399
Function Value
[1] 7.831743
Gradient:
[1]  0.03489348 -0.09175409 -0.07383122  0.08871194

iteration = 229
Step:
[1] -0.002693930  0.006388468  0.004863937 -0.006558084
Parameter:
[1] -1.1885706  1.4219818 -0.6764074  0.4709818
Function Value
[1] 7.830099
Gradient:
[1]  0.03565220 -0.09418255 -0.07648403  0.09093473

iteration = 230
Step:
[1] -0.002753921  0.006545807  0.005023829 -0.006723650
Parameter:
[1] -1.1913245  1.4285277 -0.6713836  0.4642581
Function Value
[1] 7.828364
Gradient:
[1]  0.03644404 -0.09673275 -0.07930870  0.09325987

iteration = 231
Step:
[1] -0.002816485  0.006710280  0.005193229 -0.006896944
Parameter:
[1] -1.1941410  1.4352379 -0.6661904  0.4573612
Function Value
[1] 7.826531
Gradient:
[1]  0.03727133 -0.09941407 -0.08232167  0.09569434

iteration = 232
Step:
[1] -0.002881788  0.006882366  0.005372977 -0.007078503
Parameter:
[1] -1.1970228  1.4421203 -0.6608174  0.4502827
Function Value
[1] 7.824592
Gradient:
[1]  0.03813664 -0.10223682 -0.08554149  0.09824574

iteration = 233
Step:
[1] -0.002950010  0.007062584  0.005564011 -0.007268912
Parameter:
[1] -1.1999728  1.4491829 -0.6552534  0.4430138
Function Value
[1] 7.822536
Gradient:
[1]  0.03904278 -0.10521245 -0.08898914  0.10092232

iteration = 234
Step:
[1] -0.003021345  0.007251497  0.005767379 -0.007468810
Parameter:
[1] -1.202994  1.456434 -0.649486  0.435545
Function Value
[1] 7.820354
Gradient:
[1]  0.03999288 -0.10835361 -0.09268840  0.10373306

iteration = 235
Step:
[1] -0.003096002  0.007449714  0.005984262 -0.007678889
Parameter:
[1] -1.2060902  1.4638841 -0.6435017  0.4278661
Function Value
[1] 7.818035
Gradient:
[1]  0.04099036 -0.11167435 -0.09666634  0.10668771

iteration = 236
Step:
[1] -0.003174207  0.007657899  0.006215986 -0.007899908
Parameter:
[1] -1.2092644  1.4715420 -0.6372858  0.4199662
Function Value
[1] 7.815565
Gradient:
[1]  0.04203907 -0.11519033 -0.10095387  0.10979691

iteration = 237
Step:
[1] -0.003256205  0.007876767  0.006464050 -0.008132690
Parameter:
[1] -1.2125206  1.4794188 -0.6308217  0.4118335
Function Value
[1] 7.812931
Gradient:
[1]  0.04314325 -0.11891902 -0.10558648  0.11307222

iteration = 238
Step:
[1] -0.003342256  0.008107094  0.006730152 -0.008378136
Parameter:
[1] -1.2158628  1.4875259 -0.6240916  0.4034554
Function Value
[1] 7.810116
Gradient:
[1]  0.04430767 -0.12287995 -0.11060497  0.11652623

iteration = 239
Step:
[1] -0.003432644  0.008349719  0.007016221 -0.008637224
Parameter:
[1] -1.2192955  1.4958756 -0.6170753  0.3948181
Function Value
[1] 7.807101
Gradient:
[1]  0.04553766 -0.12709502 -0.11605656  0.12017260

iteration = 240
Step:
[1] -0.003527667  0.008605544  0.007324453 -0.008911018
Parameter:
[1] -1.2228231  1.5044811 -0.6097509  0.3859071
Function Value
[1] 7.803865
Gradient:
[1]  0.04683921 -0.13158887 -0.12199605  0.12402613

iteration = 241
Step:
[1] -0.003627648  0.008875539  0.007657362 -0.009200672
Parameter:
[1] -1.2264508  1.5133567 -0.6020935  0.3767064
Function Value
[1] 7.800385
Gradient:
[1]  0.04821911 -0.13638926 -0.12848739  0.12810283

iteration = 242
Step:
[1] -0.003732922  0.009160736  0.008017828 -0.009507431
Parameter:
[1] -1.2301837  1.5225174 -0.5940757  0.3671990
Function Value
[1] 7.796633
Gradient:
[1]  0.04968505 -0.14152753 -0.13560552  0.13241993

iteration = 243
Step:
[1] -0.003843843  0.009462228  0.008409165 -0.009832630
Parameter:
[1] -1.2340276  1.5319796 -0.5856665  0.3573664
Function Value
[1] 7.792576
Gradient:
[1]  0.0512458 -0.1470392 -0.1434387  0.1369959

iteration = 244
Step:
[1] -0.003960770  0.009781155  0.008835195 -0.010177691
Parameter:
[1] -1.2379883  1.5417608 -0.5768313  0.3471887
Function Value
[1] 7.788179
Gradient:
[1]  0.0529114 -0.1529645 -0.1520916  0.1418501

iteration = 245
Step:
[1] -0.004084066  0.010118687  0.009300340 -0.010544104
Parameter:
[1] -1.2420724  1.5518795 -0.5675310  0.3366446
Function Value
[1] 7.783398
Gradient:
[1]  0.05469341 -0.15934918 -0.16168847  0.14700314

iteration = 246
Step:
[1] -0.004214076  0.010475985  0.009809726 -0.010933400
Parameter:
[1] -1.2462865  1.5623554 -0.5577213  0.3257112
Function Value
[1] 7.778183
Gradient:
[1]  0.05660524 -0.16624535 -0.17237843  0.15247586

iteration = 247
Step:
[1] -0.004351111  0.010854154  0.010369306 -0.011347106
Parameter:
[1] -1.2506376  1.5732096 -0.5473520  0.3143641
Function Value
[1] 7.772476
Gradient:
[1]  0.05866248 -0.17371225 -0.18434078  0.15828912

iteration = 248
Step:
[1] -0.00449541  0.01125415  0.01098600 -0.01178666
Parameter:
[1] -1.2551330  1.5844637 -0.5363660  0.3025774
Function Value
[1] 7.766207
Gradient:
[1]  0.06088343 -0.18181730 -0.19779258  0.16446267

iteration = 249
Step:
[1] -0.004647087  0.011676654  0.011667832 -0.012253266
Parameter:
[1] -1.2597801  1.5961404 -0.5246981  0.2903242
Function Value
[1] 7.759293
Gradient:
[1]  0.06328968 -0.19063698 -0.21299799  0.17101369

iteration = 250
Step:
[1] -0.00480606  0.01212187  0.01242411 -0.01274772
Parameter:
[1] -1.2645861  1.6082623 -0.5122740  0.2775764
Function Value
[1] 7.751638
Gradient:
[1]  0.06590685 -0.20025769 -0.23028013  0.17795440

iteration = 251
Step:
[1] -0.004971922  0.012589202  0.013265527 -0.013270064
Parameter:
[1] -1.2695581  1.6208515 -0.4990085  0.2643064
Function Value
[1] 7.743122
Gradient:
[1]  0.06876556 -0.21077614 -0.25003598  0.18528881

iteration = 252
Step:
[1] -0.005143777  0.013076819  0.014204221 -0.013819056
Parameter:
[1] -1.2747018  1.6339283 -0.4848043  0.2504873
Function Value
[1] 7.733604
Gradient:
[1]  0.07190261 -0.22229897 -0.27275487  0.19300777

iteration = 253
Step:
[1] -0.005319969  0.013580919  0.015253670 -0.014391420
Parameter:
[1] -1.2800218  1.6475092 -0.4695506  0.2360959
Function Value
[1] 7.722915
Gradient:
[1]  0.07536234 -0.23494079 -0.29904076  0.20108228

iteration = 254
Step:
[1] -0.005497696  0.014094691  0.016428222 -0.014980621
Parameter:
[1] -1.2855195  1.6616039 -0.4531224  0.2211153
Function Value
[1] 7.710846
Gradient:
[1]  0.07919821 -0.24881934 -0.32963782  0.20945457

iteration = 255
Step:
[1] -0.005672434  0.014606741  0.017741942 -0.015575018
Parameter:
[1] -1.2911919  1.6762106 -0.4353804  0.2055403
Function Value
[1] 7.697149
Gradient:
[1]  0.0834743 -0.2640454 -0.3654569  0.2180272

iteration = 256
Step:
[1] -0.005837112  0.015098818  0.019206184 -0.016155105
Parameter:
[1] -1.2970291  1.6913095 -0.4161742  0.1893851
Function Value
[1] 7.681526
Gradient:
[1]  0.08826597 -0.28070412 -0.40759626  0.22665265

iteration = 257
Step:
[1] -0.005980959  0.015542597  0.020824808 -0.016689492
Parameter:
[1] -1.3030100  1.7068521 -0.3953494  0.1726957
Function Value
[1] 7.663627
Gradient:
[1]  0.09365835 -0.29882152 -0.45734220  0.23512830

iteration = 258
Step:
[1] -0.006088011  0.015895473  0.022585356 -0.017129406
Parameter:
[1] -1.3090980  1.7227475 -0.3727641  0.1555662
Function Value
[1] 7.643054
Gradient:
[1]  0.09973904 -0.31830893 -0.51612055  0.24321268

iteration = 259
Step:
[1] -0.006135451  0.016095753  0.024443657 -0.017402039
Parameter:
[1] -1.3152335  1.7388433 -0.3483204  0.1381642
Function Value
[1] 7.619384
Gradient:
[1]  0.1065787 -0.3388761 -0.5853482  0.2506899

iteration = 260
Step:
[1] -0.006092461  0.016059071  0.026299260 -0.017404793
Parameter:
[1] -1.3213259  1.7549024 -0.3220212  0.1207594
Function Value
[1] 7.592236
Gradient:
[1]  0.1141884 -0.3599107 -0.6661104  0.2575277

iteration = 261
Step:
[1] -0.005921301  0.015680699  0.027962047 -0.017006398
Parameter:
[1] -1.3272472  1.7705831 -0.2940591  0.1037530
Function Value
[1] 7.561392
Gradient:
[1]  0.1224411 -0.3803476 -0.7585970  0.2641605

iteration = 262
Step:
[1] -0.005583879  0.014852782  0.029122201 -0.016067415
Parameter:
[1] -1.3328311  1.7854358 -0.2649369  0.0876856
Function Value
[1] 7.527022
Gradient:
[1]  0.1309578 -0.3986110 -0.8613405  0.2718043

iteration = 263
Step:
[1] -0.00505755  0.01350725  0.02936261 -0.01449660
Parameter:
[1] -1.3378887  1.7989431 -0.2355743  0.0731890
Function Value
[1] 7.489963
Gradient:
[1]  0.1390161 -0.4128078 -0.9705997  0.2823647

iteration = 264
Step:
[1] -0.004358855  0.011681670  0.028281146 -0.012342320
Parameter:
[1] -1.34224752  1.81062475 -0.20729316  0.06084668
Function Value
[1] 7.451902
Gradient:
[1]  0.1456331 -0.4213471 -1.0805636  0.2971931

iteration = 265
Step:
[1] -0.003559457  0.009565489  0.025745609 -0.009858497
Parameter:
[1] -1.34580698  1.82019024 -0.18154755  0.05098818
Function Value
[1] 7.415164
Gradient:
[1]  0.1499635 -0.4238275 -1.1847934  0.3148880

iteration = 266
Step:
[1] -0.002768339  0.007454190  0.022108437 -0.007435473
Parameter:
[1] -1.34857532  1.82764443 -0.15943911  0.04355271
Function Value
[1] 7.381974
Gradient:
[1]  0.1518107 -0.4214301 -1.2781434  0.3308620

iteration = 267
Step:
[1] -0.002080514  0.005609459  0.018080534 -0.005395605
Parameter:
[1] -1.3506558  1.8332539 -0.1413586  0.0381571
Function Value
[1] 7.353669
Gradient:
[1]  0.1517113 -0.4162177 -1.3578154  0.3406742

iteration = 268
Step:
[1] -0.001537624  0.004149182  0.014314266 -0.003851603
Parameter:
[1] -1.3521935  1.8374031 -0.1270443  0.0343055
Function Value
[1] 7.330501
Gradient:
[1]  0.1504915 -0.4100228 -1.4232840  0.3432953

iteration = 269
Step:
[1] -0.001132833  0.003058500  0.011138118 -0.002749208
Parameter:
[1] -1.35332629  1.84046157 -0.11590620  0.03155629
Function Value
[1] 7.312001
Gradient:
[1]  0.1488283 -0.4039555 -1.4756478  0.3405442

iteration = 270
Step:
[1] -0.0008382663  0.0022639935  0.0086035191 -0.0019788217
Parameter:
[1] -1.35416455  1.84272556 -0.10730268  0.02957747
Function Value
[1] 7.297427
Gradient:
[1]  0.1471234 -0.3985245 -1.5168270  0.3348799

iteration = 271
Step:
[1] -0.0006248828  0.0016880779  0.0066327562 -0.0014406778
Parameter:
[1] -1.35478944  1.84441364 -0.10066992  0.02813679
Function Value
[1] 7.286022
Gradient:
[1]  0.1455666 -0.3938909 -1.5489133  0.3281779

iteration = 272
Step:
[1] -0.0004695128  0.0012685577  0.0051163639 -0.0010612248
Parameter:
[1] -1.35525895  1.84568220 -0.09555356  0.02707557
Function Value
[1] 7.277123
Gradient:
[1]  0.1442260 -0.3900472 -1.5738091  0.3215492

iteration = 273
Step:
[1] -0.0004184343  0.0011306548  0.0046706213 -0.0009311659
Parameter:
[1] -1.35567738  1.84681285 -0.09088293  0.02614440
Function Value
[1] 7.268924
Gradient:
[1]  0.1428850 -0.3863839 -1.5966171  0.3142561

iteration = 274
Step:
[1] -0.0004139885  0.0011187654  0.0047360845 -0.0009064536
Parameter:
[1] -1.35609137  1.84793162 -0.08614685  0.02523795
Function Value
[1] 7.260538
Gradient:
[1]  0.1414371 -0.3825077 -1.6197478  0.3058527

iteration = 275
Step:
[1] -0.0004092705  0.0011061489  0.0048022603 -0.0008791113
Parameter:
[1] -1.35650064  1.84903777 -0.08134459  0.02435884
Function Value
[1] 7.25196
Gradient:
[1]  0.1398940 -0.3783769 -1.6431346  0.2965371

iteration = 276
Step:
[1] -0.0004042638  0.0010927274  0.0048690041 -0.0008494783
Parameter:
[1] -1.35690491  1.85013050 -0.07647559  0.02350936
Function Value
[1] 7.243187
Gradient:
[1]  0.1382498 -0.3739643 -1.6667268  0.2864244

iteration = 277
Step:
[1] -0.0003989469  0.0010784391  0.0049361956 -0.0008177443
Parameter:
[1] -1.35730385  1.85120893 -0.07153939  0.02269161
Function Value
[1] 7.234215
Gradient:
[1]  0.1364972 -0.3692484 -1.6904818  0.2755787

iteration = 278
Step:
[1] -0.0003933002  0.0010632308  0.0050037256 -0.0007840070
Parameter:
[1] -1.35769715  1.85227217 -0.06653566  0.02190761
Function Value
[1] 7.225042
Gradient:
[1]  0.1346291 -0.3642104 -1.7143611  0.2640326

iteration = 279
Step:
[1] -0.0003873057  0.0010470537  0.0050714886 -0.0007483084
Parameter:
[1] -1.35808446  1.85331922 -0.06146418  0.02115930
Function Value
[1] 7.215663
Gradient:
[1]  0.1326393 -0.3588332 -1.7383271  0.2517999

iteration = 280
Step:
[1] -0.0003809464  0.0010298621  0.0051393779 -0.0007106568
Parameter:
[1] -1.35846541  1.85434908 -0.05632480  0.02044864
Function Value
[1] 7.206076
Gradient:
[1]  0.1305217 -0.3531006 -1.7623422  0.2388828

iteration = 281
Step:
[1] -0.0003742064  0.0010116117  0.0052072828 -0.0006710414
Parameter:
[1] -1.35883961  1.85536069 -0.05111752  0.01977760
Function Value
[1] 7.196278
Gradient:
[1]  0.1282707 -0.3469969 -1.7863668  0.2252771

iteration = 282
Step:
[1] -0.0003670699  0.0009922596  0.0052750869 -0.0006294405
Parameter:
[1] -1.35920668  1.85635295 -0.04584243  0.01914816
Function Value
[1] 7.186266
Gradient:
[1]  0.1258808 -0.3405068 -1.8103596  0.2109748

iteration = 283
Step:
[1] -0.0003595216  0.0009717634  0.0053426670 -0.0005858277
Parameter:
[1] -1.35956620  1.85732472 -0.04049976  0.01856233
Function Value
[1] 7.176038
Gradient:
[1]  0.1233465 -0.3336154 -1.8342767  0.1959666

iteration = 284
Step:
[1] -0.0003515466  0.0009500817  0.0054098927 -0.0005401760
Parameter:
[1] -1.35991775  1.85827480 -0.03508987  0.01802216
Function Value
[1] 7.165593
Gradient:
[1]  0.1206624 -0.3263080 -1.8580717  0.1802427

iteration = 285
Step:
[1] -0.0003431301  0.0009271738  0.0054766262 -0.0004924597
Parameter:
[1] -1.36026088  1.85920197 -0.02961324  0.01752970
Function Value
[1] 7.154927
Gradient:
[1]  0.1178233 -0.3185700 -1.8816954  0.1637942

iteration = 286
Step:
[1] -0.0003342577  0.0009030000  0.0055427221 -0.0004426573
Parameter:
[1] -1.36059514  1.86010497 -0.02407052  0.01708704
Function Value
[1] 7.14404
Gradient:
[1]  0.1148242 -0.3103874 -1.9050959  0.1466133

iteration = 287
Step:
[1] -0.0003249153  0.0008775216  0.0056080276 -0.0003907520
Parameter:
[1] -1.36092005  1.86098249 -0.01846249  0.01669629
Function Value
[1] 7.132932
Gradient:
[1]  0.1116599 -0.3017465 -1.9282187  0.1286944

iteration = 288
Step:
[1] -0.0003150895  0.0008507012  0.0056723832 -0.0003367338
Parameter:
[1] -1.36123514  1.86183319 -0.01279011  0.01635955
Function Value
[1] 7.121602
Gradient:
[1]  0.1083258 -0.2926339 -1.9510069  0.1100340

iteration = 289
Step:
[1] -0.0003047671  0.0008225031  0.0057356227 -0.0002806000
Parameter:
[1] -1.361539909  1.862655698 -0.007054487  0.016078953
Function Value
[1] 7.110049
Gradient:
[1]  0.10481710 -0.28303704 -1.97340101  0.09063127

iteration = 290
Step:
[1] -0.0002939359  0.0007928937  0.0057975741 -0.0002223560
Parameter:
[1] -1.361833845  1.863448591 -0.001256913  0.015856597
Function Value
[1] 7.098276
Gradient:
[1]  0.10112950 -0.27294398 -1.99533961  0.07048836

iteration = 291
Step:
[1] -0.0002825843  0.0007618415  0.0058580602 -0.0001620167
Parameter:
[1] -1.362116430  1.864210433  0.004601147  0.015694580
Function Value
[1] 7.086282
Gradient:
[1]  0.09725889 -0.26234356 -2.01675934  0.04961075

iteration = 292
Step:
[1] -2.707017e-04  7.293175e-04  5.916900e-03 -9.960662e-05
Parameter:
[1] -1.36238713  1.86493975  0.01051805  0.01559497
Function Value
[1] 7.07407
Gradient:
[1]  0.09320147 -0.25122561 -2.03759533  0.02800742

iteration = 293
Step:
[1] -2.582784e-04  6.952961e-04  5.973908e-03 -3.516094e-05
Parameter:
[1] -1.36264541  1.86563505  0.01649196  0.01555981
Function Value
[1] 7.061642
Gradient:
[1]  0.088953859 -0.239581012 -2.057781511  0.005691109

iteration = 294
Step:
[1] -0.0002453060  0.0006597547  0.0060288991  0.0000312741
Parameter:
[1] -1.36289072  1.86629480  0.02252085  0.01559109
Function Value
[1] 7.049001
Gradient:
[1]  0.08451306 -0.22740189 -2.07725110 -0.01732145

iteration = 295
Step:
[1] -2.317773e-04  6.226745e-04  6.081685e-03  9.964065e-05
Parameter:
[1] -1.36312249  1.86691748  0.02860254  0.01569073
Function Value
[1] 7.03615
Gradient:
[1]  0.07987657 -0.21468170 -2.09593703 -0.04100939

iteration = 296
Step:
[1] -0.0002176867  0.0005840409  0.0061320805  0.0001698689
Parameter:
[1] -1.36334018  1.86750152  0.03473462  0.01586060
Function Value
[1] 7.023095
Gradient:
[1]  0.07504237 -0.20141541 -2.11377244 -0.06534756

iteration = 297
Step:
[1] -0.0002030298  0.0005438438  0.0061799004  0.0002418768
Parameter:
[1] -1.36354321  1.86804536  0.04091452  0.01610247
Function Value
[1] 7.00984
Gradient:
[1]  0.07000905 -0.18759959 -2.13069124 -0.09030646

iteration = 298
Step:
[1] -0.0001878044  0.0005020778  0.0062249647  0.0003155700
Parameter:
[1] -1.36373101  1.86854744  0.04713949  0.01641804
Function Value
[1] 6.99639
Gradient:
[1]  0.06477578 -0.17323260 -2.14662870 -0.11585216

iteration = 299
Step:
[1] -0.0001720097  0.0004587430  0.0062670988  0.0003908418
Parameter:
[1] -1.36390302  1.86900618  0.05340658  0.01680888
Function Value
[1] 6.982753
Gradient:
[1]  0.0593424 -0.1583146 -2.1615220 -0.1419463

iteration = 300
Step:
[1] -0.0001556471  0.0004138446  0.0063061351  0.0004675732
Parameter:
[1] -1.36405867  1.86942003  0.05971272  0.01727646
Function Value
[1] 6.968934
Gradient:
[1]  0.05370944 -0.14284796 -2.17531091 -0.16854625

iteration = 301
Step:
[1] -0.0001387197  0.0003673939  0.0063419153  0.0005456335
Parameter:
[1] -1.36419739  1.86978742  0.06605463  0.01782209
Function Value
[1] 6.954941
Gradient:
[1]  0.04787819 -0.12683686 -2.18793835 -0.19560509

iteration = 302
Step:
[1] -0.0001212331  0.0003194081  0.0063742916  0.0006248808
Parameter:
[1] -1.36431862  1.87010683  0.07242893  0.01844697
Function Value
[1] 6.940783
Gradient:
[1]  0.04185068 -0.11028785 -2.19935107 -0.22307190

iteration = 303
Step:
[1] -0.0001031949  0.0002699107  0.0064031289  0.0007051624
Parameter:
[1] -1.36442182  1.87037674  0.07883205  0.01915213
Function Value
[1] 6.926468
Gradient:
[1]  0.03562975 -0.09320973 -2.20950020 -0.25089198

iteration = 304
Step:
[1] -9.811953e-05  2.532129e-04  7.833597e-03  9.674545e-04
Parameter:
[1] -1.36451994  1.87062995  0.08666565  0.02011959
Function Value
[1] 6.908833
Gradient:
[1]  0.02783484 -0.07184915 -2.22005409 -0.28555359

iteration = 305
Step:
[1] -8.500062e-05  2.083276e-04  1.264357e-02  1.791238e-03
Parameter:
[1] -1.36460494  1.87083828  0.09930923  0.02191083
Function Value
[1] 6.880101
Gradient:
[1]  0.01505217 -0.03690437 -2.23213149 -0.34607263

iteration = 306
Step:
[1]  6.866834e-05 -2.278978e-04  2.171840e-02  3.703621e-03
Parameter:
[1] -1.36453627  1.87061038  0.12102762  0.02561445
Function Value
[1] 6.830027
Gradient:
[1] -0.007150475  0.023725343 -2.235765976 -0.470485388

iteration = 307
Step:
[1]  0.0008930246 -0.0025116882  0.0413633843  0.0090990279
Parameter:
[1] -1.36364325  1.86809869  0.16239100  0.03471348
Function Value
[1] 6.732601
Gradient:
[1] -0.0495586  0.1380786 -2.1629349 -0.8087591

iteration = 308
Step:
[1]  0.005865902 -0.016141497  0.094875070  0.029875323
Parameter:
[1] -1.3577773  1.8519572  0.2572661  0.0645888
Function Value
[1] 6.507164
Gradient:
[1] -0.1545740  0.3679696 -1.3375572 -2.3140200

iteration = 309
Step:
[1]  0.02006263 -0.05440251  0.10010924  0.05284849
Parameter:
[1] -1.3377147  1.7975547  0.3573753  0.1174373
Function Value
[1] 6.248449
Gradient:
[1] -0.35512495  0.25067082  0.03730303 -3.88655296

iteration = 310
Step:
[1]  0.02188923 -0.05841428  0.07399841  0.05621233
Parameter:
[1] -1.3158255  1.7391404  0.4313737  0.1736496
Function Value
[1] 6.027426
Gradient:
[1] -0.5559061  0.1176393  0.7936289 -4.2953588

iteration = 311
Step:
[1]  0.03332685 -0.08742050  0.09295190  0.08510893
Parameter:
[1] -1.2824986  1.6517199  0.5243256  0.2587586
Function Value
[1] 5.738526
Gradient:
[1] -1.0164932 -0.1284048  2.0987440 -4.9776095

iteration = 312
Step:
[1]  0.05846274 -0.14920984  0.13131071  0.14683807
Parameter:
[1] -1.2240359  1.5025101  0.6556363  0.4055966
Function Value
[1] 5.32447
Gradient:
[1] -2.3690722 -0.7692439  5.0379018 -6.4244787

iteration = 313
Step:
[1]  0.1747267 -0.4230126  0.2957624  0.4226206
Parameter:
[1] -1.0493091  1.0794975  0.9513987  0.8282173
Function Value
[1] 4.87277
Gradient:
[1] -13.144583  -6.105887  26.255796 -15.745569

iteration = 314
Step:
[1]  0.11774003 -0.21875350  0.08477023  0.24530965
Parameter:
[1] -0.9315691  0.8607440  1.0361689  1.0735269
Function Value
[1] 3.785008
Gradient:
[1] -6.5002322 -2.7725430  0.1167958 -1.2934785

iteration = 315
Step:
[1]  0.06982201 -0.12788026  0.06405534  0.13315099
Parameter:
[1] -0.8617471  0.7328637  1.1002243  1.2066779
Function Value
[1] 3.545955
Gradient:
[1] -7.082359 -3.252800  1.711729 -1.801210

iteration = 316
Step:
[1]  0.11515467 -0.19289882  0.09019494  0.20082346
Parameter:
[1] -0.7465924  0.5399649  1.1904192  1.4075014
Function Value
[1] 3.228392
Gradient:
[1] -8.700028 -4.711254  4.493461 -2.604551

iteration = 317
Step:
[1]  0.2156264 -0.2993173  0.1270091  0.3144900
Parameter:
[1] -0.5309660  0.2406477  1.3174283  1.7219913
Function Value
[1] 2.865106
Gradient:
[1] -11.828669  -9.298948   7.097325  -2.903635

iteration = 318
Step:
[1]  0.11064105 -0.07144231  0.02355367  0.07736808
Parameter:
[1] -0.4203250  0.1692053  1.3409820  1.7993594
Function Value
[1] 2.414905
Gradient:
[1] -4.09620488 -2.44828837  0.13802217 -0.09985956

iteration = 319
Step:
[1]  0.07856286 -0.06315544  0.02297008  0.06174204
Parameter:
[1] -0.3417621  0.1060499  1.3639521  1.8611014
Function Value
[1] 2.263206
Gradient:
[1] -4.1533001 -3.1582739  0.3663989 -0.1734415

iteration = 320
Step:
[1]  0.11723001 -0.07365959  0.02630053  0.07212986
Parameter:
[1] -0.22453212  0.03239031  1.39025259  1.93323130
Function Value
[1] 2.057419
Gradient:
[1] -4.0678835 -4.6726082  0.5657692 -0.2301704

iteration = 321
Step:
[1]  0.21158548 -0.07141935  0.02491830  0.07050777
Parameter:
[1] -0.01294665 -0.03902903  1.41517088  2.00373907
Function Value
[1] 1.781905
Gradient:
[1] -2.2288793 -8.9536830  0.3053708 -0.1117659

iteration = 322
Step:
[1]  0.11302900  0.04161731 -0.01439565 -0.04019124
Parameter:
[1] 0.100082350 0.002588272 1.400775235 1.963547835
Function Value
[1] 1.372165
Gradient:
[1] -1.50246242 -2.55511074  0.10737192 -0.03730225

iteration = 323
Step:
[1]  0.064341692  0.014854609 -0.005157927 -0.014431460
Parameter:
[1] 0.16442404 0.01744288 1.39561731 1.94911638
Function Value
[1] 1.248389
Gradient:
[1] -1.04026446 -2.97362649  0.10356697 -0.03611334

iteration = 324
Step:
[1]  0.09084499  0.03369663 -0.01173278 -0.03272887
Parameter:
[1] 0.25526903 0.05113951 1.38388453 1.91638750
Function Value
[1] 1.080256
Gradient:
[1] -0.05763018 -3.82706368  0.14447002 -0.05121106

iteration = 325
Step:
[1]  0.25461304  0.14839913 -0.05209732 -0.14406540
Parameter:
[1] 0.5098821 0.1995386 1.3317872 1.7723221
Function Value
[1] 0.9710543
Gradient:
[1]  11.3468963 -12.9655605   1.3036715  -0.4885435

iteration = 326
Step:
[1]  0.06588771  0.13128122 -0.04841710 -0.12649393
Parameter:
[1] 0.5757698 0.3308199 1.2833701 1.6458282
Function Value
[1] 0.4388274
Gradient:
[1] -0.6893211 -0.8682380  1.1260873 -0.4219589

iteration = 327
Step:
[1]  0.04500093  0.05196585 -0.01957376 -0.05010023
Parameter:
[1] 0.6207707 0.3827857 1.2637963 1.5957279
Function Value
[1] 0.3659937
Gradient:
[1] -0.1201627 -1.1864310  1.1887813 -0.4487268

iteration = 328
Step:
[1]  0.06112031  0.07654035 -0.02931110 -0.07377156
Parameter:
[1] 0.6818910 0.4593261 1.2344852 1.5219564
Function Value
[1] 0.276149
Gradient:
[1]  0.9046706 -1.7167415  1.3566622 -0.5213644

iteration = 329
Step:
[1]  0.10399730  0.14499171 -0.05699756 -0.13965857
Parameter:
[1] 0.7858883 0.6043178 1.1774877 1.3822978
Function Value
[1] 0.1589307
Gradient:
[1]  3.7535543 -3.0838264  2.1266241 -0.8643928

iteration = 330
Step:
[1]  0.10397853  0.17779309 -0.07435724 -0.17070737
Parameter:
[1] 0.8898669 0.7821109 1.1031304 1.2115904
Function Value
[1] 0.05365187
Gradient:
[1]  3.2509926 -2.1623071  2.3135529 -0.9952199

iteration = 331
Step:
[1]  0.06060113  0.11799188 -0.05387736 -0.11357228
Parameter:
[1] 0.9504680 0.9001027 1.0492531 1.0980182
Function Value
[1] 0.01067604
Gradient:
[1]  1.1504862 -0.7344993  1.1991718 -0.5224985

iteration = 332
Step:
[1]  0.03778046  0.07517374 -0.03639316 -0.07349035
Parameter:
[1] 0.9882485 0.9752765 1.0128599 1.0245278
Function Value
[1] 0.00089683
Gradient:
[1]  0.5135270 -0.2854727  0.5206823 -0.2384031

iteration = 333
Step:
[1]  0.01026419  0.02165227 -0.01126125 -0.02146102
Parameter:
[1] 0.9985126 0.9969287 1.0015987 1.0030668
Function Value
[1] 1.110667e-05
Gradient:
[1]  0.03647400 -0.02107072  0.05120412 -0.02282682

iteration = 334
Step:
[1]  0.001469939  0.003034332 -0.001578848 -0.003029705
Parameter:
[1] 0.9999826 0.9999631 1.0000198 1.0000371
Function Value
[1] 2.292034e-09
Gradient:
[1]  0.0008061652 -0.0004321440  0.0009730295 -0.0004486970

iteration = 335
Parameter:
[1] 1 1 1 1
Function Value
[1] 1.004941e-16
Gradient:
[1]  1.065983e-07 -6.062012e-08  1.601571e-07 -7.082200e-08

Relative gradient close to zero.
Current iterate is probably solution.

> print(t1nlmo)
$convergence
[1] 0

$value
[1] 1.004941e-16

$par
[1] 1 1 1 1

$counts
[1]  NA 335

$message
[1] "nlm: Convergence indicator (code) =  1"

> 
> ## FOLLOWING SHOWS UP ERRORS??
> t1nlminbo <- optimr(x0, wood.f, wood.g, hess=wood.h, method="nlminb", control=list(trace=1))
Parameter scaling:[1] 1 1 1 1
  0:     19192.000: -3.00000 -1.00000 -3.00000 -1.00000
  1:     7844.8110: -2.34188 -0.814182 -2.36728 -0.827234
  2:     1216.1133: -1.68443 0.393908 -1.69404 0.313883
  3:     63.588133: -1.45306  1.71905 -1.44613  1.65143
  4:     16.494685: -1.19893  1.31181 -1.19548  1.29854
  5:     8.5754053: -1.04247  1.05440 -1.02968  1.02406
  6:     7.8893787: -0.984105 0.972760 -0.971950 0.949965
  7:     7.8769236: -0.977607 0.965750 -0.960225 0.933163
  8:     7.8762403: -1.00695  1.02307 -0.929896 0.875292
  9:     7.8736524: -1.06370  1.13800 -0.867196 0.759942
 10:     7.8639782: -1.11594  1.25222 -0.798496 0.645011
 11:     7.8548631: -1.13591  1.29937 -0.765236 0.596982
 12:     7.8409865: -1.21945  1.48926 -0.637546 0.403740
 13:     7.7765044: -1.25895  1.59258 -0.545841 0.302611
 14:     7.7110154: -1.29377  1.68164 -0.448823 0.206860
 15:     7.6479639: -1.36018  1.85456 -0.237404 0.0279485
 16:     7.3414193: -1.36613  1.87495 -0.131228 0.0197128
 17:     7.1459204: -1.36939  1.88395 -0.0220586 0.00419477
 18:     6.8499981: -1.37092  1.88810 0.199369 0.00469949
 19:     6.2503936: -1.33300  1.78413 0.360771 0.116495
 20:     5.7947116: -1.29523  1.68459 0.513971 0.245855
 21:     5.3563474: -1.24407  1.55349 0.629984 0.387008
 22:     4.7857877: -1.13048  1.27366 0.840203 0.665704
 23:     4.0497195: -0.992126 0.973269 0.983984 0.954618
 24:     3.5179818: -0.841522 0.692665  1.12885  1.25650
 25:     3.0488024: -0.658857 0.407011  1.24823  1.54704
 26:     2.6325343: -0.500037 0.229669  1.31902  1.73685
 27:     2.3059389: -0.307769 0.0630001  1.38020  1.90295
 28:     1.9350808: -0.174234 0.0178386  1.39533  1.94834
 29:     1.6534354: -0.0296107 -0.0129818  1.40343  1.97124
 30:     1.5716753: 0.234877 -0.00937673  1.40482  1.97512
 31:    0.94438690: 0.306481 0.0937164  1.36921  1.87497
 32:    0.74178203: 0.438677 0.174107  1.34892  1.82029
 33:    0.53974471: 0.526746 0.269899  1.31329  1.72450
 34:    0.40832177: 0.737124 0.500274  1.22372  1.49026
 35:    0.12697466: 0.792936 0.627489  1.16789  1.36128
 36:   0.058109409: 0.874374 0.757557  1.11579  1.24255
 37:   0.014841604: 0.942386 0.883727  1.05723  1.11444
 38:  0.0015171246: 0.983721 0.966104  1.01742  1.03352
 39: 2.9694242e-05: 0.997648 0.995118  1.00255  1.00487
 40: 1.6239262e-08: 0.999951 0.999896  1.00006  1.00010
 41: 5.1701713e-15:  1.00000  1.00000  1.00000  1.00000
 42: 1.4404033e-27:  1.00000  1.00000  1.00000  1.00000
 43: 7.3028059e-28:  1.00000  1.00000  1.00000  1.00000
 44: 4.7923300e-29:  1.00000  1.00000  1.00000  1.00000
 45: 4.7923300e-29:  1.00000  1.00000  1.00000  1.00000
> print(t1nlminb)
$par
[1] 1 1 1 1

$objective
[1] 4.79233e-29

$convergence
[1] 0

$iterations
[1] 45

$evaluations
function gradient 
      56       45 

$message
[1] "X-convergence (3)"

> 
> 
> # sink()
> 
