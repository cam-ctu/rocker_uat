
R version 4.4.3 (2025-02-28) -- "Trophy Case"
Copyright (C) 2025 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "rstanarm"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('rstanarm')
Loading required package: Rcpp
This is rstanarm version 2.32.1
- See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!
- Default priors may change, so it's safest to specify priors, even if equivalent to the defaults.
- For execution on a local, multicore CPU with excess RAM we recommend calling
  options(mc.cores = parallel::detectCores())
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("as.matrix.stanreg")
> ### * as.matrix.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: as.matrix.stanreg
> ### Title: Extract the posterior sample
> ### Aliases: as.matrix.stanreg as.array.stanreg as.data.frame.stanreg
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ }
NULL
> 
> 
> 
> cleanEx()
> nameEx("bayes_R2.stanreg")
> ### * bayes_R2.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bayes_R2.stanreg
> ### Title: Compute a Bayesian version of R-squared or LOO-adjusted
> ###   R-squared for regression models.
> ### Aliases: bayes_R2.stanreg bayes_R2 loo_R2.stanreg loo_R2
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ fit <- stan_glm(
+   mpg ~ wt + cyl, 
+   data = mtcars, 
+   QR = TRUE, 
+   chains = 2, 
+   refresh = 0
+ )
+ rsq <- bayes_R2(fit)
+ print(median(rsq))
+ hist(rsq)
+ 
+ loo_rsq <- loo_R2(fit)
+ print(median(loo_rsq))
+ 
+ # multilevel binomial model
+ if (!exists("example_model")) example(example_model)
+ print(example_model)
+ median(bayes_R2(example_model))
+ median(bayes_R2(example_model, re.form = NA)) # exclude group-level
+ }
[1] 0.8157955
[1] 0.7981092

exmpl_> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
exmpl_+ example_model <- 
exmpl_+   stan_glmer(cbind(incidence, size - incidence) ~ size + period + (1|herd),
exmpl_+              data = lme4::cbpp, family = binomial, QR = TRUE,
exmpl_+              # this next line is only to keep the example small in size!
exmpl_+              chains = 2, cores = 1, seed = 12345, iter = 1000, refresh = 0)
exmpl_+ example_model
exmpl_+ }
stan_glmer
 family:       binomial [logit]
 formula:      cbind(incidence, size - incidence) ~ size + period + (1 | herd)
 observations: 56
------
            Median MAD_SD
(Intercept) -1.5    0.6  
size         0.0    0.0  
period2     -1.0    0.3  
period3     -1.1    0.4  
period4     -1.6    0.5  

Error terms:
 Groups Name        Std.Dev.
 herd   (Intercept) 0.76    
Num. levels: herd 15 

------
* For help interpreting the printed output see ?print.stanreg
* For info on the priors used see ?prior_summary.stanreg
stan_glmer
 family:       binomial [logit]
 formula:      cbind(incidence, size - incidence) ~ size + period + (1 | herd)
 observations: 56
------
            Median MAD_SD
(Intercept) -1.5    0.6  
size         0.0    0.0  
period2     -1.0    0.3  
period3     -1.1    0.4  
period4     -1.6    0.5  

Error terms:
 Groups Name        Std.Dev.
 herd   (Intercept) 0.76    
Num. levels: herd 15 

------
* For help interpreting the printed output see ?print.stanreg
* For info on the priors used see ?prior_summary.stanreg
[1] 0.6206511
> 
> 
> 
> cleanEx()
> nameEx("example_jm")
> ### * example_jm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: example_jm
> ### Title: Example joint longitudinal and time-to-event model
> ### Aliases: example_jm
> 
> ### ** Examples
> 
>   # set.seed(123)
>   if (.Platform$OS.type != "windows" || .Platform$r_arch !="i386")
+   example_jm <- 
+      stan_jm(formulaLong = logBili ~ year + (1 | id), 
+              dataLong = pbcLong[1:101,],
+              formulaEvent = survival::Surv(futimeYears, death) ~ sex + trt, 
+              dataEvent = pbcSurv[1:15,],
+              time_var = "year",
+              # this next line is only to keep the example small in size!
+              chains = 1, seed = 12345, iter = 100, refresh = 0)
Loading required namespace: data.table
Fitting a univariate joint model.

Please note the warmup may be much slower than later iterations!
Warning: The largest R-hat is 1.07, indicating chains have not mixed.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#r-hat
Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#bulk-ess
Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#tail-ess
> 
> 
> 
> 
> 
> cleanEx()
> nameEx("example_model")
> ### * example_model
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: example_model
> ### Title: Example model
> ### Aliases: example_model
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ example_model <- 
+   stan_glmer(cbind(incidence, size - incidence) ~ size + period + (1|herd),
+              data = lme4::cbpp, family = binomial, QR = TRUE,
+              # this next line is only to keep the example small in size!
+              chains = 2, cores = 1, seed = 12345, iter = 1000, refresh = 0)
+ example_model
+ }
stan_glmer
 family:       binomial [logit]
 formula:      cbind(incidence, size - incidence) ~ size + period + (1 | herd)
 observations: 56
------
            Median MAD_SD
(Intercept) -1.5    0.6  
size         0.0    0.0  
period2     -1.0    0.3  
period3     -1.1    0.4  
period4     -1.6    0.5  

Error terms:
 Groups Name        Std.Dev.
 herd   (Intercept) 0.76    
Num. levels: herd 15 

------
* For help interpreting the printed output see ?print.stanreg
* For info on the priors used see ?prior_summary.stanreg
> 
> 
> 
> cleanEx()
> nameEx("kfold.stanreg")
> ### * kfold.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: kfold.stanreg
> ### Title: K-fold cross-validation
> ### Aliases: kfold.stanreg kfold
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ }
NULL
> # Example code demonstrating the different ways to specify the number 
> # of cores and how the cores are used
> # 
> # options(mc.cores = NULL)
> # 
> # # spread the K models over N_CORES cores (method 1)
> # kfold(fit, K, cores = N_CORES)
> # 
> # # spread the K models over N_CORES cores (method 2)
> # options(mc.cores = N_CORES)
> # kfold(fit, K)
> #  
> # # fit K models sequentially using N_CORES cores for the Markov chains each time
> # options(mc.cores = N_CORES)
> # kfold(fit, K, cores = 1)
> 
> 
> 
> 
> cleanEx()
> nameEx("launch_shinystan.stanreg")
> ### * launch_shinystan.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: launch_shinystan.stanreg
> ### Title: Using the ShinyStan GUI with rstanarm models
> ### Aliases: launch_shinystan.stanreg launch_shinystan
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ ## Not run: 
+ ##D if (!exists("example_model")) example(example_model) 
+ ##D 
+ ##D # Launch the ShinyStan app without saving the resulting shinystan object
+ ##D if (interactive()) launch_shinystan(example_model)
+ ##D 
+ ##D # Launch the ShinyStan app (saving resulting shinystan object as sso)
+ ##D if (interactive()) sso <- launch_shinystan(example_model)
+ ##D 
+ ##D # First create shinystan object then call launch_shinystan
+ ##D sso <- shinystan::as.shinystan(example_model)
+ ##D if (interactive()) launch_shinystan(sso)
+ ##D 
+ ##D # Prevent ShinyStan from preparing graphical posterior predictive checks that
+ ##D # can be time consuming. example_model is small enough that it won't matter
+ ##D # much here but in general this can help speed up launch_shinystan
+ ##D sso <- shinystan::as.shinystan(example_model, ppd = FALSE)
+ ##D if (interactive()) launch_shinystan(sso)
+ ## End(Not run)
+ }
NULL
> 
> 
> 
> cleanEx()
> nameEx("log_lik.stanreg")
> ### * log_lik.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: log_lik.stanreg
> ### Title: Pointwise log-likelihood matrix
> ### Aliases: log_lik.stanreg log_lik log_lik.stanmvreg log_lik.stanjm
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ }
NULL
> 
> 
> 
> cleanEx()
> nameEx("loo.stanreg")
> ### * loo.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: loo.stanreg
> ### Title: Information criteria and cross-validation
> ### Aliases: loo.stanreg loo waic.stanreg waic loo_compare.stanreg
> ###   loo_compare loo_compare.stanreg_list loo_model_weights.stanreg_list
> ###   loo_model_weights compare_models
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ }
NULL
> 
> 
> 
> cleanEx()
> nameEx("loo_predict.stanreg")
> ### * loo_predict.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: loo_predict.stanreg
> ### Title: Compute weighted expectations using LOO
> ### Aliases: loo_predict.stanreg loo_predict loo_linpred
> ###   loo_predictive_interval loo_linpred.stanreg
> ###   loo_predictive_interval.stanreg
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ ## Not run: 
+ ##D if (!exists("example_model")) example(example_model)
+ ##D 
+ ##D # optionally, log-weights can be pre-computed and reused
+ ##D psis_result <- loo::psis(log_ratios = -log_lik(example_model))
+ ##D 
+ ##D loo_probs <- loo_linpred(example_model, type = "mean", transform = TRUE, psis_object = psis_result)
+ ##D str(loo_probs)
+ ##D 
+ ##D loo_pred_var <- loo_predict(example_model, type = "var", psis_object = psis_result)
+ ##D str(loo_pred_var)
+ ##D 
+ ##D loo_pred_ints <- loo_predictive_interval(example_model, prob = 0.8, psis_object = psis_result)
+ ##D str(loo_pred_ints)
+ ## End(Not run)
+ }
NULL
> 
> 
> 
> cleanEx()
> nameEx("neg_binomial_2")
> ### * neg_binomial_2
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: neg_binomial_2
> ### Title: Family function for negative binomial GLMs
> ### Aliases: neg_binomial_2
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386")
+ stan_glm(Days ~ Sex/(Age + Eth*Lrn), data = MASS::quine, seed = 123,
+          family = neg_binomial_2, QR = TRUE, algorithm = "optimizing") 
Warning: Pareto k diagnostic value is 0.79. Resampling is unreliable. Increasing the number of draws or decreasing tol_rel_grad may help.
stan_glm
 family:       neg_binomial_2 [log]
 formula:      Days ~ Sex/(Age + Eth * Lrn)
 observations: 146
 predictors:   14
------
                Median MAD_SD
(Intercept)      3.1    0.3  
SexM            -0.5    0.5  
SexF:AgeF1      -0.7    0.4  
SexM:AgeF1      -0.7    0.4  
SexF:AgeF2      -0.6    0.3  
SexM:AgeF2       0.6    0.3  
SexF:AgeF3      -0.4    0.4  
SexM:AgeF3       1.1    0.3  
SexF:EthN        0.0    0.3  
SexM:EthN       -0.7    0.3  
SexF:LrnSL       1.0    0.4  
SexM:LrnSL       0.2    0.3  
SexF:EthN:LrnSL -1.4    0.4  
SexM:EthN:LrnSL  0.8    0.4  

Auxiliary parameter(s):
                      Median MAD_SD
reciprocal_dispersion 1.4    0.2   

------
* For help interpreting the printed output see ?print.stanreg
* For info on the priors used see ?prior_summary.stanreg
>                 
> # or, equivalently, call stan_glm.nb() without specifying the family
> 
> 
> 
> 
> cleanEx()
> nameEx("pairs.stanreg")
> ### * pairs.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: pairs.stanreg
> ### Title: Pairs method for stanreg objects
> ### Aliases: pairs.stanreg pairs_style_np pairs_condition
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ }
NULL
> 
> 
> 
> cleanEx()
> nameEx("plot.predict.stanjm")
> ### * plot.predict.stanjm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.predict.stanjm
> ### Title: Plot the estimated subject-specific or marginal longitudinal
> ###   trajectory
> ### Aliases: plot.predict.stanjm
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ }
NULL
> 
> 
> 
> cleanEx()
> nameEx("plot.stanreg")
> ### * plot.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.stanreg
> ### Title: Plot method for stanreg objects
> ### Aliases: plot.stanreg
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ 
+ # For graphical posterior predictive checks see
+ # help("pp_check.stanreg")
+ }
NULL
> 
> 
> 
> cleanEx()
> nameEx("plot.survfit.stanjm")
> ### * plot.survfit.stanjm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.survfit.stanjm
> ### Title: Plot the estimated subject-specific or marginal survival
> ###   function
> ### Aliases: plot.survfit.stanjm plot_stack_jm
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ }
NULL
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ }
NULL
> 
> 
> 
> cleanEx()
> nameEx("posterior_interval.stanreg")
> ### * posterior_interval.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: posterior_interval.stanreg
> ### Title: Posterior uncertainty intervals
> ### Aliases: posterior_interval.stanreg posterior_interval
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ if (!exists("example_model")) example(example_model)
+ posterior_interval(example_model)
+ posterior_interval(example_model, regex_pars = "herd")
+ posterior_interval(example_model, pars = "period2", prob = 0.5)
+ }

exmpl_> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
exmpl_+ example_model <- 
exmpl_+   stan_glmer(cbind(incidence, size - incidence) ~ size + period + (1|herd),
exmpl_+              data = lme4::cbpp, family = binomial, QR = TRUE,
exmpl_+              # this next line is only to keep the example small in size!
exmpl_+              chains = 2, cores = 1, seed = 12345, iter = 1000, refresh = 0)
exmpl_+ example_model
exmpl_+ }
stan_glmer
 family:       binomial [logit]
 formula:      cbind(incidence, size - incidence) ~ size + period + (1 | herd)
 observations: 56
------
            Median MAD_SD
(Intercept) -1.5    0.6  
size         0.0    0.0  
period2     -1.0    0.3  
period3     -1.1    0.4  
period4     -1.6    0.5  

Error terms:
 Groups Name        Std.Dev.
 herd   (Intercept) 0.76    
Num. levels: herd 15 

------
* For help interpreting the printed output see ?print.stanreg
* For info on the priors used see ?prior_summary.stanreg
              25%        75%
period2 -1.190268 -0.7887574
> 
> 
> 
> cleanEx()
> nameEx("posterior_linpred.stanreg")
> ### * posterior_linpred.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: posterior_linpred.stanreg
> ### Title: Posterior distribution of the (possibly transformed) linear
> ###   predictor
> ### Aliases: posterior_linpred.stanreg posterior_linpred posterior_epred
> ###   posterior_epred.stanreg
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ if (!exists("example_model")) example(example_model)
+ print(family(example_model))
+ 
+ # linear predictor on log-odds scale
+ linpred <- posterior_linpred(example_model)
+ colMeans(linpred)
+ 
+ # probabilities
+ # same as posterior_linpred(example_model, transform = TRUE)
+ probs <- posterior_epred(example_model) 
+ colMeans(probs)
+ 
+ # not conditioning on any group-level parameters
+ probs2 <- posterior_epred(example_model, re.form = NA)
+ apply(probs2, 2, median)
+ }

exmpl_> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
exmpl_+ example_model <- 
exmpl_+   stan_glmer(cbind(incidence, size - incidence) ~ size + period + (1|herd),
exmpl_+              data = lme4::cbpp, family = binomial, QR = TRUE,
exmpl_+              # this next line is only to keep the example small in size!
exmpl_+              chains = 2, cores = 1, seed = 12345, iter = 1000, refresh = 0)
exmpl_+ example_model
exmpl_+ }
stan_glmer
 family:       binomial [logit]
 formula:      cbind(incidence, size - incidence) ~ size + period + (1 | herd)
 observations: 56
------
            Median MAD_SD
(Intercept) -1.5    0.6  
size         0.0    0.0  
period2     -1.0    0.3  
period3     -1.1    0.4  
period4     -1.6    0.5  

Error terms:
 Groups Name        Std.Dev.
 herd   (Intercept) 0.76    
Num. levels: herd 15 

------
* For help interpreting the printed output see ?print.stanreg
* For info on the priors used see ?prior_summary.stanreg

Family: binomial 
Link function: logit 

         1          2          3          4          5          6          7 
0.19321385 0.07963232 0.07058646 0.04248258 0.20038371 0.08293944 0.07416584 
         8          9         10         11         12         13         14 
0.20038371 0.08184582 0.07185831 0.04623685 0.19090399 0.07887589 0.07058646 
        15         16         17         18         19         20         21 
0.04277052 0.19618560 0.08564462 0.07561027 0.04226464 0.19533469 0.08247894 
        22         23         24         25         26         27         28 
0.07292688 0.04623685 0.19424230 0.07887589 0.07058646 0.04248258 0.21139640 
        29         30         31         32         33         34         35 
0.19034663 0.07727663 0.07032113 0.04277052 0.20038371 0.08387899 0.07292688 
        36         37         38         39         40         41         42 
0.04711961 0.20205369 0.08630690 0.07462140 0.04711961 0.19090399 0.07843710 
        43         44         45         46         47         48         49 
0.06977302 0.04248258 0.19933598 0.08501582 0.07355331 0.04754166 0.19751916 
        50         51         52         53         54         55         56 
0.07599325 0.06856146 0.04164939 0.19751916 0.08096430 0.07165066 0.04567692 
> 
> 
> 
> cleanEx()
> nameEx("posterior_predict.stanreg")
> ### * posterior_predict.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: posterior_predict.stanreg
> ### Title: Draw from posterior predictive distribution
> ### Aliases: posterior_predict.stanreg posterior_predict
> ###   posterior_predict.stanmvreg
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ if (!exists("example_model")) example(example_model)
+ yrep <- posterior_predict(example_model)
+ table(yrep)
+ 
+ }

exmpl_> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
exmpl_+ example_model <- 
exmpl_+   stan_glmer(cbind(incidence, size - incidence) ~ size + period + (1|herd),
exmpl_+              data = lme4::cbpp, family = binomial, QR = TRUE,
exmpl_+              # this next line is only to keep the example small in size!
exmpl_+              chains = 2, cores = 1, seed = 12345, iter = 1000, refresh = 0)
exmpl_+ example_model
exmpl_+ }
stan_glmer
 family:       binomial [logit]
 formula:      cbind(incidence, size - incidence) ~ size + period + (1 | herd)
 observations: 56
------
            Median MAD_SD
(Intercept) -1.5    0.6  
size         0.0    0.0  
period2     -1.0    0.3  
period3     -1.1    0.4  
period4     -1.6    0.5  

Error terms:
 Groups Name        Std.Dev.
 herd   (Intercept) 0.76    
Num. levels: herd 15 

------
* For help interpreting the printed output see ?print.stanreg
* For info on the priors used see ?prior_summary.stanreg
yrep
    0     1     2     3     4     5     6     7     8     9    10    11    12 
20254 14220  8198  4732  2736  1632  1261   827   611   443   304   232   171 
   13    14    15    16    17    18    19    20    21    22 
  128    84    49    51    28    14    12     7     3     3 
> 
> 
> 
> cleanEx()
> nameEx("posterior_survfit")
> ### * posterior_survfit
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: posterior_survfit
> ### Title: Estimate subject-specific or standardised survival probabilities
> ### Aliases: posterior_survfit
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ }
NULL
> 
> 
> 
> cleanEx()
> nameEx("posterior_traj")
> ### * posterior_traj
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: posterior_traj
> ### Title: Estimate the subject-specific or marginal longitudinal
> ###   trajectory
> ### Aliases: posterior_traj
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ }
NULL
> 
> 
> 
> cleanEx()
> nameEx("posterior_vs_prior")
> ### * posterior_vs_prior
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: posterior_vs_prior
> ### Title: Juxtapose prior and posterior
> ### Aliases: posterior_vs_prior posterior_vs_prior.stanreg
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ ## Not run: 
+ ##D if (!exists("example_model")) example(example_model)
+ ##D # display non-varying (i.e. not group-level) coefficients
+ ##D posterior_vs_prior(example_model, pars = "beta")
+ ##D 
+ ##D # show group-level (varying) parameters and group by parameter
+ ##D posterior_vs_prior(example_model, pars = "varying",
+ ##D                    group_by_parameter = TRUE, color_by = "vs")
+ ##D 
+ ##D # group by parameter and allow axis scales to vary across facets
+ ##D posterior_vs_prior(example_model, regex_pars = "period",
+ ##D                    group_by_parameter = TRUE, color_by = "none",
+ ##D                    facet_args = list(scales = "free"))
+ ##D 
+ ##D # assign to object and customize with functions from ggplot2
+ ##D (gg <- posterior_vs_prior(example_model, pars = c("beta", "varying"), prob = 0.8))
+ ##D 
+ ##D gg + 
+ ##D  ggplot2::geom_hline(yintercept = 0, size = 0.3, linetype = 3) + 
+ ##D  ggplot2::coord_flip() + 
+ ##D  ggplot2::ggtitle("Comparing the prior and posterior")
+ ##D  
+ ##D # compare very wide and very narrow priors using roaches example
+ ##D # (see help(roaches, "rstanarm") for info on the dataset)
+ ##D roaches$roach100 <- roaches$roach1 / 100
+ ##D wide_prior <- normal(0, 10)
+ ##D narrow_prior <- normal(0, 0.1)
+ ##D fit_pois_wide_prior <- stan_glm(y ~ treatment + roach100 + senior, 
+ ##D                                 offset = log(exposure2), 
+ ##D                                 family = "poisson", data = roaches, 
+ ##D                                 prior = wide_prior)
+ ##D posterior_vs_prior(fit_pois_wide_prior, pars = "beta", prob = 0.5, 
+ ##D                    group_by_parameter = TRUE, color_by = "vs", 
+ ##D                    facet_args = list(scales = "free"))
+ ##D                    
+ ##D fit_pois_narrow_prior <- update(fit_pois_wide_prior, prior = narrow_prior)
+ ##D posterior_vs_prior(fit_pois_narrow_prior, pars = "beta", prob = 0.5, 
+ ##D                    group_by_parameter = TRUE, color_by = "vs", 
+ ##D                    facet_args = list(scales = "free"))
+ ##D                    
+ ##D 
+ ##D # look at cutpoints for ordinal model
+ ##D fit_polr <- stan_polr(tobgp ~ agegp, data = esoph, method = "probit",
+ ##D                       prior = R2(0.2, "mean"), init_r = 0.1)
+ ##D (gg_polr <- posterior_vs_prior(fit_polr, regex_pars = "\\|", color_by = "vs",
+ ##D                                group_by_parameter = TRUE))
+ ##D # flip the x and y axes
+ ##D gg_polr + ggplot2::coord_flip()
+ ## End(Not run)
+ }
NULL
> 
> 
> 
> cleanEx()
> nameEx("pp_check.stanreg")
> ### * pp_check.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: pp_check.stanreg
> ### Title: Graphical posterior predictive checks
> ### Aliases: pp_check.stanreg pp_check
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ fit <- stan_glmer(
+   mpg ~ wt + am + (1|cyl),
+   data = mtcars,
+   iter = 400, # iter and chains small just to keep example quick
+   chains = 2,
+   refresh = 0
+ )
+ 
+ # Compare distribution of y to distributions of multiple yrep datasets
+ pp_check(fit)
+ pp_check(fit, plotfun = "boxplot", nreps = 10, notch = FALSE)
+ pp_check(fit, plotfun = "hist", nreps = 3)
+ 
+ }
Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#bulk-ess
Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#tail-ess
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
> 
> 
> 
> cleanEx()
> nameEx("pp_validate")
> ### * pp_validate
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: pp_validate
> ### Title: Model validation via simulation
> ### Aliases: pp_validate
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ ## Not run: 
+ ##D if (!exists("example_model")) example(example_model)
+ ##D try(pp_validate(example_model)) # fails with default seed / priors
+ ## End(Not run)
+ }
NULL
> 
> 
> 
> cleanEx()
> nameEx("predictive_error.stanreg")
> ### * predictive_error.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: predictive_error.stanreg
> ### Title: In-sample or out-of-sample predictive errors
> ### Aliases: predictive_error.stanreg predictive_error
> ###   predictive_error.matrix predictive_error.ppd
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ if (!exists("example_model")) example(example_model)
+ err1 <- predictive_error(example_model, draws = 50)
+ hist(err1)
+ 
+ # Using newdata with a binomial model
+ formula(example_model)
+ nd <- data.frame(
+  size = c(10, 20), 
+  incidence = c(5, 10), 
+  period = factor(c(1,2)), 
+  herd = c(1, 15)
+ )
+ err2 <- predictive_error(example_model, newdata = nd, draws = 10, seed = 1234)
+ 
+ # stanreg vs matrix methods
+ fit <- stan_glm(mpg ~ wt, data = mtcars, iter = 300)
+ preds <- posterior_predict(fit, seed = 123)
+ all.equal(
+   predictive_error(fit, seed = 123),
+   predictive_error(preds, y = fit$y)
+ )
+ }

exmpl_> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
exmpl_+ example_model <- 
exmpl_+   stan_glmer(cbind(incidence, size - incidence) ~ size + period + (1|herd),
exmpl_+              data = lme4::cbpp, family = binomial, QR = TRUE,
exmpl_+              # this next line is only to keep the example small in size!
exmpl_+              chains = 2, cores = 1, seed = 12345, iter = 1000, refresh = 0)
exmpl_+ example_model
exmpl_+ }
stan_glmer
 family:       binomial [logit]
 formula:      cbind(incidence, size - incidence) ~ size + period + (1 | herd)
 observations: 56
------
            Median MAD_SD
(Intercept) -1.5    0.6  
size         0.0    0.0  
period2     -1.0    0.3  
period3     -1.1    0.4  
period4     -1.6    0.5  

Error terms:
 Groups Name        Std.Dev.
 herd   (Intercept) 0.76    
Num. levels: herd 15 

------
* For help interpreting the printed output see ?print.stanreg
* For info on the priors used see ?prior_summary.stanreg

SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 2.2e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:   1 / 300 [  0%]  (Warmup)
Chain 1: Iteration:  30 / 300 [ 10%]  (Warmup)
Chain 1: Iteration:  60 / 300 [ 20%]  (Warmup)
Chain 1: Iteration:  90 / 300 [ 30%]  (Warmup)
Chain 1: Iteration: 120 / 300 [ 40%]  (Warmup)
Chain 1: Iteration: 150 / 300 [ 50%]  (Warmup)
Chain 1: Iteration: 151 / 300 [ 50%]  (Sampling)
Chain 1: Iteration: 180 / 300 [ 60%]  (Sampling)
Chain 1: Iteration: 210 / 300 [ 70%]  (Sampling)
Chain 1: Iteration: 240 / 300 [ 80%]  (Sampling)
Chain 1: Iteration: 270 / 300 [ 90%]  (Sampling)
Chain 1: Iteration: 300 / 300 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.009 seconds (Warm-up)
Chain 1:                0.004 seconds (Sampling)
Chain 1:                0.013 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 9e-06 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:   1 / 300 [  0%]  (Warmup)
Chain 2: Iteration:  30 / 300 [ 10%]  (Warmup)
Chain 2: Iteration:  60 / 300 [ 20%]  (Warmup)
Chain 2: Iteration:  90 / 300 [ 30%]  (Warmup)
Chain 2: Iteration: 120 / 300 [ 40%]  (Warmup)
Chain 2: Iteration: 150 / 300 [ 50%]  (Warmup)
Chain 2: Iteration: 151 / 300 [ 50%]  (Sampling)
Chain 2: Iteration: 180 / 300 [ 60%]  (Sampling)
Chain 2: Iteration: 210 / 300 [ 70%]  (Sampling)
Chain 2: Iteration: 240 / 300 [ 80%]  (Sampling)
Chain 2: Iteration: 270 / 300 [ 90%]  (Sampling)
Chain 2: Iteration: 300 / 300 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.009 seconds (Warm-up)
Chain 2:                0.004 seconds (Sampling)
Chain 2:                0.013 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 9e-06 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:   1 / 300 [  0%]  (Warmup)
Chain 3: Iteration:  30 / 300 [ 10%]  (Warmup)
Chain 3: Iteration:  60 / 300 [ 20%]  (Warmup)
Chain 3: Iteration:  90 / 300 [ 30%]  (Warmup)
Chain 3: Iteration: 120 / 300 [ 40%]  (Warmup)
Chain 3: Iteration: 150 / 300 [ 50%]  (Warmup)
Chain 3: Iteration: 151 / 300 [ 50%]  (Sampling)
Chain 3: Iteration: 180 / 300 [ 60%]  (Sampling)
Chain 3: Iteration: 210 / 300 [ 70%]  (Sampling)
Chain 3: Iteration: 240 / 300 [ 80%]  (Sampling)
Chain 3: Iteration: 270 / 300 [ 90%]  (Sampling)
Chain 3: Iteration: 300 / 300 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.009 seconds (Warm-up)
Chain 3:                0.004 seconds (Sampling)
Chain 3:                0.013 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 9e-06 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:   1 / 300 [  0%]  (Warmup)
Chain 4: Iteration:  30 / 300 [ 10%]  (Warmup)
Chain 4: Iteration:  60 / 300 [ 20%]  (Warmup)
Chain 4: Iteration:  90 / 300 [ 30%]  (Warmup)
Chain 4: Iteration: 120 / 300 [ 40%]  (Warmup)
Chain 4: Iteration: 150 / 300 [ 50%]  (Warmup)
Chain 4: Iteration: 151 / 300 [ 50%]  (Sampling)
Chain 4: Iteration: 180 / 300 [ 60%]  (Sampling)
Chain 4: Iteration: 210 / 300 [ 70%]  (Sampling)
Chain 4: Iteration: 240 / 300 [ 80%]  (Sampling)
Chain 4: Iteration: 270 / 300 [ 90%]  (Sampling)
Chain 4: Iteration: 300 / 300 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.006 seconds (Warm-up)
Chain 4:                0.004 seconds (Sampling)
Chain 4:                0.01 seconds (Total)
Chain 4: 
Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#bulk-ess
Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#tail-ess
[1] TRUE
> 
> 
> 
> cleanEx()
> nameEx("predictive_interval.stanreg")
> ### * predictive_interval.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: predictive_interval.stanreg
> ### Title: Predictive intervals
> ### Aliases: predictive_interval.stanreg predictive_interval
> ###   predictive_interval.matrix predictive_interval.ppd
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ fit <- stan_glm(mpg ~ wt, data = mtcars, iter = 300)
+ predictive_interval(fit)
+ predictive_interval(fit, newdata = data.frame(wt = range(mtcars$wt)), 
+                     prob = 0.5)
+ 
+ # stanreg vs matrix methods
+ preds <- posterior_predict(fit, seed = 123)
+ all.equal(
+   predictive_interval(fit, seed = 123),
+   predictive_interval(preds)
+ )
+ }

SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 1.3e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:   1 / 300 [  0%]  (Warmup)
Chain 1: Iteration:  30 / 300 [ 10%]  (Warmup)
Chain 1: Iteration:  60 / 300 [ 20%]  (Warmup)
Chain 1: Iteration:  90 / 300 [ 30%]  (Warmup)
Chain 1: Iteration: 120 / 300 [ 40%]  (Warmup)
Chain 1: Iteration: 150 / 300 [ 50%]  (Warmup)
Chain 1: Iteration: 151 / 300 [ 50%]  (Sampling)
Chain 1: Iteration: 180 / 300 [ 60%]  (Sampling)
Chain 1: Iteration: 210 / 300 [ 70%]  (Sampling)
Chain 1: Iteration: 240 / 300 [ 80%]  (Sampling)
Chain 1: Iteration: 270 / 300 [ 90%]  (Sampling)
Chain 1: Iteration: 300 / 300 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.009 seconds (Warm-up)
Chain 1:                0.004 seconds (Sampling)
Chain 1:                0.013 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 9e-06 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:   1 / 300 [  0%]  (Warmup)
Chain 2: Iteration:  30 / 300 [ 10%]  (Warmup)
Chain 2: Iteration:  60 / 300 [ 20%]  (Warmup)
Chain 2: Iteration:  90 / 300 [ 30%]  (Warmup)
Chain 2: Iteration: 120 / 300 [ 40%]  (Warmup)
Chain 2: Iteration: 150 / 300 [ 50%]  (Warmup)
Chain 2: Iteration: 151 / 300 [ 50%]  (Sampling)
Chain 2: Iteration: 180 / 300 [ 60%]  (Sampling)
Chain 2: Iteration: 210 / 300 [ 70%]  (Sampling)
Chain 2: Iteration: 240 / 300 [ 80%]  (Sampling)
Chain 2: Iteration: 270 / 300 [ 90%]  (Sampling)
Chain 2: Iteration: 300 / 300 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.009 seconds (Warm-up)
Chain 2:                0.005 seconds (Sampling)
Chain 2:                0.014 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 9e-06 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:   1 / 300 [  0%]  (Warmup)
Chain 3: Iteration:  30 / 300 [ 10%]  (Warmup)
Chain 3: Iteration:  60 / 300 [ 20%]  (Warmup)
Chain 3: Iteration:  90 / 300 [ 30%]  (Warmup)
Chain 3: Iteration: 120 / 300 [ 40%]  (Warmup)
Chain 3: Iteration: 150 / 300 [ 50%]  (Warmup)
Chain 3: Iteration: 151 / 300 [ 50%]  (Sampling)
Chain 3: Iteration: 180 / 300 [ 60%]  (Sampling)
Chain 3: Iteration: 210 / 300 [ 70%]  (Sampling)
Chain 3: Iteration: 240 / 300 [ 80%]  (Sampling)
Chain 3: Iteration: 270 / 300 [ 90%]  (Sampling)
Chain 3: Iteration: 300 / 300 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.009 seconds (Warm-up)
Chain 3:                0.005 seconds (Sampling)
Chain 3:                0.014 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 9e-06 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:   1 / 300 [  0%]  (Warmup)
Chain 4: Iteration:  30 / 300 [ 10%]  (Warmup)
Chain 4: Iteration:  60 / 300 [ 20%]  (Warmup)
Chain 4: Iteration:  90 / 300 [ 30%]  (Warmup)
Chain 4: Iteration: 120 / 300 [ 40%]  (Warmup)
Chain 4: Iteration: 150 / 300 [ 50%]  (Warmup)
Chain 4: Iteration: 151 / 300 [ 50%]  (Sampling)
Chain 4: Iteration: 180 / 300 [ 60%]  (Sampling)
Chain 4: Iteration: 210 / 300 [ 70%]  (Sampling)
Chain 4: Iteration: 240 / 300 [ 80%]  (Sampling)
Chain 4: Iteration: 270 / 300 [ 90%]  (Sampling)
Chain 4: Iteration: 300 / 300 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.012 seconds (Warm-up)
Chain 4:                0.004 seconds (Sampling)
Chain 4:                0.016 seconds (Total)
Chain 4: 
Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#bulk-ess
Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#tail-ess
[1] TRUE
> 
> 
> 
> cleanEx()
> nameEx("prior_summary.stanreg")
> ### * prior_summary.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: prior_summary.stanreg
> ### Title: Summarize the priors used for an rstanarm model
> ### Aliases: prior_summary.stanreg prior_summary
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ if (!exists("example_model")) example(example_model) 
+ prior_summary(example_model)
+ 
+ priors <- prior_summary(example_model)
+ names(priors)
+ priors$prior$scale
+ priors$prior$adjusted_scale
+ 
+ # for a glm with adjusted scales (see Details, above), compare 
+ # the default (rstanarm adjusting the scales) to setting 
+ # autoscale=FALSE for prior on coefficients
+ fit <- stan_glm(mpg ~ wt + am, data = mtcars, 
+                 prior = normal(0, c(2.5, 4)), 
+                 prior_intercept = normal(0, 5), 
+                 iter = 10, chains = 1) # only for demonstration 
+ prior_summary(fit)
+ 
+ fit2 <- update(fit, prior = normal(0, c(2.5, 4), autoscale=FALSE), 
+                prior_intercept = normal(0, 5, autoscale=FALSE))
+ prior_summary(fit2)
+ }

exmpl_> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
exmpl_+ example_model <- 
exmpl_+   stan_glmer(cbind(incidence, size - incidence) ~ size + period + (1|herd),
exmpl_+              data = lme4::cbpp, family = binomial, QR = TRUE,
exmpl_+              # this next line is only to keep the example small in size!
exmpl_+              chains = 2, cores = 1, seed = 12345, iter = 1000, refresh = 0)
exmpl_+ example_model
exmpl_+ }
stan_glmer
 family:       binomial [logit]
 formula:      cbind(incidence, size - incidence) ~ size + period + (1 | herd)
 observations: 56
------
            Median MAD_SD
(Intercept) -1.5    0.6  
size         0.0    0.0  
period2     -1.0    0.3  
period3     -1.1    0.4  
period4     -1.6    0.5  

Error terms:
 Groups Name        Std.Dev.
 herd   (Intercept) 0.76    
Num. levels: herd 15 

------
* For help interpreting the printed output see ?print.stanreg
* For info on the priors used see ?prior_summary.stanreg

SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 2.1e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: WARNING: No variance estimation is
Chain 1:          performed for num_warmup < 20
Chain 1: 
Chain 1: Iteration: 1 / 10 [ 10%]  (Warmup)
Chain 1: Iteration: 2 / 10 [ 20%]  (Warmup)
Chain 1: Iteration: 3 / 10 [ 30%]  (Warmup)
Chain 1: Iteration: 4 / 10 [ 40%]  (Warmup)
Chain 1: Iteration: 5 / 10 [ 50%]  (Warmup)
Chain 1: Iteration: 6 / 10 [ 60%]  (Sampling)
Chain 1: Iteration: 7 / 10 [ 70%]  (Sampling)
Chain 1: Iteration: 8 / 10 [ 80%]  (Sampling)
Chain 1: Iteration: 9 / 10 [ 90%]  (Sampling)
Chain 1: Iteration: 10 / 10 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0 seconds (Warm-up)
Chain 1:                0 seconds (Sampling)
Chain 1:                0 seconds (Total)
Chain 1: 
Warning: There were 1 chains where the estimated Bayesian Fraction of Missing Information was low. See
https://mc-stan.org/misc/warnings.html#bfmi-low
Warning: Examine the pairs() plot to diagnose sampling problems

Warning: The largest R-hat is 1.9, indicating chains have not mixed.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#r-hat
Warning: Markov chains did not converge! Do not analyze results!

SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 1e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: WARNING: No variance estimation is
Chain 1:          performed for num_warmup < 20
Chain 1: 
Chain 1: Iteration: 1 / 10 [ 10%]  (Warmup)
Chain 1: Iteration: 2 / 10 [ 20%]  (Warmup)
Chain 1: Iteration: 3 / 10 [ 30%]  (Warmup)
Chain 1: Iteration: 4 / 10 [ 40%]  (Warmup)
Chain 1: Iteration: 5 / 10 [ 50%]  (Warmup)
Chain 1: Iteration: 6 / 10 [ 60%]  (Sampling)
Chain 1: Iteration: 7 / 10 [ 70%]  (Sampling)
Chain 1: Iteration: 8 / 10 [ 80%]  (Sampling)
Chain 1: Iteration: 9 / 10 [ 90%]  (Sampling)
Chain 1: Iteration: 10 / 10 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0 seconds (Warm-up)
Chain 1:                0 seconds (Sampling)
Chain 1:                0 seconds (Total)
Chain 1: 
Warning: The largest R-hat is 1.9, indicating chains have not mixed.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#r-hat
Warning: Markov chains did not converge! Do not analyze results!
Priors for model 'fit2' 
------
Intercept (after predictors centered)
 ~ normal(location = 0, scale = 5)

Coefficients
 ~ normal(location = [0,0], scale = [2.5,4.0])

Auxiliary (sigma)
  Specified prior:
    ~ exponential(rate = 1)
  Adjusted prior:
    ~ exponential(rate = 0.17)
------
See help('prior_summary.stanreg') for more details
> 
> 
> 
> cleanEx()
> nameEx("priors")
> ### * priors
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: priors
> ### Title: Prior distributions and options
> ### Aliases: priors normal student_t cauchy hs hs_plus laplace lasso
> ###   product_normal exponential decov lkj dirichlet R2
> ###   default_prior_intercept default_prior_coef
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ fmla <- mpg ~ wt + qsec + drat + am
+ 
+ # Draw from prior predictive distribution (by setting prior_PD = TRUE)
+ prior_pred_fit <- stan_glm(fmla, data = mtcars, prior_PD = TRUE,
+                            chains = 1, seed = 12345, iter = 250, # for speed only
+                            prior = student_t(df = 4, 0, 2.5), 
+                            prior_intercept = cauchy(0,10), 
+                            prior_aux = exponential(1/2))
+ plot(prior_pred_fit, "hist")
+ 
+ 
+ # Visually compare normal, student_t, cauchy, laplace, and product_normal
+ compare_priors <- function(scale = 1, df_t = 2, xlim = c(-10, 10)) {
+   dt_loc_scale <- function(x, df, location, scale) { 
+     1/scale * dt((x - location)/scale, df)  
+   }
+   dlaplace <- function(x, location, scale) {
+     0.5 / scale * exp(-abs(x - location) / scale)
+   }
+   dproduct_normal <- function(x, scale) {
+     besselK(abs(x) / scale ^ 2, nu = 0) / (scale ^ 2 * pi)
+   }
+   stat_dist <- function(dist, ...) {
+     ggplot2::stat_function(ggplot2::aes_(color = dist), ...)
+   }
+   ggplot2::ggplot(data.frame(x = xlim), ggplot2::aes(x)) + 
+     stat_dist("normal", size = .75, fun = dnorm, 
+               args = list(mean = 0, sd = scale)) +
+     stat_dist("student_t", size = .75, fun = dt_loc_scale, 
+               args = list(df = df_t, location = 0, scale = scale)) +
+     stat_dist("cauchy", size = .75, linetype = 2, fun = dcauchy, 
+               args = list(location = 0, scale = scale)) + 
+     stat_dist("laplace", size = .75, linetype = 2, fun = dlaplace,
+               args = list(location = 0, scale = scale)) +
+     stat_dist("product_normal", size = .75, linetype = 2, fun = dproduct_normal,
+               args = list(scale = 1))            
+ }
+ # Cauchy has fattest tails, followed by student_t, laplace, and normal
+ compare_priors()
+ 
+ # The student_t with df = 1 is the same as the cauchy
+ compare_priors(df_t = 1) 
+ 
+ # Even a scale of 5 is somewhat large. It gives plausibility to rather 
+ # extreme values
+ compare_priors(scale = 5, xlim = c(-20,20)) 
+ 
+ # If you use a prior like normal(0, 1000) to be "non-informative" you are 
+ # actually saying that a coefficient value of e.g. -500 is quite plausible
+ compare_priors(scale = 1000, xlim = c(-1000,1000))
+ }

SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 1.2e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: WARNING: There aren't enough warmup iterations to fit the
Chain 1:          three stages of adaptation as currently configured.
Chain 1:          Reducing each adaptation stage to 15%/75%/10% of
Chain 1:          the given number of warmup iterations:
Chain 1:            init_buffer = 18
Chain 1:            adapt_window = 95
Chain 1:            term_buffer = 12
Chain 1: 
Chain 1: Iteration:   1 / 250 [  0%]  (Warmup)
Chain 1: Iteration:  25 / 250 [ 10%]  (Warmup)
Chain 1: Iteration:  50 / 250 [ 20%]  (Warmup)
Chain 1: Iteration:  75 / 250 [ 30%]  (Warmup)
Chain 1: Iteration: 100 / 250 [ 40%]  (Warmup)
Chain 1: Iteration: 125 / 250 [ 50%]  (Warmup)
Chain 1: Iteration: 126 / 250 [ 50%]  (Sampling)
Chain 1: Iteration: 150 / 250 [ 60%]  (Sampling)
Chain 1: Iteration: 175 / 250 [ 70%]  (Sampling)
Chain 1: Iteration: 200 / 250 [ 80%]  (Sampling)
Chain 1: Iteration: 225 / 250 [ 90%]  (Sampling)
Chain 1: Iteration: 250 / 250 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.022 seconds (Warm-up)
Chain 1:                0.023 seconds (Sampling)
Chain 1:                0.045 seconds (Total)
Chain 1: 
Warning: The largest R-hat is 1.14, indicating chains have not mixed.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#r-hat
Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#bulk-ess
Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#tail-ess
Warning: `aes_()` was deprecated in ggplot2 3.0.0.
ℹ Please use tidy evaluation idioms with `aes()`
Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
ℹ Please use `linewidth` instead.
> 
> 
> 
> cleanEx()
> nameEx("ps_check")
> ### * ps_check
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: ps_check
> ### Title: Graphical checks of the estimated survival function
> ### Aliases: ps_check
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ }
NULL
> 
> 
> 
> cleanEx()
> nameEx("rstanarm-datasets")
> ### * rstanarm-datasets
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: rstanarm-datasets
> ### Title: Datasets for rstanarm examples
> ### Aliases: rstanarm-datasets kidiq roaches wells bball1970 bball2006
> ###   mortality tumors radon pbcLong pbcSurv
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ # Using 'kidiq' dataset 
+ fit <- stan_lm(kid_score ~ mom_hs * mom_iq, data = kidiq, 
+                prior = R2(location = 0.30, what = "mean"),
+                # the next line is only to make the example go fast enough
+                chains = 1, iter = 500, seed = 12345)
+ pp_check(fit, nreps = 20)
+ }

SAMPLING FOR MODEL 'lm' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0.000333 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 3.33 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:   1 / 500 [  0%]  (Warmup)
Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup)
Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup)
Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup)
Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup)
Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup)
Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling)
Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling)
Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling)
Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling)
Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling)
Chain 1: Iteration: 500 / 500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.754 seconds (Warm-up)
Chain 1:                0.247 seconds (Sampling)
Chain 1:                1.001 seconds (Total)
Chain 1: 
Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#bulk-ess
Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#tail-ess
> 
> 
> 
> cleanEx()
> nameEx("stan_betareg")
> ### * stan_betareg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: stan_betareg
> ### Title: Bayesian beta regression models via Stan
> ### Aliases: stan_betareg stan_betareg.fit
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ ### Simulated data
+ N <- 200
+ x <- rnorm(N, 2, 1)
+ z <- rnorm(N, 2, 1)
+ mu <- binomial(link = "logit")$linkinv(1 + 0.2*x)
+ phi <- exp(1.5 + 0.4*z)
+ y <- rbeta(N, mu * phi, (1 - mu) * phi)
+ hist(y, col = "dark grey", border = FALSE, xlim = c(0,1))
+ fake_dat <- data.frame(y, x, z)
+ 
+ fit <- stan_betareg(
+   y ~ x | z, data = fake_dat, 
+   link = "logit", 
+   link.phi = "log", 
+   algorithm = "optimizing" # just for speed of example
+  ) 
+ print(fit, digits = 2)
+ }
stan_betareg
 family:       beta [logit, link.phi=log]
 formula:      y ~ x | z
 observations: 200
------
                  Median MAD_SD
(Intercept)       1.14   0.12  
x                 0.17   0.06  
(phi)_(Intercept) 1.47   0.21  
(phi)_z           0.40   0.09  

------
* For help interpreting the printed output see ?print.stanreg
* For info on the priors used see ?prior_summary.stanreg
> 
> 
> 
> cleanEx()
> nameEx("stan_biglm")
> ### * stan_biglm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: stan_biglm
> ### Title: Bayesian regularized linear but big models via Stan
> ### Aliases: stan_biglm stan_biglm.fit
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ # create inputs
+ ols <- lm(mpg ~ wt + qsec + am, data = mtcars, # all row are complete so ...
+           na.action = na.exclude)              # not necessary in this case
+ b <- coef(ols)[-1]
+ R <- qr.R(ols$qr)[-1,-1]
+ SSR <- crossprod(ols$residuals)[1]
+ not_NA <- !is.na(fitted(ols))
+ N <- sum(not_NA)
+ xbar <- colMeans(mtcars[not_NA,c("wt", "qsec", "am")])
+ y <- mtcars$mpg[not_NA]
+ ybar <- mean(y)
+ s_y <- sd(y)
+ post <- stan_biglm.fit(b, R, SSR, N, xbar, ybar, s_y, prior = R2(.75),
+                        # the next line is only to make the example go fast
+                        chains = 1, iter = 500, seed = 12345)
+ cbind(lm = b, stan_lm = rstan::get_posterior_mean(post)[13:15,]) # shrunk
+ }

SAMPLING FOR MODEL 'lm' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 1.8e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:   1 / 500 [  0%]  (Warmup)
Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup)
Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup)
Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup)
Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup)
Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup)
Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling)
Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling)
Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling)
Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling)
Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling)
Chain 1: Iteration: 500 / 500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.506 seconds (Warm-up)
Chain 1:                0.256 seconds (Sampling)
Chain 1:                0.762 seconds (Total)
Chain 1: 
Warning: There were 1 divergent transitions after warmup. See
https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
to find out why this is a problem and how to eliminate them.
Warning: Examine the pairs() plot to diagnose sampling problems

Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#bulk-ess
Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#tail-ess
            lm   stan_lm
wt   -3.916504 -3.694667
qsec  1.225886  1.190556
am    2.935837  2.984365
> 
> 
> 
> cleanEx()
> nameEx("stan_clogit")
> ### * stan_clogit
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: stan_clogit
> ### Title: Conditional logistic (clogit) regression models via Stan
> ### Aliases: stan_clogit
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ dat <- infert[order(infert$stratum), ] # order by strata
+ post <- stan_clogit(case ~ spontaneous + induced + (1 | education), 
+                     strata = stratum,
+                     data = dat,
+                     subset = parity <= 2,
+                     QR = TRUE,
+                     chains = 2, iter = 500) # for speed only
+ 
+ nd <- dat[dat$parity > 2, c("case", "spontaneous", "induced", "education", "stratum")]
+ # next line would fail without case and stratum variables                                 
+ pr <- posterior_epred(post, newdata = nd) # get predicted probabilities
+ 
+ # not a random variable b/c probabilities add to 1 within strata
+ all.equal(rep(sum(nd$case), nrow(pr)), rowSums(pr)) 
+ }

SAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 4.7e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.47 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:   1 / 500 [  0%]  (Warmup)
Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup)
Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup)
Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup)
Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup)
Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup)
Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling)
Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling)
Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling)
Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling)
Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling)
Chain 1: Iteration: 500 / 500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.31 seconds (Warm-up)
Chain 1:                0.09 seconds (Sampling)
Chain 1:                0.4 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 3.5e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.35 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:   1 / 500 [  0%]  (Warmup)
Chain 2: Iteration:  50 / 500 [ 10%]  (Warmup)
Chain 2: Iteration: 100 / 500 [ 20%]  (Warmup)
Chain 2: Iteration: 150 / 500 [ 30%]  (Warmup)
Chain 2: Iteration: 200 / 500 [ 40%]  (Warmup)
Chain 2: Iteration: 250 / 500 [ 50%]  (Warmup)
Chain 2: Iteration: 251 / 500 [ 50%]  (Sampling)
Chain 2: Iteration: 300 / 500 [ 60%]  (Sampling)
Chain 2: Iteration: 350 / 500 [ 70%]  (Sampling)
Chain 2: Iteration: 400 / 500 [ 80%]  (Sampling)
Chain 2: Iteration: 450 / 500 [ 90%]  (Sampling)
Chain 2: Iteration: 500 / 500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.223 seconds (Warm-up)
Chain 2:                0.071 seconds (Sampling)
Chain 2:                0.294 seconds (Total)
Chain 2: 
[1] TRUE
> 
> 
> 
> cleanEx()
> nameEx("stan_gamm4")
> ### * stan_gamm4
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: stan_gamm4
> ### Title: Bayesian generalized linear additive models with optional
> ###   group-specific terms via Stan
> ### Aliases: stan_gamm4 plot_nonlinear
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ # from example(gamm4, package = "gamm4"), prefixing gamm4() call with stan_
+ }
NULL
> 
> 
> 
> cleanEx()
> nameEx("stan_glm")
> ### * stan_glm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: stan_glm
> ### Title: Bayesian generalized linear models via Stan
> ### Aliases: stan_glm stan_glm.nb stan_glm.fit
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ ### Linear regression
+ mtcars$mpg10 <- mtcars$mpg / 10
+ fit <- stan_glm(
+   mpg10 ~ wt + cyl + am,            
+   data = mtcars, 
+   QR = TRUE,
+   # for speed of example only (default is "sampling")
+   algorithm = "fullrank",
+   refresh = 0 
+  ) 
+                 
+ plot(fit, prob = 0.5)
+ plot(fit, prob = 0.5, pars = "beta")
+ plot(fit, "hist", pars = "sigma")
+ }
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
> 
> 
> 
> cleanEx()
> nameEx("stan_glmer")
> ### * stan_glmer
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: stan_glmer
> ### Title: Bayesian generalized linear models with group-specific terms via
> ###   Stan
> ### Aliases: stan_glmer stan_lmer stan_glmer.nb
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ # see help(example_model) for details on the model below
+ if (!exists("example_model")) example(example_model) 
+ print(example_model, digits = 1)
+ }

exmpl_> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
exmpl_+ example_model <- 
exmpl_+   stan_glmer(cbind(incidence, size - incidence) ~ size + period + (1|herd),
exmpl_+              data = lme4::cbpp, family = binomial, QR = TRUE,
exmpl_+              # this next line is only to keep the example small in size!
exmpl_+              chains = 2, cores = 1, seed = 12345, iter = 1000, refresh = 0)
exmpl_+ example_model
exmpl_+ }
stan_glmer
 family:       binomial [logit]
 formula:      cbind(incidence, size - incidence) ~ size + period + (1 | herd)
 observations: 56
------
            Median MAD_SD
(Intercept) -1.5    0.6  
size         0.0    0.0  
period2     -1.0    0.3  
period3     -1.1    0.4  
period4     -1.6    0.5  

Error terms:
 Groups Name        Std.Dev.
 herd   (Intercept) 0.76    
Num. levels: herd 15 

------
* For help interpreting the printed output see ?print.stanreg
* For info on the priors used see ?prior_summary.stanreg
stan_glmer
 family:       binomial [logit]
 formula:      cbind(incidence, size - incidence) ~ size + period + (1 | herd)
 observations: 56
------
            Median MAD_SD
(Intercept) -1.5    0.6  
size         0.0    0.0  
period2     -1.0    0.3  
period3     -1.1    0.4  
period4     -1.6    0.5  

Error terms:
 Groups Name        Std.Dev.
 herd   (Intercept) 0.76    
Num. levels: herd 15 

------
* For help interpreting the printed output see ?print.stanreg
* For info on the priors used see ?prior_summary.stanreg
> 
> 
> 
> cleanEx()
> nameEx("stan_jm")
> ### * stan_jm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: stan_jm
> ### Title: Bayesian joint longitudinal and time-to-event models via Stan
> ### Aliases: stan_jm
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch !="i386") {
+ }
NULL
> 
> 
> 
> 
> cleanEx()
> nameEx("stan_lm")
> ### * stan_lm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: stan_aov
> ### Title: Bayesian regularized linear models via Stan
> ### Aliases: stan_aov stan_lm stan_lm.wfit stan_lm.fit
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ }
NULL
> if (.Platform$OS.type != "windows" || .Platform$r_arch !="i386") {
+ (fit <- stan_lm(mpg ~ wt + qsec + am, data = mtcars, prior = R2(0.75), 
+                 # the next line is only to make the example go fast enough
+                 chains = 1, iter = 300, seed = 12345, refresh = 0))
+ plot(fit, "hist", pars = c("wt", "am", "qsec", "sigma"), 
+      transformations = list(sigma = "log"))
+ }
Warning: The largest R-hat is 1.09, indicating chains have not mixed.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#r-hat
Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#bulk-ess
Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#tail-ess
Warning: Markov chains did not converge! Do not analyze results!
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
> 
> 
> 
> cleanEx()
> nameEx("stan_mvmer")
> ### * stan_mvmer
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: stan_mvmer
> ### Title: Bayesian multivariate generalized linear models with correlated
> ###   group-specific terms via Stan
> ### Aliases: stan_mvmer
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch !="i386") {
+ }
NULL
> 
> 
> 
> cleanEx()
> nameEx("stan_nlmer")
> ### * stan_nlmer
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: stan_nlmer
> ### Title: Bayesian nonlinear models with group-specific terms via Stan
> ### Aliases: stan_nlmer
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch !="i386") {
+ }
NULL
> 
> 
> 
> cleanEx()
> nameEx("stan_polr")
> ### * stan_polr
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: stan_polr
> ### Title: Bayesian ordinal regression models via Stan
> ### Aliases: stan_polr stan_polr.fit
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch !="i386") {
+  fit <- stan_polr(tobgp ~ agegp, data = esoph, method = "probit",
+           prior = R2(0.2, "mean"), init_r = 0.1, seed = 12345,
+           algorithm = "fullrank") # for speed only
+  print(fit)
+  plot(fit)
+ }
Chain 1: ------------------------------------------------------------
Chain 1: EXPERIMENTAL ALGORITHM:
Chain 1:   This procedure has not been thoroughly tested and may be unstable
Chain 1:   or buggy. The interface is subject to change.
Chain 1: ------------------------------------------------------------
Chain 1: 
Chain 1: 
Chain 1: 
Chain 1: Gradient evaluation took 5.3e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.53 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Begin eta adaptation.
Chain 1: Iteration:   1 / 250 [  0%]  (Adaptation)
Chain 1: Iteration:  50 / 250 [ 20%]  (Adaptation)
Chain 1: Iteration: 100 / 250 [ 40%]  (Adaptation)
Chain 1: Iteration: 150 / 250 [ 60%]  (Adaptation)
Chain 1: Iteration: 200 / 250 [ 80%]  (Adaptation)
Chain 1: Success! Found best value [eta = 1] earlier than expected.
Chain 1: 
Chain 1: Begin stochastic gradient ascent.
Chain 1:   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes 
Chain 1:    100         -135.991             1.000            1.000
Chain 1:    200         -131.110             0.519            1.000
Chain 1:    300         -128.295             0.353            0.037
Chain 1:    400         -127.636             0.266            0.037
Chain 1:    500         -127.828             0.213            0.022
Chain 1:    600         -127.903             0.178            0.022
Chain 1:    700         -127.740             0.153            0.005   MEDIAN ELBO CONVERGED
Chain 1: 
Chain 1: Drawing a sample of size 1000 from the approximate posterior... 
Chain 1: COMPLETED.
stan_polr
 family:       ordered [probit]
 formula:      tobgp ~ agegp
 observations: 88
------
        Median MAD_SD
agegp.L -0.1    0.3  
agegp.Q -0.2    0.2  
agegp.C  0.0    0.3  
agegp^4  0.0    0.2  
agegp^5  0.0    0.2  

Cutpoints:
               Median MAD_SD
0-9g/day|10-19 -0.6    0.1  
10-19|20-29     0.1    0.1  
20-29|30+       0.8    0.2  

------
* For help interpreting the printed output see ?print.stanreg
* For info on the priors used see ?prior_summary.stanreg
> 
> 
> 
> 
> cleanEx()
> nameEx("stanreg-draws-formats")
> ### * stanreg-draws-formats
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: stanreg-draws-formats
> ### Title: Create a 'draws' object from a 'stanreg' object
> ### Aliases: stanreg-draws-formats as_draws as_draws_matrix as_draws_array
> ###   as_draws_df as_draws_rvars as_draws_list as_draws.stanreg
> ###   as_draws_matrix.stanreg as_draws_array.stanreg as_draws_df.stanreg
> ###   as_draws_list.stanreg as_draws_rvars.stanreg
> 
> ### ** Examples
> 
> fit <- stan_glm(mpg ~ wt + as.factor(cyl), data = mtcars)

SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 2e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.048 seconds (Warm-up)
Chain 1:                0.046 seconds (Sampling)
Chain 1:                0.094 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 1e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.051 seconds (Warm-up)
Chain 2:                0.043 seconds (Sampling)
Chain 2:                0.094 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 3.1e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.31 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.051 seconds (Warm-up)
Chain 3:                0.046 seconds (Sampling)
Chain 3:                0.097 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 9e-06 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.05 seconds (Warm-up)
Chain 4:                0.046 seconds (Sampling)
Chain 4:                0.096 seconds (Total)
Chain 4: 
> as_draws_matrix(fit) # matrix format combines all chains 
# A draws_matrix: 4000 iterations, 1 chains, and 5 variables
    variable
draw (Intercept)   wt as.factor(cyl)6 as.factor(cyl)8 sigma
  1           34 -3.2            -4.4            -5.3   2.2
  2           34 -3.3            -4.7            -5.2   2.2
  3           33 -2.7            -2.9            -7.6   2.7
  4           31 -2.1            -3.3            -8.0   2.8
  5           32 -3.1            -2.2            -6.0   2.4
  6           36 -3.4            -6.1            -5.9   2.7
  7           38 -4.8            -2.8            -3.3   2.4
  8           39 -4.9            -3.2            -4.0   2.6
  9           40 -5.1            -3.4            -3.9   2.6
  10          39 -5.0            -3.2            -4.4   2.7
# ... with 3990 more draws
> as_draws_df(fit, regex_pars = "cyl")
# A draws_df: 1000 iterations, 4 chains, and 2 variables
   as.factor(cyl)6 as.factor(cyl)8
1             -4.4            -5.3
2             -4.7            -5.2
3             -2.9            -7.6
4             -3.3            -8.0
5             -2.2            -6.0
6             -6.1            -5.9
7             -2.8            -3.3
8             -3.2            -4.0
9             -3.4            -3.9
10            -3.2            -4.4
# ... with 3990 more draws
# ... hidden reserved variables {'.chain', '.iteration', '.draw'}
> posterior::summarize_draws(as_draws_array(fit))
# A tibble: 5 × 10
  variable         mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail
  <chr>           <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>
1 (Intercept)     34.0   34.1  1.98  2.00  30.7  37.2   1.00    2931.    2818.
2 wt              -3.21  -3.23 0.793 0.801 -4.49 -1.87  1.00    2166.    2321.
3 as.factor(cyl)6 -4.26  -4.25 1.42  1.38  -6.59 -1.92  1.00    2356.    2503.
4 as.factor(cyl)8 -6.08  -6.06 1.73  1.69  -8.97 -3.25  1.00    2034.    2073.
5 sigma            2.66   2.62 0.371 0.353  2.13  3.33  1.00    2528.    2416.
> 
> 
> 
> 
> cleanEx()
> nameEx("summary.stanreg")
> ### * summary.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summary.stanreg
> ### Title: Summary method for stanreg objects
> ### Aliases: summary.stanreg print.summary.stanreg
> ###   as.data.frame.summary.stanreg summary.stanmvreg
> ###   print.summary.stanmvreg
> 
> ### ** Examples
> 
> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
+ if (!exists("example_model")) example(example_model) 
+ summary(example_model, probs = c(0.1, 0.9))
+ 
+ # These produce the same output for this example, 
+ # but the second method can be used for any model
+ summary(example_model, pars = c("(Intercept)", "size", 
+                                 paste0("period", 2:4)))
+ summary(example_model, pars = c("alpha", "beta"))
+ 
+ # Only show parameters varying by group
+ summary(example_model, pars = "varying")
+ as.data.frame(summary(example_model, pars = "varying"))
+ }

exmpl_> if (.Platform$OS.type != "windows" || .Platform$r_arch != "i386") {
exmpl_+ example_model <- 
exmpl_+   stan_glmer(cbind(incidence, size - incidence) ~ size + period + (1|herd),
exmpl_+              data = lme4::cbpp, family = binomial, QR = TRUE,
exmpl_+              # this next line is only to keep the example small in size!
exmpl_+              chains = 2, cores = 1, seed = 12345, iter = 1000, refresh = 0)
exmpl_+ example_model
exmpl_+ }
stan_glmer
 family:       binomial [logit]
 formula:      cbind(incidence, size - incidence) ~ size + period + (1 | herd)
 observations: 56
------
            Median MAD_SD
(Intercept) -1.5    0.6  
size         0.0    0.0  
period2     -1.0    0.3  
period3     -1.1    0.4  
period4     -1.6    0.5  

Error terms:
 Groups Name        Std.Dev.
 herd   (Intercept) 0.76    
Num. levels: herd 15 

------
* For help interpreting the printed output see ?print.stanreg
* For info on the priors used see ?prior_summary.stanreg
                              mean       mcse        sd         10%         50%
b[(Intercept) herd:1]   0.62722341 0.01608742 0.4415459  0.07595455  0.62715031
b[(Intercept) herd:2]  -0.36427769 0.01525883 0.4424714 -0.94483006 -0.33901142
b[(Intercept) herd:3]   0.38045628 0.01263177 0.3766349 -0.07852149  0.37502550
b[(Intercept) herd:4]   0.03841076 0.01803683 0.4905975 -0.58000948  0.04103359
b[(Intercept) herd:5]  -0.26015881 0.01415271 0.4160125 -0.80240461 -0.23959978
b[(Intercept) herd:6]  -0.45988461 0.01559916 0.4388333 -1.02158661 -0.43434658
b[(Intercept) herd:7]   0.92618148 0.01426487 0.4360411  0.40131569  0.89970975
b[(Intercept) herd:8]   0.51032101 0.01925821 0.5221492 -0.13943996  0.52135539
b[(Intercept) herd:9]  -0.25893282 0.01666986 0.5406258 -0.90647896 -0.24139284
b[(Intercept) herd:10] -0.62914073 0.01481049 0.4468560 -1.22576496 -0.60609808
b[(Intercept) herd:11] -0.14637179 0.01431972 0.4129541 -0.71249718 -0.11485555
b[(Intercept) herd:12] -0.04363117 0.01846334 0.5122429 -0.69627174 -0.02758330
b[(Intercept) herd:13] -0.78627355 0.01656960 0.4573965 -1.36763552 -0.75501245
b[(Intercept) herd:14]  1.00700584 0.01707785 0.4423126  0.43654877  0.98415992
b[(Intercept) herd:15] -0.60198255 0.01381385 0.4725656 -1.22122313 -0.57879172
                               90% n_eff      Rhat
b[(Intercept) herd:1]   1.18994683   753 1.0005647
b[(Intercept) herd:2]   0.18168238   841 0.9992947
b[(Intercept) herd:3]   0.86572288   889 0.9996979
b[(Intercept) herd:4]   0.64919383   740 0.9988455
b[(Intercept) herd:5]   0.24399929   864 0.9985012
b[(Intercept) herd:6]   0.06249890   791 1.0008678
b[(Intercept) herd:7]   1.52063980   934 0.9988557
b[(Intercept) herd:8]   1.15757378   735 1.0005324
b[(Intercept) herd:9]   0.41947464  1052 0.9983954
b[(Intercept) herd:10] -0.09920854   910 0.9994387
b[(Intercept) herd:11]  0.35927443   832 0.9998923
b[(Intercept) herd:12]  0.59755834   770 1.0019334
b[(Intercept) herd:13] -0.25753682   762 1.0027890
b[(Intercept) herd:14]  1.59355623   671 1.0003160
b[(Intercept) herd:15] -0.01508412  1170 0.9985240
> 
> 
> 
> ### * <FOOTER>
> ###
> cleanEx()
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  21.936 1.309 21.86 0 0 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
