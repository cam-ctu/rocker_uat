
R version 4.3.3 (2024-02-29) -- "Angel Food Cake"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "car"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('car')
Loading required package: carData
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("Anova")
> ### * Anova
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Anova
> ### Title: Anova Tables for Various Statistical Models
> ### Aliases: Anova Anova.lm Anova.lme Anova.aov Anova.glm Anova.multinom
> ###   Anova.polr Anova.mer Anova.merMod Anova.mlm Anova.manova Manova
> ###   Manova.mlm print.Anova.mlm summary.Anova.mlm print.summary.Anova.mlm
> ###   print.univaov as.data.frame.univaov Anova.coxph Anova.svyglm
> ###   Anova.svycoxph Anova.rlm Anova.coxme Anova.default
> ### Keywords: htest models regression
> 
> ### ** Examples
> 
> 
> ## Two-Way Anova
> 
> mod <- lm(conformity ~ fcategory*partner.status, data=Moore,
+   contrasts=list(fcategory=contr.sum, partner.status=contr.sum))
> Anova(mod)
Anova Table (Type II tests)

Response: conformity
                         Sum Sq Df F value   Pr(>F)   
fcategory                 11.61  2  0.2770 0.759564   
partner.status           212.21  1 10.1207 0.002874 **
fcategory:partner.status 175.49  2  4.1846 0.022572 * 
Residuals                817.76 39                    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> Anova(mod, type=3)  # note use of contr.sum in call to lm()
Anova Table (Type III tests)

Response: conformity
                         Sum Sq Df  F value    Pr(>F)    
(Intercept)              5752.8  1 274.3592 < 2.2e-16 ***
fcategory                  36.0  2   0.8589  0.431492    
partner.status            239.6  1  11.4250  0.001657 ** 
fcategory:partner.status  175.5  2   4.1846  0.022572 *  
Residuals                 817.8 39                       
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> 
> ## One-Way MANOVA
> ## See ?Pottery for a description of the data set used in this example.
> 
> summary(Anova(lm(cbind(Al, Fe, Mg, Ca, Na) ~ Site, data=Pottery)))

Type II MANOVA Tests:

Sum of squares and products for error:
           Al          Fe          Mg          Ca         Na
Al 48.2881429  7.08007143  0.60801429  0.10647143 0.58895714
Fe  7.0800714 10.95084571  0.52705714 -0.15519429 0.06675857
Mg  0.6080143  0.52705714 15.42961143  0.43537714 0.02761571
Ca  0.1064714 -0.15519429  0.43537714  0.05148571 0.01007857
Na  0.5889571  0.06675857  0.02761571  0.01007857 0.19929286

------------------------------------------
 
Term: Site 

Sum of squares and products for the hypothesis:
            Al          Fe          Mg         Ca         Na
Al  175.610319 -149.295533 -130.809707 -5.8891637 -5.3722648
Fe -149.295533  134.221616  117.745035  4.8217866  5.3259491
Mg -130.809707  117.745035  103.350527  4.2091613  4.7105458
Ca   -5.889164    4.821787    4.209161  0.2047027  0.1547830
Na   -5.372265    5.325949    4.710546  0.1547830  0.2582456

Multivariate Tests: Site
                 Df test stat  approx F num Df   den Df     Pr(>F)    
Pillai            3   1.55394   4.29839     15 60.00000 2.4129e-05 ***
Wilks             3   0.01230  13.08854     15 50.09147 1.8404e-12 ***
Hotelling-Lawley  3  35.43875  39.37639     15 50.00000 < 2.22e-16 ***
Roy               3  34.16111 136.64446      5 20.00000 9.4435e-15 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> 
> ## MANOVA for a randomized block design (example courtesy of Michael Friendly:
> ##  See ?Soils for description of the data set)
> 
> soils.mod <- lm(cbind(pH,N,Dens,P,Ca,Mg,K,Na,Conduc) ~ Block + Contour*Depth,
+     data=Soils)
> Manova(soils.mod)

Type II MANOVA Tests: Pillai test statistic
              Df test stat approx F num Df den Df    Pr(>F)    
Block          3    1.6758   3.7965     27     81 1.777e-06 ***
Contour        2    1.3386   5.8468     18     52 2.730e-07 ***
Depth          3    1.7951   4.4697     27     81 8.777e-08 ***
Contour:Depth  6    1.2351   0.8640     54    180    0.7311    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> summary(Anova(soils.mod), univariate=TRUE, multivariate=FALSE,
+     p.adjust.method=TRUE)

 Type II Sums of Squares
              df       pH         N     Dens        P       Ca      Mg        K
Block          3  1.23247 0.0038257 0.111250   6591.2  14.6009 13.8776 0.323442
Contour        2  0.26066 0.0054845 0.047279  12224.5  25.3941  6.9637 0.473288
Depth          3 14.95897 0.1637141 1.589817 224703.5 378.3826 34.8509 1.130825
Contour:Depth  6  0.51587 0.0030885 0.088371  10260.6   8.4497  4.5386 0.020262
residuals     33  4.24730 0.0358700 0.433050  55810.8  71.4284 27.7522 0.409308
                    Na   Conduc
Block          15.4013   7.3116
Contour        13.3148  12.8727
Depth         446.6692 674.4830
Contour:Depth   3.0929   5.8732
residuals      29.9400  46.7515

 F-tests
                 pH     N  Dens     P    Ca   Mg     K     Na Conduc
Block          3.19  1.76  2.83  0.65  2.25 8.25  8.69   2.83   1.72
Contour        1.01  1.68  0.60  2.41  5.87 2.76  6.36   4.89   4.54
Depth         38.74 25.10 40.38 66.43 58.27 6.91 30.39 246.16 158.70
Contour:Depth  0.67  0.95  3.37  2.02  0.65 1.80  0.82   1.14   0.69

 p-values
              pH         N          Dens       P          Ca         Mg        
Block         0.03622480 0.18784329 0.05368061 0.69011331 0.10102309 0.00124231
Contour       0.37427327 0.18986452 0.72782049 0.08459444 0.00661088 0.05764573
Depth         6.4142e-11 5.6100e-11 3.7698e-11 2.6890e-12 2.8152e-13 8.1354e-05
Contour:Depth 0.67593329 0.42910155 0.04669490 0.12985165 0.68927638 0.16658584
              K          Na         Conduc    
Block         0.00021642 0.02469800 0.18188132
Contour       0.00016011 0.00637205 0.01807839
Depth         1.2952e-09 < 2.22e-16 < 2.22e-16
Contour:Depth 0.45056838 0.34871568 0.65840514

 p-values adjusted (by term) for simultaneous inference by holm method
              pH         N          Dens       P          Ca         Mg        
Block         0.2173488  0.5456440  0.2684030  0.6901133  0.4040923  0.0099385 
Contour       0.7485465  0.5695936  0.7485465  0.3383777  0.0509764  0.2882286 
Depth         2.2440e-10 2.2440e-10 1.8849e-10 1.6134e-11 1.9707e-12 8.1354e-05
Contour:Depth 1.0000000  1.0000000  0.4202541  1.0000000  1.0000000  1.0000000 
              K          Na         Conduc    
Block         0.0019478  0.1728860  0.5456440 
Contour       0.0014410  0.0509764  0.1084704 
Depth         2.5904e-09 < 2.22e-16 < 2.22e-16
Contour:Depth 1.0000000  1.0000000  1.0000000 
> 
> ## a multivariate linear model for repeated-measures data
> ## See ?OBrienKaiser for a description of the data set used in this example.
> 
> phase <- factor(rep(c("pretest", "posttest", "followup"), c(5, 5, 5)),
+     levels=c("pretest", "posttest", "followup"))
> hour <- ordered(rep(1:5, 3))
> idata <- data.frame(phase, hour)
> idata
      phase hour
1   pretest    1
2   pretest    2
3   pretest    3
4   pretest    4
5   pretest    5
6  posttest    1
7  posttest    2
8  posttest    3
9  posttest    4
10 posttest    5
11 followup    1
12 followup    2
13 followup    3
14 followup    4
15 followup    5
> 
> mod.ok <- lm(cbind(pre.1, pre.2, pre.3, pre.4, pre.5,
+                      post.1, post.2, post.3, post.4, post.5,
+                      fup.1, fup.2, fup.3, fup.4, fup.5) ~  treatment*gender,
+                 data=OBrienKaiser)
> (av.ok <- Anova(mod.ok, idata=idata, idesign=~phase*hour))

Type II Repeated Measures MANOVA Tests: Pillai test statistic
                            Df test stat approx F num Df den Df    Pr(>F)    
(Intercept)                  1   0.96954   318.34      1     10 6.532e-09 ***
treatment                    2   0.48092     4.63      2     10 0.0376868 *  
gender                       1   0.20356     2.56      1     10 0.1409735    
treatment:gender             2   0.36350     2.86      2     10 0.1044692    
phase                        1   0.85052    25.61      2      9 0.0001930 ***
treatment:phase              2   0.68518     2.61      4     20 0.0667354 .  
gender:phase                 1   0.04314     0.20      2      9 0.8199968    
treatment:gender:phase       2   0.31060     0.92      4     20 0.4721498    
hour                         1   0.93468    25.04      4      7 0.0003043 ***
treatment:hour               2   0.30144     0.35      8     16 0.9295212    
gender:hour                  1   0.29274     0.72      4      7 0.6023742    
treatment:gender:hour        2   0.57022     0.80      8     16 0.6131884    
phase:hour                   1   0.54958     0.46      8      3 0.8324517    
treatment:phase:hour         2   0.66367     0.25     16      8 0.9914415    
gender:phase:hour            1   0.69505     0.85      8      3 0.6202076    
treatment:gender:phase:hour  2   0.79277     0.33     16      8 0.9723693    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> 
> summary(av.ok, multivariate=FALSE)

Univariate Type II Repeated-Measures ANOVA Assuming Sphericity

                            Sum Sq num Df Error SS den Df  F value    Pr(>F)
(Intercept)                 7260.0      1  228.056     10 318.3435 6.532e-09
treatment                    211.3      2  228.056     10   4.6323  0.037687
gender                        58.3      1  228.056     10   2.5558  0.140974
treatment:gender             130.2      2  228.056     10   2.8555  0.104469
phase                        167.5      2   80.278     20  20.8651 1.274e-05
treatment:phase               78.7      4   80.278     20   4.8997  0.006426
gender:phase                   1.7      2   80.278     20   0.2078  0.814130
treatment:gender:phase        10.2      4   80.278     20   0.6366  0.642369
hour                         106.3      4   62.500     40  17.0067 3.191e-08
treatment:hour                 1.2      8   62.500     40   0.0929  0.999257
gender:hour                    2.6      4   62.500     40   0.4094  0.800772
treatment:gender:hour          7.8      8   62.500     40   0.6204  0.755484
phase:hour                    11.1      8   96.167     80   1.1525  0.338317
treatment:phase:hour           6.3     16   96.167     80   0.3256  0.992814
gender:phase:hour              6.6      8   96.167     80   0.6900  0.699124
treatment:gender:phase:hour   14.2     16   96.167     80   0.7359  0.749562
                               
(Intercept)                 ***
treatment                   *  
gender                         
treatment:gender               
phase                       ***
treatment:phase             ** 
gender:phase                   
treatment:gender:phase         
hour                        ***
treatment:hour                 
gender:hour                    
treatment:gender:hour          
phase:hour                     
treatment:phase:hour           
gender:phase:hour              
treatment:gender:phase:hour    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


Mauchly Tests for Sphericity

                            Test statistic p-value
phase                              0.74927 0.27282
treatment:phase                    0.74927 0.27282
gender:phase                       0.74927 0.27282
treatment:gender:phase             0.74927 0.27282
hour                               0.06607 0.00760
treatment:hour                     0.06607 0.00760
gender:hour                        0.06607 0.00760
treatment:gender:hour              0.06607 0.00760
phase:hour                         0.00478 0.44939
treatment:phase:hour               0.00478 0.44939
gender:phase:hour                  0.00478 0.44939
treatment:gender:phase:hour        0.00478 0.44939


Greenhouse-Geisser and Huynh-Feldt Corrections
 for Departure from Sphericity

                             GG eps Pr(>F[GG])    
phase                       0.79953  7.323e-05 ***
treatment:phase             0.79953    0.01223 *  
gender:phase                0.79953    0.76616    
treatment:gender:phase      0.79953    0.61162    
hour                        0.46028  8.741e-05 ***
treatment:hour              0.46028    0.97879    
gender:hour                 0.46028    0.65346    
treatment:gender:hour       0.46028    0.64136    
phase:hour                  0.44950    0.34573    
treatment:phase:hour        0.44950    0.94019    
gender:phase:hour           0.44950    0.58903    
treatment:gender:phase:hour 0.44950    0.64634    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

                               HF eps   Pr(>F[HF])
phase                       0.9278594 2.387543e-05
treatment:phase             0.9278594 8.089765e-03
gender:phase                0.9278594 7.984495e-01
treatment:gender:phase      0.9278594 6.319975e-01
hour                        0.5592802 2.014357e-05
treatment:hour              0.5592802 9.887716e-01
gender:hour                 0.5592802 6.911521e-01
treatment:gender:hour       0.5592802 6.692976e-01
phase:hour                  0.7330608 3.440460e-01
treatment:phase:hour        0.7330608 9.804731e-01
gender:phase:hour           0.7330608 6.552382e-01
treatment:gender:phase:hour 0.7330608 7.080122e-01
> 
> ## A "doubly multivariate" design with two  distinct repeated-measures variables
> ## (example courtesy of Michael Friendly)
> ## See ?WeightLoss for a description of the dataset.
> 
> imatrix <- matrix(c(
+ 	1,0,-1, 1, 0, 0,
+ 	1,0, 0,-2, 0, 0,
+ 	1,0, 1, 1, 0, 0,
+ 	0,1, 0, 0,-1, 1,
+ 	0,1, 0, 0, 0,-2,
+ 	0,1, 0, 0, 1, 1), 6, 6, byrow=TRUE)
> colnames(imatrix) <- c("WL", "SE", "WL.L", "WL.Q", "SE.L", "SE.Q")
> rownames(imatrix) <- colnames(WeightLoss)[-1]
> (imatrix <- list(measure=imatrix[,1:2], month=imatrix[,3:6]))
$measure
    WL SE
wl1  1  0
wl2  1  0
wl3  1  0
se1  0  1
se2  0  1
se3  0  1

$month
    WL.L WL.Q SE.L SE.Q
wl1   -1    1    0    0
wl2    0   -2    0    0
wl3    1    1    0    0
se1    0    0   -1    1
se2    0    0    0   -2
se3    0    0    1    1

> contrasts(WeightLoss$group) <- matrix(c(-2,1,1, 0,-1,1), ncol=2)
> (wl.mod<-lm(cbind(wl1, wl2, wl3, se1, se2, se3)~group, data=WeightLoss))

Call:
lm(formula = cbind(wl1, wl2, wl3, se1, se2, se3) ~ group, data = WeightLoss)

Coefficients:
             wl1       wl2       wl3       se1       se2       se3     
(Intercept)   5.34444   4.45000   2.17778  14.92778  13.79444  16.28333
group1        0.42222   0.55833   0.04722   0.08889  -0.26944   0.60000
group2        0.43333   1.09167  -0.02500   0.18333  -0.22500   0.71667

> Anova(wl.mod, imatrix=imatrix, test="Roy")

Type II Repeated Measures MANOVA Tests: Roy test statistic
              Df test stat approx F num Df den Df    Pr(>F)    
measure        1    86.203  1293.04      2     30 < 2.2e-16 ***
group:measure  2     0.356     5.52      2     31  0.008906 ** 
month          1     9.407    65.85      4     28 7.807e-14 ***
group:month    2     1.772    12.84      4     29 3.909e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> 
> ## mixed-effects models examples:
> 
> ## Not run: 
> ##D  # loads nlme package
> ##D 	library(nlme)
> ##D 	example(lme)
> ##D 	Anova(fm2)
> ## End(Not run)
> 
> ## Not run: 
> ##D  # loads lme4 package
> ##D 	library(lme4)
> ##D 	example(glmer)
> ##D 	Anova(gm1)
> ## End(Not run)
> 
> 
> 
> 
> cleanEx()
> nameEx("Boot")
> ### * Boot
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Boot
> ### Title: Bootstrapping for regression models
> ### Aliases: Boot Boot.default Boot.lm Boot.glm Boot.nls
> ### Keywords: regression
> 
> ### ** Examples
> 
> m1 <- lm(Fertility ~ ., swiss)
> betahat.boot <- Boot(m1, R=199) # 199 bootstrap samples--too small to be useful
Loading required namespace: boot
> summary(betahat.boot)  # default summary

Number of bootstrap replications R = 199 
                 original    bootBias    bootSE  bootMed
(Intercept)      66.91518 -1.02882995 10.944359 66.56737
Agriculture      -0.17211  0.00090838  0.060318 -0.16913
Examination      -0.25801  0.00229418  0.247031 -0.27161
Education        -0.87094 -0.01195505  0.201078 -0.89334
Catholic          0.10412 -0.00022590  0.030387  0.10450
Infant.Mortality  1.07705  0.05052016  0.475142  1.13569
> confint(betahat.boot)
Bootstrap bca confidence intervals

                       2.5 %      97.5 %
(Intercept)      44.25372647 92.63368913
Agriculture      -0.28415560 -0.05517064
Examination      -0.66167616  0.27418932
Education        -1.23127702 -0.46509770
Catholic          0.04094191  0.16205988
Infant.Mortality -0.28238152  1.88103788
> hist(betahat.boot)
> # Bootstrap for the estimated residual standard deviation:
> sigmahat.boot <- Boot(m1, R=199, f=sigmaHat, labels="sigmaHat")
> summary(sigmahat.boot)
           R original bootBias  bootSE bootMed
sigmaHat 199   7.1654 -0.53505 0.76112  6.6352
> confint(sigmahat.boot)
Warning in norm.inter(t, adj.alpha) :
  extreme order statistics used as endpoints
Bootstrap bca confidence intervals

            2.5 %   97.5 %
sigmaHat 6.374564 8.500058
> 
> 
> 
> cleanEx()
> nameEx("Boxplot")
> ### * Boxplot
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Boxplot
> ### Title: Boxplots With Point Identification
> ### Aliases: Boxplot Boxplot.default Boxplot.formula Boxplot.list
> ###   Boxplot.data.frame Boxplot.matrix
> ### Keywords: hplot
> 
> ### ** Examples
> 
> Boxplot(~income, data=Prestige, id=list(n=Inf)) # identify all outliers
[1] "general.managers"         "lawyers"                 
[3] "physicians"               "veterinarians"           
[5] "osteopaths.chiropractors"
> Boxplot(income ~ type, data=Prestige)
[1] "general.managers" "physicians"      
> Boxplot(income ~ type, data=Prestige, at=c(1, 3, 2))
[1] "general.managers" "physicians"      
> Boxplot(k5 + k618 ~ lfp*wc, data=Mroz)
[1] "746" "53" 
> with(Prestige, Boxplot(income, id=list(labels=rownames(Prestige))))
[1] "general.managers"         "lawyers"                 
[3] "physicians"               "veterinarians"           
[5] "osteopaths.chiropractors"
> with(Prestige, Boxplot(income, type, id=list(labels=rownames(Prestige))))
[1] "general.managers" "physicians"      
> Boxplot(scale(Prestige[, 1:4]))
[1] "general.managers"         "lawyers"                 
[3] "physicians"               "veterinarians"           
[5] "osteopaths.chiropractors"
> 
> 
> 
> cleanEx()
> nameEx("Contrasts")
> ### * Contrasts
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Contrasts
> ### Title: Functions to Construct Contrasts
> ### Aliases: Contrasts contr.Treatment contr.Sum contr.Helmert
> ### Keywords: models regression
> 
> ### ** Examples
> 
> # contr.Treatment vs. contr.treatment in the base package:
> 
> lm(prestige ~ (income + education)*type, data=Prestige, 
+     contrasts=list(type="contr.Treatment"))

Call:
lm(formula = prestige ~ (income + education) * type, data = Prestige, 
    contrasts = list(type = "contr.Treatment"))

Coefficients:
           (Intercept)                  income               education  
              2.275753                0.003522                1.713275  
          type[T.prof]              type[T.wc]     income:type[T.prof]  
             15.351896              -33.536652               -0.002903  
     income:type[T.wc]  education:type[T.prof]    education:type[T.wc]  
             -0.002072                1.387809                4.290875  

> 
> ##  Call:
> ##  lm(formula = prestige ~ (income + education) * type, data = Prestige,
> ##      contrasts = list(type = "contr.Treatment"))
> ##  
> ##  Coefficients:
> ##          (Intercept)                  income               education  
> ##              2.275753                0.003522                1.713275  
> ##          type[T.prof]              type[T.wc]     income:type[T.prof]  
> ##              15.351896              -33.536652               -0.002903  
> ##      income:type[T.wc]  education:type[T.prof]    education:type[T.wc]  
> ##              -0.002072                1.387809                4.290875  
> 
> lm(prestige ~ (income + education)*type, data=Prestige, 
+     contrasts=list(type="contr.treatment"))    

Call:
lm(formula = prestige ~ (income + education) * type, data = Prestige, 
    contrasts = list(type = "contr.treatment"))

Coefficients:
       (Intercept)              income           education            typeprof  
          2.275753            0.003522            1.713275           15.351896  
            typewc     income:typeprof       income:typewc  education:typeprof  
        -33.536652           -0.002903           -0.002072            1.387809  
  education:typewc  
          4.290875  

> 
> ##  Call:
> ##  lm(formula = prestige ~ (income + education) * type, data = Prestige,
> ##      contrasts = list(type = "contr.treatment"))
> ##  
> ##  Coefficients:
> ##      (Intercept)              income           education  
> ##          2.275753            0.003522            1.713275  
> ##          typeprof              typewc     income:typeprof  
> ##          15.351896          -33.536652           -0.002903  
> ##      income:typewc  education:typeprof    education:typewc  
> ##          -0.002072            1.387809            4.290875      
> 
> 
> 
> cleanEx()
> nameEx("Ellipses")
> ### * Ellipses
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Ellipses
> ### Title: Ellipses, Data Ellipses, and Confidence Ellipses
> ### Aliases: ellipse dataEllipse confidenceEllipse
> ###   confidenceEllipse.default confidenceEllipse.lm confidenceEllipse.glm
> ###   confidenceEllipse.mlm confidenceEllipses confidenceEllipses.default
> ###   confidenceEllipses.mlm
> ### Keywords: hplot aplot
> 
> ### ** Examples
> 
> dataEllipse(Duncan$income, Duncan$education, levels=0.1*1:9, 
+     ellipse.label=0.1*1:9, lty=2, fill=TRUE, fill.alpha=0.1)
>     
> confidenceEllipse(lm(prestige ~ income + education, data=Duncan), Scheffe=TRUE)
> 
> confidenceEllipse(lm(prestige ~ income + education, data=Duncan), vcov.=hccm)
> 
> confidenceEllipse(lm(prestige ~ income + education, data=Duncan), 
+ 	L=c("income + education", "income - education"))
> 	
> confidenceEllipses(lm(prestige ~ income + education + type, data=Duncan),
+   fill=TRUE)
> cov2cor(vcov(lm(prestige ~ income + education + type, 
+   data=Duncan))) # correlations among coefficients
            (Intercept)     income  education   typeprof     typewc
(Intercept)   1.0000000 -0.3484661 -0.6102747  0.5427211  0.3483203
income       -0.3484661  1.0000000 -0.2880828 -0.2016613 -0.1997770
education    -0.6102747 -0.2880828  1.0000000 -0.7761809 -0.5592417
typeprof      0.5427211 -0.2016613 -0.7761809  1.0000000  0.7072750
typewc        0.3483203 -0.1997770 -0.5592417  0.7072750  1.0000000
> 
> wts <- rep(1, nrow(Duncan))
> wts[c(6, 16)] <- 0 # delete Minister, Conductor
> with(Duncan, {
+ 	dataEllipse(income, prestige, levels=0.68)
+ 	dataEllipse(income, prestige, levels=0.68, robust=TRUE, 
+ 	    plot.points=FALSE, col="green3")
+ 	dataEllipse(income, prestige, weights=wts, levels=0.68, 
+ 	    plot.points=FALSE, col="brown")
+ 	dataEllipse(income, prestige, weights=wts, robust=TRUE, levels=0.68, 
+ 		plot.points=FALSE, col="blue")
+ 	})
>     
> with(Prestige, dataEllipse(income, education, type, 
+     id=list(n=2, labels=rownames(Prestige)), pch=15:17,
+     xlim=c(0, 25000), center.pch="+",
+     group.labels=c("Blue Collar", "Professional", "White Collar"),
+     ylim=c(5, 20), level=.95, fill=TRUE, fill.alpha=0.1))
> 
> 
> 
> cleanEx()
> nameEx("Export")
> ### * Export
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Export
> ### Title: Export a data frame to disk in one of many formats
> ### Aliases: Export
> ### Keywords: utilities connections
> 
> ### ** Examples
> 
> if(require("rio")) {
+ 
+ Export(Duncan, "Duncan.csv", keep.row.names="occupation")
+ Duncan2 <- Import("Duncan.csv") # Automatically restores row.names
+ identical(Duncan, Duncan2)
+ # cleanup
+ unlink("Duncan.csv")
+ 
+ }
Loading required package: rio
> 
> 
> 
> cleanEx()

detaching ‘package:rio’

> nameEx("Import")
> ### * Import
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Import
> ### Title: Import data from many file formats
> ### Aliases: Import
> ### Keywords: utilities connections
> 
> ### ** Examples
> 
> if(require("rio")) {
+ 
+ head(Duncan, 3) # first three rows
+ Export(Duncan, "Duncan.csv", keep.row.names="occupation")
+ Duncan2 <- Import("Duncan.csv") # Automatically restores row.names and factors
+ brief(Duncan2) 
+ identical(Duncan, Duncan2) # FALSE because type is of a different class
+ Duncan3 <- Import("Duncan.csv", stringsAsFactors=TRUE) 
+ brief(Duncan3) 
+ identical(Duncan, Duncan3) # TRUE type is of same class
+ # cleanup
+ unlink("Duncan.csv")
+ 
+ }
Loading required package: rio
45 x 4 data.frame (40 rows omitted)
           type income education prestige
            [c]    [i]       [i]      [i]
accountant prof     62        86       82
pilot      prof     72        76       83
architect  prof     75        92       90
. . .                                         
policeman  bc       34        47       41
waiter     bc        8        32       10
45 x 4 data.frame (40 rows omitted)
           type income education prestige
            [f]    [i]       [i]      [i]
accountant prof     62        86       82
pilot      prof     72        76       83
architect  prof     75        92       90
. . .                                         
policeman  bc       34        47       41
waiter     bc        8        32       10
> 
> 
> 
> cleanEx()

detaching ‘package:rio’

> nameEx("Predict")
> ### * Predict
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Predict
> ### Title: Model Predictions
> ### Aliases: Predict Predict.lm
> ### Keywords: models
> 
> ### ** Examples
> 
> mod <- lm(interlocks ~ log(assets), data=Ornstein)
> newd <- data.frame(assets=exp(4:12))
> (p1 <- predict(mod, newd, interval="prediction"))
         fit        lwr      upr
1 -11.546844 -35.632612 12.53892
2  -4.213580 -28.167353 19.74019
3   3.119684 -20.746798 26.98617
4  10.452948 -13.371440 34.27734
5  17.786212  -6.041518 41.61394
6  25.119476   1.242988 48.99596
7  32.452740   8.482354 56.42313
8  39.786004  15.677109 63.89490
9  47.119268  22.828014 71.41052
> p2 <- Predict(mod, newd, interval="prediction", vcov.=vcov)
> all.equal(p1, p2) # the same
[1] TRUE
> 
> (predict(mod, newd, se=TRUE))
$fit
         1          2          3          4          5          6          7 
-11.546844  -4.213580   3.119684  10.452948  17.786212  25.119476  32.452740 
         8          9 
 39.786004  47.119268 

$se.fit
        1         2         3         4         5         6         7         8 
1.9662292 1.4938511 1.0750019 0.7988559 0.8241457 1.1308251 1.5610312 2.0379832 
        9 
2.5354361 

$df
[1] 246

$residual.scale
[1] 12.06931

> (p3 <- Predict(mod, newd, se=TRUE, vcov.=hccm)) # larger SEs
$fit
         1          2          3          4          5          6          7 
-11.546844  -4.213580   3.119684  10.452948  17.786212  25.119476  32.452740 
         8          9 
 39.786004  47.119268 

$se.fit
        1         2         3         4         5         6         7         8 
2.8225421 1.9026552 1.0414745 0.6003835 1.2031087 2.0846342 3.0091773 3.9466208 
        9 
4.8895503 

$df
[1] 246

$residual.scale
[1] 12.06931

> p4 <- Predict(mod, newd, se=TRUE, vcov.=hccm(mod, type="hc3"))
> all.equal(p3, p4) # the same
[1] TRUE
> 
> 
> 
> cleanEx()
> nameEx("S")
> ### * S
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: S
> ### Title: Modified Functions for Summarizing Linear, Generalized Linear,
> ###   and Some Other Models
> ### Aliases: S Confint S.lm S.glm S.default S.multinom S.polr S.lme
> ###   S.lmerMod S.glmerMod S.data.frame print.S.lm print.S.glm
> ###   print.S.multinom print.S.polr print.S.lme print.S.lmerMod
> ###   print.S.glmerMod Confint.lm Confint.glm Confint.multinom Confint.polr
> ###   Confint.lme Confint.lmerMod Confint.glmerMod Confint.default
> ### Keywords: models regression
> 
> ### ** Examples
> 
> mod.prestige <- lm(prestige ~ education + income + type, Prestige)
> S(mod.prestige, vcov.=hccm)
Call: lm(formula = prestige ~ education + income + type, data = Prestige)
Standard errors computed by hccm 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -0.6229292  5.2381025  -0.119 0.905593    
education    3.6731661  0.6982758   5.260 9.16e-07 ***
income       0.0010132  0.0002672   3.793 0.000265 ***
typeprof     6.0389707  3.7951209   1.591 0.114948    
typewc      -2.7372307  2.4384681  -1.123 0.264531    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard deviation: 7.095 on 93 degrees of freedom
  (4 observations deleted due to missingness)
Multiple R-squared: 0.8349
F-statistic: 120.2 on 4 and 93 DF,  p-value: < 2.2e-16 
   AIC    BIC 
669.02 684.52 

> S(mod.prestige, brief=TRUE)
Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -0.6229292  5.2275255  -0.119    0.905    
education    3.6731661  0.6405016   5.735 1.21e-07 ***
income       0.0010132  0.0002209   4.586 1.40e-05 ***
typeprof     6.0389707  3.8668551   1.562    0.122    
typewc      -2.7372307  2.5139324  -1.089    0.279    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard deviation: 7.095 on 93 degrees of freedom
  (4 observations deleted due to missingness)
Multiple R-squared: 0.8349
F-statistic: 117.5 on 4 and 93 DF,  p-value: < 2.2e-16 
   AIC    BIC 
669.02 684.52 

> Confint(mod.prestige, vcov.=hccm)
Standard errors computed by hccm 
                Estimate         2.5 %       97.5 %
(Intercept) -0.622929165 -1.102476e+01  9.778904256
education    3.673166052  2.286529e+00  5.059803411
income       0.001013193  4.826801e-04  0.001543706
typeprof     6.038970651 -1.497387e+00 13.575328718
typewc      -2.737230718 -7.579545e+00  2.105083723
> 
> # A logit model
> mod.mroz <- glm(lfp ~ ., data=Mroz, family=binomial)
> S(mod.mroz)
Call: glm(formula = lfp ~ ., family = binomial, data = Mroz)

Coefficients:
             Estimate Std. Error z value Pr(>|z|)    
(Intercept)  3.182140   0.644375   4.938 7.88e-07 ***
k5          -1.462913   0.197001  -7.426 1.12e-13 ***
k618        -0.064571   0.068001  -0.950 0.342337    
age         -0.062871   0.012783  -4.918 8.73e-07 ***
wcyes        0.807274   0.229980   3.510 0.000448 ***
hcyes        0.111734   0.206040   0.542 0.587618    
lwg          0.604693   0.150818   4.009 6.09e-05 ***
inc         -0.034446   0.008208  -4.196 2.71e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1029.75  on 752  degrees of freedom
Residual deviance:  905.27  on 745  degrees of freedom

 logLik      df     AIC     BIC 
-452.63       8  921.27  958.26 

Number of Fisher Scoring iterations: 4

Exponentiated Coefficients and Confidence Bounds
              Estimate     2.5 %     97.5 %
(Intercept) 24.0982799 6.9377228 87.0347916
k5           0.2315607 0.1555331  0.3370675
k618         0.9374698 0.8200446  1.0710837
age          0.9390650 0.9154832  0.9625829
wcyes        2.2417880 1.4347543  3.5387571
hcyes        1.1182149 0.7467654  1.6766380
lwg          1.8306903 1.3689201  2.4768235
inc          0.9661401 0.9502809  0.9814042

> 
> # use for data frames vs. summary()
> Duncan.1 <-Duncan
> Duncan.1$type <- as.character(Duncan$type)
> summary(Duncan.1)
     type               income        education         prestige    
 Length:45          Min.   : 7.00   Min.   :  7.00   Min.   : 3.00  
 Class :character   1st Qu.:21.00   1st Qu.: 26.00   1st Qu.:16.00  
 Mode  :character   Median :42.00   Median : 45.00   Median :41.00  
                    Mean   :41.87   Mean   : 52.56   Mean   :47.69  
                    3rd Qu.:64.00   3rd Qu.: 84.00   3rd Qu.:81.00  
                    Max.   :81.00   Max.   :100.00   Max.   :97.00  
> S(Duncan.1)
   type        income        education         prestige    
 bc  :21   Min.   : 7.00   Min.   :  7.00   Min.   : 3.00  
 prof:18   1st Qu.:21.00   1st Qu.: 26.00   1st Qu.:16.00  
 wc  : 6   Median :42.00   Median : 45.00   Median :41.00  
           Mean   :41.87   Mean   : 52.56   Mean   :47.69  
           3rd Qu.:64.00   3rd Qu.: 84.00   3rd Qu.:81.00  
           Max.   :81.00   Max.   :100.00   Max.   :97.00  
> 
> ## Not run: 
> ##D  # generates an error, which can then be corrected to run example
> ##D # Using the bootstrap for standard errors
> ##D b1 <- Boot(mod.prestige)
> ##D S(mod.prestige, vcov.= vcov(b1))
> ##D Confint(b1) # run with the boot object to get corrected confidence intervals
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("ScatterplotSmoothers")
> ### * ScatterplotSmoothers
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: ScatterplotSmoothers
> ### Title: Smoothers to Draw Lines on Scatterplots
> ### Aliases: ScatterplotSmoothers gamLine quantregLine loessLine
> ### Keywords: hplot
> 
> ### ** Examples
> 
> scatterplot(prestige ~ income, data=Prestige)
> scatterplot(prestige ~ income, data=Prestige, smooth=list(smoother=gamLine))
> scatterplot(prestige ~ income, data=Prestige,
+     smooth=list(smoother=quantregLine))
Error in validObject(.Object) : 
  invalid class “dsparseModelMatrix” object: superclass "xMatrix" not defined in the environment of the object's class
Calls: scatterplot ... initialize -> callNextMethod -> .nextMethod -> validObject
Execution halted
