
R version 4.3.3 (2024-02-29) -- "Angel Food Cake"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "modelr"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('modelr')
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("add_predictions")
> ### * add_predictions
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: add_predictions
> ### Title: Add predictions to a data frame
> ### Aliases: add_predictions spread_predictions gather_predictions
> 
> ### ** Examples
> 
> df <- tibble::tibble(
+   x = sort(runif(100)),
+   y = 5 * x + 0.5 * x ^ 2 + 3 + rnorm(length(x))
+ )
> plot(df)
> 
> m1 <- lm(y ~ x, data = df)
> grid <- data.frame(x = seq(0, 1, length = 10))
> grid %>% add_predictions(m1)
           x     pred
1  0.0000000 3.272090
2  0.1111111 3.801867
3  0.2222222 4.331644
4  0.3333333 4.861421
5  0.4444444 5.391198
6  0.5555556 5.920975
7  0.6666667 6.450752
8  0.7777778 6.980529
9  0.8888889 7.510307
10 1.0000000 8.040084
> 
> m2 <- lm(y ~ poly(x, 2), data = df)
> grid %>% spread_predictions(m1, m2)
           x       m1       m2
1  0.0000000 3.272090 3.072074
2  0.1111111 3.801867 3.709839
3  0.2222222 4.331644 4.321005
4  0.3333333 4.861421 4.905570
5  0.4444444 5.391198 5.463534
6  0.5555556 5.920975 5.994898
7  0.6666667 6.450752 6.499662
8  0.7777778 6.980529 6.977825
9  0.8888889 7.510307 7.429387
10 1.0000000 8.040084 7.854349
> grid %>% gather_predictions(m1, m2)
   model         x     pred
1     m1 0.0000000 3.272090
2     m1 0.1111111 3.801867
3     m1 0.2222222 4.331644
4     m1 0.3333333 4.861421
5     m1 0.4444444 5.391198
6     m1 0.5555556 5.920975
7     m1 0.6666667 6.450752
8     m1 0.7777778 6.980529
9     m1 0.8888889 7.510307
10    m1 1.0000000 8.040084
11    m2 0.0000000 3.072074
12    m2 0.1111111 3.709839
13    m2 0.2222222 4.321005
14    m2 0.3333333 4.905570
15    m2 0.4444444 5.463534
16    m2 0.5555556 5.994898
17    m2 0.6666667 6.499662
18    m2 0.7777778 6.977825
19    m2 0.8888889 7.429387
20    m2 1.0000000 7.854349
> 
> 
> 
> cleanEx()
> nameEx("add_predictors")
> ### * add_predictors
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: add_predictors
> ### Title: Add predictors to a formula
> ### Aliases: add_predictors
> 
> ### ** Examples
> 
> f <- lhs ~ rhs
> add_predictors(f, ~var1, ~var2)
lhs ~ rhs + var1 + var2
> 
> # Left-hand sides are ignored:
> add_predictors(f, lhs1 ~ var1, lhs2 ~ var2)
lhs ~ rhs + var1 + var2
> 
> # fun can also be set to a function like "*":
> add_predictors(f, ~var1, ~var2, fun = "*")
lhs ~ rhs * var1 * var2
> 
> 
> 
> cleanEx()
> nameEx("add_residuals")
> ### * add_residuals
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: add_residuals
> ### Title: Add residuals to a data frame
> ### Aliases: add_residuals spread_residuals gather_residuals
> 
> ### ** Examples
> 
> df <- tibble::tibble(
+   x = sort(runif(100)),
+   y = 5 * x + 0.5 * x ^ 2 + 3 + rnorm(length(x))
+ )
> plot(df)
> 
> m1 <- lm(y ~ x, data = df)
> df %>% add_residuals(m1)
# A tibble: 100 × 3
        x     y   resid
    <dbl> <dbl>   <dbl>
 1 0.0134  3.47  0.129 
 2 0.0233  2.50 -0.878 
 3 0.0589  3.64  0.0844
 4 0.0618  2.18 -1.39  
 5 0.0707  4.79  1.18  
 6 0.0842  5.41  1.73  
 7 0.0995  3.14 -0.611 
 8 0.108   2.50 -1.29  
 9 0.122   4.19  0.333 
10 0.126   3.50 -0.370 
# ℹ 90 more rows
> 
> m2 <- lm(y ~ poly(x, 2), data = df)
> df %>% spread_residuals(m1, m2)
# A tibble: 100 × 4
        x     y      m1     m2
    <dbl> <dbl>   <dbl>  <dbl>
 1 0.0134  3.47  0.129   0.315
 2 0.0233  2.50 -0.878  -0.703
 3 0.0589  3.64  0.0844  0.224
 4 0.0618  2.18 -1.39   -1.25 
 5 0.0707  4.79  1.18    1.31 
 6 0.0842  5.41  1.73    1.85 
 7 0.0995  3.14 -0.611  -0.509
 8 0.108   2.50 -1.29   -1.19 
 9 0.122   4.19  0.333   0.416
10 0.126   3.50 -0.370  -0.290
# ℹ 90 more rows
> df %>% gather_residuals(m1, m2)
# A tibble: 200 × 4
   model      x     y   resid
   <chr>  <dbl> <dbl>   <dbl>
 1 m1    0.0134  3.47  0.129 
 2 m1    0.0233  2.50 -0.878 
 3 m1    0.0589  3.64  0.0844
 4 m1    0.0618  2.18 -1.39  
 5 m1    0.0707  4.79  1.18  
 6 m1    0.0842  5.41  1.73  
 7 m1    0.0995  3.14 -0.611 
 8 m1    0.108   2.50 -1.29  
 9 m1    0.122   4.19  0.333 
10 m1    0.126   3.50 -0.370 
# ℹ 190 more rows
> 
> 
> 
> cleanEx()
> nameEx("bootstrap")
> ### * bootstrap
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bootstrap
> ### Title: Generate 'n' bootstrap replicates.
> ### Aliases: bootstrap
> 
> ### ** Examples
> 
> library(purrr)
> boot <- bootstrap(mtcars, 100)
> 
> models <- map(boot$strap, ~ lm(mpg ~ wt, data = .))
> tidied <- map_df(models, broom::tidy, .id = "id")
> 
> hist(subset(tidied, term == "wt")$estimate)
> hist(subset(tidied, term == "(Intercept)")$estimate)
> 
> 
> 
> cleanEx()

detaching ‘package:purrr’

> nameEx("crossv_mc")
> ### * crossv_mc
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: crossv_mc
> ### Title: Generate test-training pairs for cross-validation
> ### Aliases: crossv_mc crossv_kfold crossv_loo
> 
> ### ** Examples
> 
> cv1 <- crossv_kfold(mtcars, 5)
> cv1
# A tibble: 5 × 3
  train                test                .id  
  <named list>         <named list>        <chr>
1 <resample [25 x 11]> <resample [7 x 11]> 1    
2 <resample [25 x 11]> <resample [7 x 11]> 2    
3 <resample [26 x 11]> <resample [6 x 11]> 3    
4 <resample [26 x 11]> <resample [6 x 11]> 4    
5 <resample [26 x 11]> <resample [6 x 11]> 5    
> 
> library(purrr)
> cv2 <- crossv_mc(mtcars, 100)
> models <- map(cv2$train, ~ lm(mpg ~ wt, data = .))
> errs <- map2_dbl(models, cv2$test, rmse)
> hist(errs)
> 
> 
> 
> cleanEx()

detaching ‘package:purrr’

> nameEx("data_grid")
> ### * data_grid
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: data_grid
> ### Title: Generate a data grid.
> ### Aliases: data_grid
> 
> ### ** Examples
> 
> data_grid(mtcars, vs, am)
# A tibble: 4 × 2
     vs    am
  <dbl> <dbl>
1     0     0
2     0     1
3     1     0
4     1     1
> 
> # For continuous variables, seq_range is useful
> data_grid(mtcars, mpg = mpg)
# A tibble: 25 × 1
     mpg
   <dbl>
 1  10.4
 2  13.3
 3  14.3
 4  14.7
 5  15  
 6  15.2
 7  15.5
 8  15.8
 9  16.4
10  17.3
# ℹ 15 more rows
> data_grid(mtcars, mpg = seq_range(mpg, 10))
# A tibble: 10 × 1
     mpg
   <dbl>
 1  10.4
 2  13.0
 3  15.6
 4  18.2
 5  20.8
 6  23.5
 7  26.1
 8  28.7
 9  31.3
10  33.9
> 
> # If you supply a model, missing predictors will be filled in with
> # typical values
> mod <- lm(mpg ~ wt + cyl + vs, data = mtcars)
> data_grid(mtcars, .model = mod)
# A tibble: 1 × 3
     wt   cyl    vs
  <dbl> <dbl> <dbl>
1  3.32     6     0
> data_grid(mtcars, cyl = seq_range(cyl, 9), .model = mod)
# A tibble: 9 × 3
    cyl    wt    vs
  <dbl> <dbl> <dbl>
1   4    3.32     0
2   4.5  3.32     0
3   5    3.32     0
4   5.5  3.32     0
5   6    3.32     0
6   6.5  3.32     0
7   7    3.32     0
8   7.5  3.32     0
9   8    3.32     0
> 
> 
> 
> cleanEx()
> nameEx("fit_with")
> ### * fit_with
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: fit_with
> ### Title: Fit a list of formulas
> ### Aliases: fit_with
> 
> ### ** Examples
> 
> # fit_with() is typically used with formulas().
> disp_fits <- mtcars %>% fit_with(lm, formulas(~disp,
+   additive = ~drat + cyl,
+   interaction = ~drat * cyl,
+   full = add_predictors(interaction, ~am, ~vs)
+ ))
> 
> # The list of fitted models is named after the names of the list of
> # formulas:
> disp_fits$full

Call:
.f(formula = disp ~ drat * cyl + am + vs, data = data)

Coefficients:
(Intercept)         drat          cyl           am           vs     drat:cyl  
    -164.83        27.58        75.84       -38.22       -15.53        -6.97  

> 
> # Additional arguments are passed on to .f
> mtcars %>% fit_with(glm, list(am ~ disp), family = binomial)
[[1]]

Call:  .f(formula = am ~ disp, family = function (link = "logit") 
{
    linktemp <- substitute(link)
    if (!is.character(linktemp)) 
        linktemp <- deparse(linktemp)
    okLinks <- c("logit", "probit", "cloglog", "cauchit", "log")
    family <- "binomial"
    if (linktemp %in% okLinks) 
        stats <- make.link(linktemp)
    else if (is.character(link)) {
        stats <- make.link(link)
        linktemp <- link
    }
    else {
        if (inherits(link, "link-glm")) {
            stats <- link
            if (!is.null(stats$name)) 
                linktemp <- stats$name
        }
        else {
            stop(gettextf("link \"%s\" not available for %s family; available links are %s", 
                linktemp, family, paste(sQuote(okLinks), collapse = ", ")), 
                domain = NA)
        }
    }
    variance <- function(mu) mu * (1 - mu)
    validmu <- function(mu) all(is.finite(mu)) && all(mu > 0 & 
        mu < 1)
    dev.resids <- function(y, mu, wt) .Call(C_binomial_dev_resids, 
        y, mu, wt)
    aic <- function(y, n, mu, wt, dev) {
        m <- if (any(n > 1)) 
            n
        else wt
        -2 * sum(ifelse(m > 0, (wt/m), 0) * dbinom(round(m * 
            y), round(m), mu, log = TRUE))
    }
    simfun <- function(object, nsim) {
        ftd <- fitted(object)
        n <- length(ftd)
        ntot <- n * nsim
        wts <- object$prior.weights
        if (any(wts%%1 != 0)) 
            stop("cannot simulate from non-integer prior.weights")
        if (!is.null(m <- object$model)) {
            y <- model.response(m)
            if (is.factor(y)) {
                yy <- factor(1 + rbinom(ntot, size = 1, prob = ftd), 
                  labels = levels(y))
                split(yy, rep(seq_len(nsim), each = n))
            }
            else if (is.matrix(y) && ncol(y) == 2) {
                yy <- vector("list", nsim)
                for (i in seq_len(nsim)) {
                  Y <- rbinom(n, size = wts, prob = ftd)
                  YY <- cbind(Y, wts - Y)
                  colnames(YY) <- colnames(y)
                  yy[[i]] <- YY
                }
                yy
            }
            else rbinom(ntot, size = wts, prob = ftd)/wts
        }
        else rbinom(ntot, size = wts, prob = ftd)/wts
    }
    structure(list(family = family, link = linktemp, linkfun = stats$linkfun, 
        linkinv = stats$linkinv, variance = variance, dev.resids = dev.resids, 
        aic = aic, mu.eta = stats$mu.eta, initialize = binomInitialize(family), 
        validmu = validmu, valideta = stats$valideta, simulate = simfun, 
        dispersion = 1), class = "family")
}, data = data)

Coefficients:
(Intercept)         disp  
     2.6308      -0.0146  

Degrees of Freedom: 31 Total (i.e. Null);  30 Residual
Null Deviance:	    43.23 
Residual Deviance: 29.73 	AIC: 33.73

> 
> 
> 
> cleanEx()
> nameEx("formulas")
> ### * formulas
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: formulas
> ### Title: Create a list of formulas
> ### Aliases: formulas formulae
> 
> ### ** Examples
> 
> # Provide named arguments to create a named list of formulas:
> models <- formulas(~lhs,
+   additive = ~var1 + var2,
+   interaction = ~var1 * var2
+ )
> models$additive
lhs ~ var1 + var2
> 
> # The formulas are created sequentially, so that you can refer to
> # previously created formulas:
> formulas(~lhs,
+   linear = ~var1 + var2,
+   hierarchical = add_predictors(linear, ~(1 | group))
+ )
$linear
lhs ~ var1 + var2

$hierarchical
lhs ~ var1 + var2 + (1 | group)

> 
> 
> 
> cleanEx()
> nameEx("model-quality")
> ### * model-quality
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model-quality
> ### Title: Compute model quality for a given dataset
> ### Aliases: model-quality mse rmse mae rsquare qae mape rsae
> 
> ### ** Examples
> 
> mod <- lm(mpg ~ wt, data = mtcars)
> mse(mod, mtcars)
[1] 8.697561
> rmse(mod, mtcars)
[1] 2.949163
> rsquare(mod, mtcars)
[1] 0.7528328
> mae(mod, mtcars)
[1] 2.340642
> qae(mod, mtcars)
       5%       25%       50%       75%       95% 
0.1784985 1.0005640 2.0946199 3.2696108 6.1794815 
> mape(mod, mtcars)
[1] 0.1260733
> rsae(mod, mtcars)
[1] 0.1165042
> 
> 
> 
> cleanEx()
> nameEx("model_matrix")
> ### * model_matrix
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_matrix
> ### Title: Construct a design matrix
> ### Aliases: model_matrix
> 
> ### ** Examples
> 
> model_matrix(mtcars, mpg ~ cyl)
# A tibble: 32 × 2
   `(Intercept)`   cyl
           <dbl> <dbl>
 1             1     6
 2             1     6
 3             1     4
 4             1     6
 5             1     8
 6             1     6
 7             1     8
 8             1     4
 9             1     4
10             1     6
# ℹ 22 more rows
> model_matrix(iris, Sepal.Length ~ Species)
# A tibble: 150 × 3
   `(Intercept)` Speciesversicolor Speciesvirginica
           <dbl>             <dbl>            <dbl>
 1             1                 0                0
 2             1                 0                0
 3             1                 0                0
 4             1                 0                0
 5             1                 0                0
 6             1                 0                0
 7             1                 0                0
 8             1                 0                0
 9             1                 0                0
10             1                 0                0
# ℹ 140 more rows
> model_matrix(iris, Sepal.Length ~ Species - 1)
# A tibble: 150 × 3
   Speciessetosa Speciesversicolor Speciesvirginica
           <dbl>             <dbl>            <dbl>
 1             1                 0                0
 2             1                 0                0
 3             1                 0                0
 4             1                 0                0
 5             1                 0                0
 6             1                 0                0
 7             1                 0                0
 8             1                 0                0
 9             1                 0                0
10             1                 0                0
# ℹ 140 more rows
> 
> 
> 
> cleanEx()
> nameEx("na.warn")
> ### * na.warn
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: na.warn
> ### Title: Handle missing values with a warning
> ### Aliases: na.warn
> 
> ### ** Examples
> 
> df <- tibble::tibble(
+   x = 1:10,
+   y = c(5.1, 9.7, NA, 17.4, 21.2, 26.6, 27.9, NA, 36.3, 40.4)
+ )
> # Default behaviour is to silently drop
> m1 <- lm(y ~ x, data = df)
> resid(m1)
          1           2           4           5           6           7 
-0.59214286  0.14500000  0.11928571  0.05642857  1.59357143 -0.96928571 
          9          10 
-0.29500000 -0.05785714 
> 
> # Use na.action = na.warn to warn
> m2 <- lm(y ~ x, data = df, na.action = na.warn)
Warning: Dropping 2 rows with missing values
> resid(m2)
          1           2           3           4           5           6 
-0.59214286  0.14500000          NA  0.11928571  0.05642857  1.59357143 
          7           8           9          10 
-0.96928571          NA -0.29500000 -0.05785714 
> 
> 
> 
> cleanEx()
> nameEx("permute")
> ### * permute
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: permute
> ### Title: Generate 'n' permutation replicates.
> ### Aliases: permute permute_
> 
> ### ** Examples
> 
> 
> library(purrr)
> perms <- permute(mtcars, 100, mpg)
> 
> models <- map(perms$perm, ~ lm(mpg ~ wt, data = .))
> glanced <- map_df(models, broom::glance, .id = "id")
> 
> # distribution of null permutation statistics
> hist(glanced$statistic)
> # confirm these are roughly uniform p-values
> hist(glanced$p.value)
> 
> # test against the unpermuted model to get a permutation p-value
> mod <- lm(mpg ~ wt, mtcars)
> mean(glanced$statistic > broom::glance(mod)$statistic)
[1] 0
> 
> 
> 
> 
> cleanEx()

detaching ‘package:purrr’

> nameEx("resample")
> ### * resample
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: resample
> ### Title: A "lazy" resample.
> ### Aliases: resample
> 
> ### ** Examples
> 
> resample(mtcars, 1:10)
<resample [10 x 11]> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10
> 
> b <- resample_bootstrap(mtcars)
> b
<resample [32 x 11]> 25, 4, 7, 1, 2, 29, 23, 11, 14, 18, ...
> as.integer(b)
 [1] 25  4  7  1  2 29 23 11 14 18 27 19  1 21 21 10 22 14 10  7  9 15 21  5  9
[26] 25 14  5  5  2 10 30
> as.data.frame(b)
                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb
Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2
Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1
Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4
Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4
Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4
Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4
AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2
Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4
Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3
Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1
Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2
Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2
Mazda RX4.1         21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4
Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1
Toyota Corona.1     21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1
Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4
Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2
Merc 450SLC.1       15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3
Merc 280.1          19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4
Duster 360.1        14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4
Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2
Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4
Toyota Corona.2     21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1
Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2
Merc 230.1          22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2
Pontiac Firebird.1  19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2
Merc 450SLC.2       15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3
Hornet Sportabout.1 18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2
Hornet Sportabout.2 18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2
Mazda RX4 Wag.1     21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4
Merc 280.2          19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4
Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6
> 
> # Many modelling functions will do the coercion for you, so you can
> # use a resample object directly in the data argument
> lm(mpg ~ wt, data = b)

Call:
lm(formula = mpg ~ wt, data = b)

Coefficients:
(Intercept)           wt  
     37.145       -5.512  

> 
> 
> 
> cleanEx()
> nameEx("resample_bootstrap")
> ### * resample_bootstrap
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: resample_bootstrap
> ### Title: Generate a boostrap replicate
> ### Aliases: resample_bootstrap
> 
> ### ** Examples
> 
> coef(lm(mpg ~ wt, data = resample_bootstrap(mtcars)))
(Intercept)          wt 
  37.144812   -5.512313 
> coef(lm(mpg ~ wt, data = resample_bootstrap(mtcars)))
(Intercept)          wt 
  40.597485   -6.199511 
> coef(lm(mpg ~ wt, data = resample_bootstrap(mtcars)))
(Intercept)          wt 
  38.951312   -5.790039 
> 
> 
> 
> cleanEx()
> nameEx("resample_partition")
> ### * resample_partition
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: resample_partition
> ### Title: Generate an exclusive partitioning of a data frame
> ### Aliases: resample_partition
> 
> ### ** Examples
> 
> ex <- resample_partition(mtcars, c(test = 0.3, train = 0.7))
> mod <- lm(mpg ~ wt, data = ex$train)
> rmse(mod, ex$test)
[1] 2.903158
> rmse(mod, ex$train)
[1] 3.064281
> 
> 
> 
> cleanEx()
> nameEx("seq_range")
> ### * seq_range
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: seq_range
> ### Title: Generate a sequence over the range of a vector
> ### Aliases: seq_range
> 
> ### ** Examples
> 
> x <- rcauchy(100)
> seq_range(x, n = 10)
 [1] -17.0624497   0.2053339  17.4731176  34.7409012  52.0086849  69.2764685
 [7]  86.5442522 103.8120358 121.0798195 138.3476031
> seq_range(x, n = 10, trim = 0.1)
 [1] -2.9312230 -1.0535618  0.8240994  2.7017606  4.5794218  6.4570830
 [7]  8.3347442 10.2124054 12.0900666 13.9677278
> seq_range(x, by = 1, trim = 0.1)
 [1] -2.93122304 -1.93122304 -0.93122304  0.06877696  1.06877696  2.06877696
 [7]  3.06877696  4.06877696  5.06877696  6.06877696  7.06877696  8.06877696
[13]  9.06877696 10.06877696 11.06877696 12.06877696 13.06877696
> 
> # Make pretty sequences
> y <- runif(100)
> seq_range(y, n = 10)
 [1] 0.01307758 0.12192274 0.23076791 0.33961307 0.44845824 0.55730340
 [7] 0.66614857 0.77499373 0.88383890 0.99268406
> seq_range(y, n = 10, pretty = TRUE)
 [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
> seq_range(y, n = 10, expand = 0.5, pretty = TRUE)
 [1] -0.4 -0.2  0.0  0.2  0.4  0.6  0.8  1.0  1.2  1.4
> 
> seq_range(y, by = 0.1)
 [1] 0.01307758 0.11307758 0.21307758 0.31307758 0.41307758 0.51307758
 [7] 0.61307758 0.71307758 0.81307758 0.91307758
> seq_range(y, by = 0.1, pretty = TRUE)
 [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
> 
> 
> 
> cleanEx()
> nameEx("typical")
> ### * typical
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: typical
> ### Title: Find the typical value
> ### Aliases: typical
> 
> ### ** Examples
> 
> # median of numeric vector
> typical(rpois(100, lambda = 10))
[1] 10
> 
> # most frequent value of character or factor
> x <- sample(c("a", "b", "c"), 100, prob = c(0.6, 0.2, 0.2), replace = TRUE)
> typical(x)
[1] "a"
> typical(factor(x))
[1] "a"
> 
> # if tied, returns them all
> x <- c("a", "a", "b", "b", "c")
> typical(x)
[1] "a" "b"
> 
> # median of an ordered factor
> typical(ordered(c("a", "a", "b", "c", "d")))
[1] "b"
> 
> 
> 
> 
> ### * <FOOTER>
> ###
> cleanEx()
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  1.258 0.035 1.295 0 0 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
