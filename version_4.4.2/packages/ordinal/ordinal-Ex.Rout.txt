
R version 4.4.2 (2024-10-31) -- "Pile of Leaves"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "ordinal"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('ordinal')
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("VarCorr")
> ### * VarCorr
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: VarCorr
> ### Title: Extract variance and correlation parameters
> ### Aliases: VarCorr VarCorr.clmm
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> fm1 <- clmm(rating ~ contact + temp + (1|judge), data=wine)
> VarCorr(fm1)
$judge
            (Intercept)
(Intercept)    1.279461
attr(,"stddev")
(Intercept) 
   1.131133 

> 
> 
> 
> 
> cleanEx()
> nameEx("addtermOld")
> ### * addtermOld
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: addterm.clm2
> ### Title: Try all one-term additions to and deletions from a model
> ### Aliases: addterm.clm2 dropterm.clm2
> ### Keywords: internal
> 
> ### ** Examples
> 
> 
> options(contrasts = c("contr.treatment", "contr.poly"))
> 
> if(require(MASS)) { ## dropterm, addterm, housing
+     mB1 <- clm2(SURENESS ~ PROD + GENDER + SOUPTYPE,
+                 scale = ~ COLD, data = soup, link = "probit",
+                 Hess = FALSE)
+     dropterm(mB1, test = "Chi")       # or
+     dropterm(mB1, which = "location", test = "Chi")
+     dropterm(mB1, which = "scale", test = "Chi")
+     addterm(mB1, scope = ~.^2, test = "Chi", which = "location")
+     addterm(mB1, scope = ~ . + GENDER + SOUPTYPE,
+             test = "Chi", which = "scale")
+     addterm(mB1, scope = ~ . + AGEGROUP + SOUPFREQ,
+             test = "Chi", which = "location")
+ 
+     ## Fit model from polr example:
+     fm1 <- clm2(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
+     addterm(fm1, ~ Infl + Type + Cont, test= "Chisq", which = "scale")
+     dropterm(fm1, test = "Chisq")
+ }
Loading required package: MASS
Single term deletions

Model:
location : Sat ~ Infl + Type + Cont
       Df    AIC     LRT   Pr(Chi)    
<none>    3495.1                      
Infl    2 3599.4 108.239 < 2.2e-16 ***
Type    3 3545.1  55.910 4.391e-12 ***
Cont    1 3507.5  14.306 0.0001554 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> 
> 
> 
> 
> base::options(contrasts = c(unordered = "contr.treatment",ordered = "contr.poly"))
> cleanEx()

detaching ‘package:MASS’

> nameEx("anovaOld")
> ### * anovaOld
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: anova.clm2
> ### Title: Likelihood ratio test of cumulative link models
> ### Aliases: anova.clm2 anova.clmm2
> ### Keywords: internal
> 
> ### ** Examples
> 
> options(contrasts = c("contr.treatment", "contr.poly"))
> m1 <- clm2(SURENESS ~ PROD, scale = ~PROD, data = soup,
+           link = "logistic")
> 
> ## anova
> anova(m1, update(m1, scale = ~.-PROD))
Likelihood ratio tests of cumulative link models

Response: SURENESS
           Model Resid. df -2logLik   Test    Df LR stat.  Pr(Chi)
1    PROD | 1 |       1841 5380.664                               
2 PROD | PROD |       1840 5375.489 1 vs 2     1 5.174937 0.022915
> mN1 <- clm2(SURENESS ~ 1, nominal = ~PROD, data = soup,
+            link = "logistic")
> anova(m1, mN1)
Likelihood ratio tests of cumulative link models

Response: SURENESS
           Model Resid. df -2logLik   Test    Df LR stat.   Pr(Chi)
1 PROD | PROD |       1840 5375.489                                
2    1 |  | PROD      1837 5370.114 1 vs 2     3 5.375473 0.1462793
> anova(m1, update(m1, scale = ~.-PROD), mN1)
Likelihood ratio tests of cumulative link models

Response: SURENESS
           Model Resid. df -2logLik   Test    Df LR stat.   Pr(Chi)
1    PROD | 1 |       1841 5380.664                                
2 PROD | PROD |       1840 5375.489 1 vs 2     1 5.174937 0.0229150
3    1 |  | PROD      1837 5370.114 2 vs 3     3 5.375473 0.1462793
> 
> ## Fit model from polr example:
> if(require(MASS)) {
+     fm1 <- clm2(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
+     anova(fm1, update(fm1, scale =~ Cont))
+ }
Loading required package: MASS
Likelihood ratio tests of cumulative link models

Response: Sat
                         Model Resid. df -2logLik   Test    Df LR stat.
1     Infl + Type + Cont |  |       1673 3479.149                      
2 Infl + Type + Cont | Cont |       1672 3473.493 1 vs 2     1 5.655882
     Pr(Chi)
1           
2 0.01739692
> 
> 
> 
> 
> base::options(contrasts = c(unordered = "contr.treatment",ordered = "contr.poly"))
> cleanEx()

detaching ‘package:MASS’

> nameEx("clm")
> ### * clm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: clm
> ### Title: Cumulative Link Models
> ### Aliases: clm
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> fm1 <- clm(rating ~ temp * contact, data = wine)
> fm1 ## print method
formula: rating ~ temp * contact
data:    wine

 link  threshold nobs logLik AIC    niter max.grad cond.H 
 logit flexible  72   -86.42 186.83 6(0)  5.22e-12 5.1e+01

Coefficients:
           tempwarm          contactyes tempwarm:contactyes 
             2.3212              1.3475              0.3595 

Threshold coefficients:
   1|2    2|3    3|4    4|5 
-1.411  1.144  3.377  4.942 
> summary(fm1)
formula: rating ~ temp * contact
data:    wine

 link  threshold nobs logLik AIC    niter max.grad cond.H 
 logit flexible  72   -86.42 186.83 6(0)  5.22e-12 5.1e+01

Coefficients:
                    Estimate Std. Error z value Pr(>|z|)    
tempwarm              2.3212     0.7009   3.311 0.000928 ***
contactyes            1.3475     0.6604   2.041 0.041300 *  
tempwarm:contactyes   0.3595     0.9238   0.389 0.697129    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -1.4113     0.5454  -2.588
2|3   1.1436     0.5097   2.244
3|4   3.3771     0.6382   5.292
4|5   4.9420     0.7509   6.581
> fm2 <- update(fm1, ~.-temp:contact)
> anova(fm1, fm2)
Likelihood ratio tests of cumulative link models:
 
    formula:                link: threshold:
fm2 rating ~ temp + contact logit flexible  
fm1 rating ~ temp * contact logit flexible  

    no.par    AIC  logLik LR.stat df Pr(>Chisq)
fm2      6 184.98 -86.492                      
fm1      7 186.83 -86.416  0.1514  1     0.6972
> 
> drop1(fm1, test = "Chi")
Single term deletions

Model:
rating ~ temp * contact
             Df    AIC     LRT Pr(>Chi)
<none>          186.83                 
temp:contact  1 184.98 0.15145   0.6972
> add1(fm1, ~.+judge, test = "Chi")
Single term additions

Model:
rating ~ temp * contact
       Df    AIC    LRT  Pr(>Chi)    
<none>    186.83                     
judge   8 171.80 31.036 0.0001384 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> 
> fm2 <- step(fm1)
Start:  AIC=186.83
rating ~ temp * contact

               Df    AIC
- temp:contact  1 184.98
<none>            186.83

Step:  AIC=184.98
rating ~ temp + contact

          Df    AIC
<none>       184.98
- contact  1 194.03
- temp     1 209.91
> summary(fm2)
formula: rating ~ temp + contact
data:    wine

 link  threshold nobs logLik AIC    niter max.grad cond.H 
 logit flexible  72   -86.49 184.98 6(0)  4.01e-12 2.7e+01

Coefficients:
           Estimate Std. Error z value Pr(>|z|)    
tempwarm     2.5031     0.5287   4.735 2.19e-06 ***
contactyes   1.5278     0.4766   3.205  0.00135 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -1.3444     0.5171  -2.600
2|3   1.2508     0.4379   2.857
3|4   3.4669     0.5978   5.800
4|5   5.0064     0.7309   6.850
> 
> coef(fm1)
                1|2                 2|3                 3|4                 4|5 
         -1.4112620           1.1435537           3.3770825           4.9419823 
           tempwarm          contactyes tempwarm:contactyes 
          2.3211843           1.3474604           0.3595489 
> vcov(fm1)
                           1|2        2|3        3|4        4|5   tempwarm
1|2                  0.2974102  0.1433319  0.1434281  0.1437944  0.1470096
2|3                  0.1433319  0.2597488  0.2498799  0.2501820  0.2521417
3|4                  0.1434281  0.2498799  0.4072504  0.3976946  0.3249357
4|5                  0.1437944  0.2501820  0.3976946  0.5638677  0.3317317
tempwarm             0.1470096  0.2521417  0.3249357  0.3317317  0.4913280
contactyes           0.1565436  0.2477552  0.2730741  0.2730982  0.2581980
tempwarm:contactyes -0.1598445 -0.2494219 -0.2039255 -0.1408440 -0.4256882
                    contactyes tempwarm:contactyes
1|2                  0.1565436          -0.1598445
2|3                  0.2477552          -0.2494219
3|4                  0.2730741          -0.2039255
4|5                  0.2730982          -0.1408440
tempwarm             0.2581980          -0.4256882
contactyes           0.4360696          -0.4226690
tempwarm:contactyes -0.4226690           0.8534413
> AIC(fm1)
[1] 186.8324
> extractAIC(fm1)
[1]   7.0000 186.8324
> logLik(fm1)
'log Lik.' -86.4162 (df=7)
> fitted(fm1)
 [1] 0.56229641 0.20864908 0.43467309 0.08938852 0.19028226 0.19028226
 [7] 0.28622518 0.28622518 0.19603509 0.56229641 0.05959593 0.43467309
[13] 0.21210373 0.50642742 0.28622518 0.37103562 0.56229641 0.20864908
[19] 0.43467309 0.38960327 0.06781183 0.06781183 0.37103562 0.37103562
[25] 0.20864908 0.56229641 0.43467309 0.38960327 0.50642742 0.21210373
[31] 0.28622518 0.28982109 0.56229641 0.20864908 0.08938852 0.43467309
[37] 0.50642742 0.50642742 0.28982109 0.28982109 0.20864908 0.56229641
[43] 0.43467309 0.38960327 0.21210373 0.19028226 0.28622518 0.37103562
[49] 0.19603509 0.19603509 0.38960327 0.38960327 0.21210373 0.50642742
[55] 0.04859504 0.28982109 0.56229641 0.56229641 0.38960327 0.43467309
[61] 0.50642742 0.50642742 0.28982109 0.37103562 0.19603509 0.56229641
[67] 0.43467309 0.38960327 0.50642742 0.21210373 0.37103562 0.37103562
> 
> confint(fm1) ## type = "profile"
                          2.5 %   97.5 %
tempwarm             0.99435182 3.761793
contactyes           0.08378091 2.694828
tempwarm:contactyes -1.45985126 2.180286
> confint(fm1, type = "Wald")
                          2.5 %     97.5 %
1|2                 -2.48013466 -0.3423893
2|3                  0.14464718  2.1424601
3|4                  2.12630850  4.6278565
4|5                  3.47022323  6.4137413
tempwarm             0.94735154  3.6950170
contactyes           0.05318714  2.6417337
tempwarm:contactyes -1.45110279  2.1702006
> pr1 <- profile(fm1)
> confint(pr1)
                          2.5 %   97.5 %
tempwarm             0.99438454 3.761828
contactyes           0.08379044 2.694864
tempwarm:contactyes -1.45984555 2.180280
> 
> ## plotting the profiles:
> par(mfrow = c(2, 2))
> plot(pr1, root = TRUE) ## check for linearity
> par(mfrow = c(2, 2))
> plot(pr1)
> par(mfrow = c(2, 2))
> plot(pr1, approx = TRUE)
> par(mfrow = c(2, 2))
> plot(pr1, Log = TRUE)
> par(mfrow = c(2, 2))
> plot(pr1, Log = TRUE, relative = FALSE)
> 
> ## other link functions:
> fm4.lgt <- update(fm1, link = "logit") ## default
> fm4.prt <- update(fm1, link = "probit")
> fm4.ll <- update(fm1, link = "loglog")
> fm4.cll <- update(fm1, link = "cloglog")
> fm4.cct <- update(fm1, link = "cauchit")
> anova(fm4.lgt, fm4.prt, fm4.ll, fm4.cll, fm4.cct)
Likelihood ratio tests of cumulative link models:
 
        formula:                link:   threshold:
fm4.lgt rating ~ temp * contact logit   flexible  
fm4.prt rating ~ temp * contact probit  flexible  
fm4.ll  rating ~ temp * contact loglog  flexible  
fm4.cll rating ~ temp * contact cloglog flexible  
fm4.cct rating ~ temp * contact cauchit flexible  

        no.par    AIC  logLik  LR.stat df Pr(>Chisq)
fm4.lgt      7 186.83 -86.416                       
fm4.prt      7 185.45 -85.723   1.3864  0           
fm4.ll       7 189.14 -87.569  -3.6923  0           
fm4.cll      7 187.22 -86.610   1.9175  0           
fm4.cct      7 198.05 -92.027 -10.8323  0           
> 
> ## structured thresholds:
> fm5 <- update(fm1, threshold = "symmetric")
> fm6 <- update(fm1, threshold = "equidistant")
> anova(fm1, fm5, fm6)
Likelihood ratio tests of cumulative link models:
 
    formula:                link: threshold: 
fm6 rating ~ temp * contact logit equidistant
fm5 rating ~ temp * contact logit symmetric  
fm1 rating ~ temp * contact logit flexible   

    no.par    AIC  logLik LR.stat df Pr(>Chisq)
fm6      5 185.14 -87.570                      
fm5      6 187.05 -87.527  0.0864  1     0.7688
fm1      7 186.83 -86.416  2.2220  1     0.1361
> 
> ## the slice methods:
> slice.fm1 <- slice(fm1)
> par(mfrow = c(3, 3))
> plot(slice.fm1)
> ## see more at '?slice.clm'
> 
> ## Another example:
> fm.soup <- clm(SURENESS ~ PRODID, data = soup)
> summary(fm.soup)
formula: SURENESS ~ PRODID
data:    soup

 link  threshold nobs logLik   AIC     niter max.grad cond.H 
 logit flexible  1847 -2677.27 5374.54 6(1)  9.18e-13 2.3e+02

Coefficients:
        Estimate Std. Error z value Pr(>|z|)    
PRODID2   0.8925     0.1184   7.540 4.70e-14 ***
PRODID3   1.4477     0.1663   8.706  < 2e-16 ***
PRODID4   0.8325     0.1532   5.433 5.55e-08 ***
PRODID5   1.3109     0.1630   8.042 8.85e-16 ***
PRODID6   1.6010     0.1690   9.475  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
    Estimate Std. Error z value
1|2 -1.41244    0.08184 -17.258
2|3 -0.42924    0.06972  -6.157
3|4 -0.10340    0.06891  -1.500
4|5  0.15121    0.06906   2.189
5|6  0.82121    0.07201  11.404
> 
> if(require(MASS)) { ## dropterm, addterm, stepAIC, housing
+     fm1 <- clm(rating ~ temp * contact, data = wine)
+     dropterm(fm1, test = "Chi")
+     addterm(fm1, ~.+judge, test = "Chi")
+     fm3 <- stepAIC(fm1)
+     summary(fm3)
+ 
+     ## Example from MASS::polr:
+     fm1 <- clm(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
+     summary(fm1)
+ }
Loading required package: MASS
Start:  AIC=186.83
rating ~ temp * contact

               Df    AIC
- temp:contact  1 184.98
<none>            186.83

Step:  AIC=184.98
rating ~ temp + contact

          Df    AIC
<none>       184.98
- contact  1 194.03
- temp     1 209.91
formula: Sat ~ Infl + Type + Cont
data:    housing

 link  threshold nobs logLik   AIC     niter max.grad cond.H 
 logit flexible  1681 -1739.57 3495.15 4(0)  6.60e-09 4.7e+01

Coefficients:
              Estimate Std. Error z value Pr(>|z|)    
InflMedium     0.56639    0.10465   5.412 6.23e-08 ***
InflHigh       1.28882    0.12716  10.136  < 2e-16 ***
TypeApartment -0.57235    0.11924  -4.800 1.59e-06 ***
TypeAtrium    -0.36619    0.15517  -2.360 0.018282 *  
TypeTerrace   -1.09101    0.15149  -7.202 5.93e-13 ***
ContHigh       0.36028    0.09554   3.771 0.000162 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
            Estimate Std. Error z value
Low|Medium   -0.4961     0.1248  -3.974
Medium|High   0.6907     0.1255   5.505
> 
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()

detaching ‘package:MASS’

> nameEx("clm.anova")
> ### * clm.anova
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: anova.clm
> ### Title: ANODE Tables and Likelihood ratio test of cumulative link models
> ### Aliases: anova.clm
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> ## Analysis of deviance tables with Wald chi-square tests:
> fm <- clm(rating ~ temp * contact, scale=~contact, data=wine)
> anova(fm, type="I")
Type I Analysis of Deviance Table with Wald chi-square tests

             Df   Chisq Pr(>Chisq)    
temp          1 17.1046  3.538e-05 ***
contact       1  9.1574   0.002477 ** 
temp:contact  1  0.1097   0.740512    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> anova(fm, type="II")
Type II Analysis of Deviance Table with Wald chi-square tests

             Df   Chisq Pr(>Chisq)    
temp          1 17.1046  3.538e-05 ***
contact       1  9.1574   0.002477 ** 
temp:contact  1  0.1097   0.740512    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> anova(fm, type="III")
Type III Analysis of Deviance Table with Wald chi-square tests

             Df  Chisq Pr(>Chisq)   
temp          1 9.5681    0.00198 **
contact       1 4.1830    0.04083 * 
temp:contact  1 0.1097    0.74051   
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> 
> options(contrasts = c("contr.treatment", "contr.poly"))
> m1 <- clm2(SURENESS ~ PROD, scale = ~PROD, data = soup,
+           link = "logistic")
> 
> ## anova
> anova(m1, update(m1, scale = ~.-PROD))
Likelihood ratio tests of cumulative link models

Response: SURENESS
           Model Resid. df -2logLik   Test    Df LR stat.  Pr(Chi)
1    PROD | 1 |       1841 5380.664                               
2 PROD | PROD |       1840 5375.489 1 vs 2     1 5.174937 0.022915
> mN1 <- clm2(SURENESS ~ 1, nominal = ~PROD, data = soup,
+            link = "logistic")
> anova(m1, mN1)
Likelihood ratio tests of cumulative link models

Response: SURENESS
           Model Resid. df -2logLik   Test    Df LR stat.   Pr(Chi)
1 PROD | PROD |       1840 5375.489                                
2    1 |  | PROD      1837 5370.114 1 vs 2     3 5.375473 0.1462793
> anova(m1, update(m1, scale = ~.-PROD), mN1)
Likelihood ratio tests of cumulative link models

Response: SURENESS
           Model Resid. df -2logLik   Test    Df LR stat.   Pr(Chi)
1    PROD | 1 |       1841 5380.664                                
2 PROD | PROD |       1840 5375.489 1 vs 2     1 5.174937 0.0229150
3    1 |  | PROD      1837 5370.114 2 vs 3     3 5.375473 0.1462793
> 
> ## Fit model from polr example:
> if(require(MASS)) {
+     fm1 <- clm2(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
+     anova(fm1, update(fm1, scale =~ Cont))
+ }
Loading required package: MASS
Likelihood ratio tests of cumulative link models

Response: Sat
                         Model Resid. df -2logLik   Test    Df LR stat.
1     Infl + Type + Cont |  |       1673 3479.149                      
2 Infl + Type + Cont | Cont |       1672 3473.493 1 vs 2     1 5.655882
     Pr(Chi)
1           
2 0.01739692
> 
> 
> 
> 
> base::options(contrasts = c(unordered = "contr.treatment",ordered = "contr.poly"))
> cleanEx()

detaching ‘package:MASS’

> nameEx("clm.fit")
> ### * clm.fit
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: clm.fit
> ### Title: Fit Cumulative Link Models
> ### Aliases: clm.fit clm.fit.default clm.fit.factor
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> ## A simple example:
> fm1 <- clm(rating ~ contact + temp, data=wine)
> summary(fm1)
formula: rating ~ contact + temp
data:    wine

 link  threshold nobs logLik AIC    niter max.grad cond.H 
 logit flexible  72   -86.49 184.98 6(0)  4.01e-12 2.7e+01

Coefficients:
           Estimate Std. Error z value Pr(>|z|)    
contactyes   1.5278     0.4766   3.205  0.00135 ** 
tempwarm     2.5031     0.5287   4.735 2.19e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -1.3444     0.5171  -2.600
2|3   1.2508     0.4379   2.857
3|4   3.4669     0.5978   5.800
4|5   5.0064     0.7309   6.850
> ## get the model frame containing y and X:
> mf1 <- update(fm1, method="design")
> names(mf1)
 [1] "y"         "y.levels"  "X"         "offset"    "terms"     "contrasts"
 [7] "xlevels"   "weights"   "doFit"     "control"   "link"      "threshold"
[13] "start"     "formulas" 
> res <- clm.fit(mf1$y, mf1$X) ## invoking the factor method
> stopifnot(all.equal(coef(res), coef(fm1)))
> names(res)
 [1] "aliased"       "alpha"         "beta"          "coefficients" 
 [5] "cond.H"        "convergence"   "df.residual"   "edf"          
 [9] "fitted.values" "gradient"      "Hessian"       "logLik"       
[13] "maxGradient"   "message"       "n"             "niter"        
[17] "nobs"          "Theta"         "tJac"          "vcov"         
> 
> ## Fitting with the default method:
> mf1$control$method <- "Newton"
> res2 <- clm.fit(mf1)
> stopifnot(all.equal(coef(res2), coef(fm1)))
> 
> 
> 
> 
> cleanEx()
> nameEx("clmOld")
> ### * clmOld
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: clm2
> ### Title: Cumulative link models
> ### Aliases: clm2
> ### Keywords: models
> 
> ### ** Examples
> 
> options(contrasts = c("contr.treatment", "contr.poly"))
> 
> ## A tabular data set:
> (tab26 <- with(soup, table("Product" = PROD, "Response" = SURENESS)))
       Response
Product   1   2   3   4   5   6
   Ref  132 161  65  41 121 219
   Test  96  99  50  57 156 650
> dimnames(tab26)[[2]] <- c("Sure", "Not Sure", "Guess", "Guess", "Not Sure", "Sure")
> dat26 <- expand.grid(sureness = as.factor(1:6), prod = c("Ref", "Test"))
> dat26$wghts <- c(t(tab26))
> 
> m1 <- clm2(sureness ~ prod, scale = ~prod, data = dat26,
+           weights = wghts, link = "logistic")
> 
> ## print, summary, vcov, logLik, AIC:
> m1
Call:
clm2(location = sureness ~ prod, scale = ~prod, data = dat26, 
    weights = wghts, link = "logistic")

Location coefficients:
prodTest 
1.295878 

Scale coefficients:
 prodTest 
0.1479862 

Threshold coefficients:
       1|2        2|3        3|4        4|5        5|6 
-1.4912570 -0.4521846 -0.1072083  0.1633653  0.8829135 

log-likelihood: -2687.745 
AIC: 5389.489 
> summary(m1)
Call:
clm2(location = sureness ~ prod, scale = ~prod, data = dat26, 
    weights = wghts, link = "logistic")

Location coefficients:
         Estimate Std. Error z value  Pr(>|z|)  
prodTest   1.2959   0.1190    10.8868 < 2.22e-16

Scale coefficients:
         Estimate Std. Error z value  Pr(>|z|)
prodTest   0.1480   0.0651     2.2731 0.023022

Threshold coefficients:
    Estimate Std. Error z value 
1|2  -1.4913   0.0922   -16.1828
2|3  -0.4522   0.0718    -6.2957
3|4  -0.1072   0.0700    -1.5326
4|5   0.1634   0.0703     2.3253
5|6   0.8829   0.0796    11.0959

log-likelihood: -2687.745 
AIC: 5389.489 
Condition number of Hessian: 103.9533 
> vcov(m1)
                   1|2           2|3           3|4          4|5         5|6
1|2       0.0084917517  0.0046258794  0.0038492224 0.0033160185 0.002036181
2|3       0.0046258794  0.0051587113  0.0044974254 0.0040993155 0.003352337
3|4       0.0038492224  0.0044974254  0.0048935904 0.0045281974 0.003948063
4|5       0.0033160185  0.0040993155  0.0045281974 0.0049357373 0.004489068
5|6       0.0020361808  0.0033523365  0.0039480627 0.0044890684 0.006331537
prodTest  0.0009111853  0.0031074303  0.0039832978 0.0047389738 0.007064842
prodTest -0.0024312135 -0.0007825925 -0.0001820515 0.0003389771 0.001989992
             prodTest      prodTest
1|2      0.0009111853 -0.0024312135
2|3      0.0031074303 -0.0007825925
3|4      0.0039832978 -0.0001820515
4|5      0.0047389738  0.0003389771
5|6      0.0070648425  0.0019899918
prodTest 0.0141687290  0.0045752937
prodTest 0.0045752937  0.0042385595
> logLik(m1)
'log Lik.' -2687.745 (df=7)
> AIC(m1)
[1] 5389.489
> coef(m1)
       1|2        2|3        3|4        4|5        5|6   prodTest   prodTest 
-1.4912570 -0.4521846 -0.1072083  0.1633653  0.8829135  1.2958776  0.1479862 
> coef(summary(m1))
           Estimate Std. Error    z value     Pr(>|z|)
1|2      -1.4912570 0.09215070 -16.182807 6.668348e-59
2|3      -0.4521846 0.07182417  -6.295717 3.059827e-10
3|4      -0.1072083 0.06995420  -1.532550 1.253867e-01
4|5       0.1633653 0.07025480   2.325325 2.005457e-02
5|6       0.8829135 0.07957095  11.095927 1.312922e-28
prodTest  1.2958776 0.11903247  10.886757 1.333025e-27
prodTest  0.1479862 0.06510422   2.273065 2.302224e-02
> 
> ## link functions:
> m2 <- update(m1, link = "probit")
> m3 <- update(m1, link = "cloglog")
> m4 <- update(m1, link = "loglog")
> m5 <- update(m1, link = "cauchit", start = coef(m1))
> m6 <- update(m1, link = "Aranda-Ordaz", lambda = 1)
> m7 <- update(m1, link = "Aranda-Ordaz")
Changing to nlminb optimizer to accommodate optimization with bounds
Warning: clm2 may not have converged:
  optimizer nlminb terminated with max|gradient|: 0.0021247505225972
> m8 <- update(m1, link = "log-gamma", lambda = 1)
> m9 <- update(m1, link = "log-gamma")
> 
> ## nominal effects:
> mN1 <-  clm2(sureness ~ 1, nominal = ~ prod, data = dat26,
+             weights = wghts, link = "logistic")
> anova(m1, mN1)
Likelihood ratio tests of cumulative link models

Response: sureness
           Model Resid. df -2logLik   Test    Df LR stat.   Pr(Chi)
1 prod | prod |       1840 5375.489                                
2    1 |  | prod      1837 5370.114 1 vs 2     3 5.375473 0.1462793
> 
> ## optimizer / method:
> update(m1, scale = ~ 1, method = "Newton")
Call:
clm2(location = sureness ~ prod, scale = ~1, data = dat26, weights = wghts, 
    link = "logistic", method = "Newton")

Location coefficients:
prodTest 
1.144436 

No Scale coefficients

Threshold coefficients:
       1|2        2|3        3|4        4|5        5|6 
-1.4050044 -0.4247426 -0.1012663  0.1507757  0.8125538 

log-likelihood: -2690.332 
AIC: 5392.664 
> update(m1, scale = ~ 1, method = "nlminb")
Warning: clm2 may not have converged:
  optimizer nlminb terminated with max|gradient|: 0.00149784696151301
Call:
clm2(location = sureness ~ prod, scale = ~1, data = dat26, weights = wghts, 
    link = "logistic", method = "nlminb")

Location coefficients:
prodTest 
1.144437 

No Scale coefficients

Threshold coefficients:
       1|2        2|3        3|4        4|5        5|6 
-1.4050069 -0.4247426 -0.1012651  0.1507768  0.8125536 

log-likelihood: -2690.332 
AIC: 5392.664 
> update(m1, scale = ~ 1, method = "optim")
Warning: clm2 may not have converged:
  optimizer optim terminated with max|gradient|: 0.0027464268894164
Call:
clm2(location = sureness ~ prod, scale = ~1, data = dat26, weights = wghts, 
    link = "logistic", method = "optim")

Location coefficients:
prodTest 
1.144436 

No Scale coefficients

Threshold coefficients:
       1|2        2|3        3|4        4|5        5|6 
-1.4050057 -0.4247413 -0.1012670  0.1507745  0.8125535 

log-likelihood: -2690.332 
AIC: 5392.664 
> ## Don't show: 
> update(m1, scale = ~ 1, method = "model.frame")
$location
   sureness prod (weights)
1         1  Ref       132
2         2  Ref       161
3         3  Ref        65
4         4  Ref        41
5         5  Ref       121
6         6  Ref       219
7         1 Test        96
8         2 Test        99
9         3 Test        50
10        4 Test        57
11        5 Test       156
12        6 Test       650

$scale
   (weights)
1        132
2        161
3         65
4         41
5        121
6        219
7         96
8         99
9         50
10        57
11       156
12       650

> update(m1, location = ~.-prod, scale = ~ 1,
+        nominal = ~ prod, method = "model.frame")
$location
   sureness (weights)
1         1       132
2         2       161
3         3        65
4         4        41
5         5       121
6         6       219
7         1        96
8         2        99
9         3        50
10        4        57
11        5       156
12        6       650

$scale
   (weights)
1        132
2        161
3         65
4         41
5        121
6        219
7         96
8         99
9         50
10        57
11       156
12       650

$nominal
   prod (weights)
1   Ref       132
2   Ref       161
3   Ref        65
4   Ref        41
5   Ref       121
6   Ref       219
7  Test        96
8  Test        99
9  Test        50
10 Test        57
11 Test       156
12 Test       650

> ## End(Don't show)
> 
> ## threshold functions
> mT1 <- update(m1, threshold = "symmetric")
> mT2 <- update(m1, threshold = "equidistant")
> anova(m1, mT1, mT2)
Likelihood ratio tests of cumulative link models

Response: sureness
           Model Resid. df -2logLik   Test    Df LR stat.      Pr(Chi)
1 prod | prod |       1843 5577.566                                   
2 prod | prod |       1842 5397.760 1 vs 2     1 179.8062 0.000000e+00
3 prod | prod |       1840 5375.489 2 vs 3     2  22.2708 1.458668e-05
> 
> ## Extend example from polr in package MASS:
> ## Fit model from polr example:
> if(require(MASS)) {
+     fm1 <- clm2(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
+     fm1
+     summary(fm1)
+     ## With probit link:
+     summary(update(fm1, link = "probit"))
+     ## Allow scale to depend on Cont-variable
+     summary(fm2 <- update(fm1, scale =~ Cont))
+     anova(fm1, fm2)
+     ## which seems to improve the fit
+ }
Loading required package: MASS
Likelihood ratio tests of cumulative link models

Response: Sat
                         Model Resid. df -2logLik   Test    Df LR stat.
1     Infl + Type + Cont |  |       1673 3479.149                      
2 Infl + Type + Cont | Cont |       1672 3473.493 1 vs 2     1 5.655882
     Pr(Chi)
1           
2 0.01739692
> 
> #################################
> ## It is possible to fit multinomial models (i.e. with nominal
> ## effects) as the following example shows:
> if(require(nnet)) {
+     (hous1.mu <- multinom(Sat ~ 1, weights = Freq, data = housing))
+     (hous1.clm <- clm2(Sat ~ 1, weights = Freq, data = housing))
+ 
+     ## It is the same likelihood:
+     all.equal(logLik(hous1.mu), logLik(hous1.clm))
+ 
+     ## and the same fitted values:
+     fitHous.mu <-
+         t(fitted(hous1.mu))[t(col(fitted(hous1.mu)) == unclass(housing$Sat))]
+     all.equal(fitted(hous1.clm), fitHous.mu)
+ 
+     ## The coefficients of multinom can be retrieved from the clm2-object
+     ## by:
+     Pi <- diff(c(0, plogis(hous1.clm$xi), 1))
+     log(Pi[2:3]/Pi[1])
+ 
+     ## A larger model with explanatory variables:
+     (hous.mu <- multinom(Sat ~ Infl + Type + Cont, weights = Freq, data = housing))
+     (hous.clm <- clm2(Sat ~ 1, nominal = ~ Infl + Type + Cont, weights = Freq,
+                       data = housing))
+ 
+     ## Almost the same likelihood:
+     all.equal(logLik(hous.mu), logLik(hous.clm))
+ 
+     ## And almost the same fitted values:
+     fitHous.mu <-
+         t(fitted(hous.mu))[t(col(fitted(hous.mu)) == unclass(housing$Sat))]
+     all.equal(fitted(hous.clm), fitHous.mu)
+     all.equal(round(fitted(hous.clm), 5), round(fitHous.mu), 5)
+ }
Loading required package: nnet
# weights:  6 (2 variable)
initial  value 1846.767257 
final  value 1824.438811 
converged
# weights:  24 (14 variable)
initial  value 1846.767257 
iter  10 value 1747.045232
final  value 1735.041933 
converged
[1] TRUE
> 
> 
> 
> 
> base::options(contrasts = c(unordered = "contr.treatment",ordered = "contr.poly"))
> cleanEx()

detaching ‘package:nnet’, ‘package:MASS’

> nameEx("clmm")
> ### * clmm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: clmm
> ### Title: Cumulative Link Mixed Models
> ### Aliases: clmm
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> ## Cumulative link model with one random term:	
> fmm1 <- clmm(rating ~ temp + contact + (1|judge), data = wine)	
> summary(fmm1)	
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: rating ~ temp + contact + (1 | judge)
data:    wine

 link  threshold nobs logLik AIC    niter    max.grad cond.H 
 logit flexible  72   -81.57 177.13 332(999) 1.03e-05 2.8e+01

Random effects:
 Groups Name        Variance Std.Dev.
 judge  (Intercept) 1.279    1.131   
Number of groups:  judge 9 

Coefficients:
           Estimate Std. Error z value Pr(>|z|)    
tempwarm     3.0630     0.5954   5.145 2.68e-07 ***
contactyes   1.8349     0.5125   3.580 0.000344 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -1.6237     0.6824  -2.379
2|3   1.5134     0.6038   2.507
3|4   4.2285     0.8090   5.227
4|5   6.0888     0.9725   6.261
> 	
> ## Not run: 
> ##D  	
> ##D ## May take a couple of seconds to run this.	
> ##D 
> ##D ## Cumulative link mixed model with two random terms:
> ##D mm1 <- clmm(SURENESS ~ PROD + (1|RESP) + (1|RESP:PROD), data = soup,
> ##D             link = "probit", threshold = "equidistant")
> ##D mm1
> ##D summary(mm1)
> ##D 
> ##D ## test random effect:
> ##D mm2 <- clmm(SURENESS ~ PROD + (1|RESP), data = soup,
> ##D             link = "probit", threshold = "equidistant")
> ##D anova(mm1, mm2)
> ## End(Not run)
> 
> 
> 
> 
> cleanEx()
> nameEx("clmmOld")
> ### * clmmOld
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: clmm2
> ### Title: Cumulative link mixed models
> ### Aliases: clmm2
> ### Keywords: models
> 
> ### ** Examples
> 
> options(contrasts = c("contr.treatment", "contr.poly"))
> 
> ## More manageable data set:
> dat <- subset(soup, as.numeric(as.character(RESP)) <=  24)
> dat$RESP <- dat$RESP[drop=TRUE]
> 
> m1 <- clmm2(SURENESS ~ PROD, random = RESP, data = dat, link="probit",
+            Hess = TRUE, method="ucminf", threshold = "symmetric")
> 
> m1
Cumulative Link Mixed Model fitted with the Laplace approximation

Call:
clmm2(location = SURENESS ~ PROD, random = RESP, data = dat, 
    Hess = TRUE, link = "probit", threshold = "symmetric", method = "ucminf")

Random effects:
            Var   Std.Dev
RESP 0.05947608 0.2438772

Location coefficients:
PRODTest 
1.090036 

No Scale coefficients

Threshold coefficients:
   central  spacing.1  spacing.2 
0.03098243 0.21461394 0.74509589 

Thresholds:
        1|2         2|3         3|4         4|5         5|6 
-0.71411346 -0.18363151  0.03098243  0.24559636  0.77607832 

log-likelihood: -283.6719 
AIC: 577.3439 
> summary(m1)
Cumulative Link Mixed Model fitted with the Laplace approximation

Call:
clmm2(location = SURENESS ~ PROD, random = RESP, data = dat, 
    Hess = TRUE, link = "probit", threshold = "symmetric", method = "ucminf")

Random effects:
            Var   Std.Dev
RESP 0.05947608 0.2438772

Location coefficients:
         Estimate Std. Error z value Pr(>|z|)  
PRODTest  1.0900   0.1678     6.4953 8.2861e-11

No scale coefficients

Threshold coefficients:
          Estimate Std. Error z value
central    0.0310   0.1302     0.2380
spacing.1  0.2146   0.0392     5.4682
spacing.2  0.7451   0.0681    10.9440

log-likelihood: -283.6719 
AIC: 577.3439 
Condition number of Hessian: 239.9357 
> logLik(m1)
'log Lik.' -283.6719 (df=5)
> vcov(m1)
                central    spacing.1    spacing.2     PRODTest              
central    0.0169459607 0.0001516004 0.0002206376 0.0140586802 -0.0005642257
spacing.1  0.0001516004 0.0015403683 0.0011567085 0.0008520672  0.0016377633
spacing.2  0.0002206376 0.0011567085 0.0046352066 0.0028731446  0.0068104952
PRODTest   0.0140586802 0.0008520672 0.0028731446 0.0281631554  0.0139822786
          -0.0005642257 0.0016377633 0.0068104952 0.0139822786  0.2755482741
> extractAIC(m1)
[1]   5.0000 577.3439
> anova(m1, update(m1, location = SURENESS ~ 1, Hess = FALSE))
Likelihood ratio tests of cumulative link models

Response: SURENESS
       Model Resid. df -2logLik   Test    Df LR stat.      Pr(Chi)
1    1 |  |        196 610.4108                                   
2 PROD |  |        195 567.3439 1 vs 2     1 43.06696 5.289791e-11
> anova(m1, update(m1, random = NULL))
Likelihood ratio tests of cumulative link models

Response: SURENESS
       Model Resid. df -2logLik   Test    Df LR stat.   Pr(Chi)
1 PROD |  |        196 568.8292                                
2 PROD |  |        195 567.3439 1 vs 2     1 1.485361 0.2229376
> 
> ## Use adaptive Gauss-Hermite quadrature rather than the Laplace
> ## approximation:
> update(m1, Hess = FALSE, nAGQ = 3)
Cumulative Link Mixed Model fitted with the adaptive Gauss-Hermite 
quadrature approximation with 3 quadrature points 

Call:
clmm2(location = SURENESS ~ PROD, random = RESP, data = dat, 
    Hess = FALSE, link = "probit", nAGQ = 3, threshold = "symmetric", 
    method = "ucminf")

Random effects:
            Var  Std.Dev
RESP 0.05975237 0.244443

Location coefficients:
PRODTest 
1.090143 

No Scale coefficients

Threshold coefficients:
   central  spacing.1  spacing.2 
0.03098245 0.21462764 0.74515323 

Thresholds:
        1|2         2|3         3|4         4|5         5|6 
-0.71417078 -0.18364519  0.03098245  0.24561010  0.77613568 

log-likelihood: -283.6692 
AIC: 577.3384 
> 
> ## Use standard Gauss-Hermite quadrature:
> update(m1, Hess = FALSE, nAGQ = -7)
Cumulative Link Mixed Model fitted with the Gauss-Hermite 
quadrature approximation with 7 quadrature points 

Call:
clmm2(location = SURENESS ~ PROD, random = RESP, data = dat, 
    Hess = FALSE, link = "probit", nAGQ = -7, threshold = "symmetric", 
    method = "ucminf")

Random effects:
            Var  Std.Dev
RESP 0.06023489 0.245428

Location coefficients:
PRODTest 
1.090219 

No Scale coefficients

Threshold coefficients:
   central  spacing.1  spacing.2 
0.03113549 0.21462614 0.74516194 

Thresholds:
        1|2         2|3         3|4         4|5         5|6 
-0.71402645 -0.18349065  0.03113549  0.24576163  0.77629743 

log-likelihood: -283.6759 
AIC: 577.3517 
> 
> ##################################################################
> ## Binomial example with the cbpp data from the lme4-package:
> if(require(lme4)) {
+     cbpp2 <- rbind(cbpp[,-(2:3)], cbpp[,-(2:3)])
+     cbpp2 <- within(cbpp2, {
+         incidence <- as.factor(rep(0:1, each=nrow(cbpp)))
+         freq <- with(cbpp, c(incidence, size - incidence))
+     })
+ 
+     ## Fit with Laplace approximation:
+     fm1 <- clmm2(incidence ~ period, random = herd, weights = freq,
+                  data = cbpp2, Hess = 1)
+     summary(fm1)
+ 
+     ## Fit with the adaptive Gauss-Hermite quadrature approximation:
+     fm2 <- clmm2(incidence ~ period, random = herd, weights = freq,
+                  data = cbpp2, Hess = 1, nAGQ = 7)
+     summary(fm2)
+ }
Loading required package: lme4
Loading required package: Matrix
Cumulative Link Mixed Model fitted with the adaptive Gauss-Hermite 
quadrature approximation with 7 quadrature points

Call:
clmm2(location = incidence ~ period, random = herd, data = cbpp2, 
    weights = freq, Hess = 1, nAGQ = 7)

Random effects:
           Var   Std.Dev
herd 0.4192826 0.6475204

Location coefficients:
        Estimate Std. Error z value Pr(>|z|)  
period2  0.9914   0.3068     3.2318 0.00123027
period3  1.1278   0.3268     3.4514 0.00055763
period4  1.5795   0.4276     3.6938 0.00022089

No scale coefficients

Threshold coefficients:
    Estimate Std. Error z value
0|1 -1.3992   0.2335    -5.9921

log-likelihood: -277.459 
AIC: 564.918 
Condition number of Hessian: 5.69815 
> 
> 
> 
> 
> base::options(contrasts = c(unordered = "contr.treatment",ordered = "contr.poly"))
> cleanEx()

detaching ‘package:lme4’, ‘package:Matrix’

> nameEx("confint.clm")
> ### * confint.clm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: confint
> ### Title: Confidence intervals and profile likelihoods for parameters in
> ###   cumulative link models
> ### Aliases: confint.clm confint.profile.clm profile.clm plot.profile.clm
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> ## Accurate profile likelihood confidence intervals compared to the
> ## conventional Wald intervals:
> fm1 <- clm(rating ~ temp * contact, data = wine)
> confint(fm1) ## type = "profile"
                          2.5 %   97.5 %
tempwarm             0.99435182 3.761793
contactyes           0.08378091 2.694828
tempwarm:contactyes -1.45985126 2.180286
> confint(fm1, type = "Wald")
                          2.5 %     97.5 %
1|2                 -2.48013466 -0.3423893
2|3                  0.14464718  2.1424601
3|4                  2.12630850  4.6278565
4|5                  3.47022323  6.4137413
tempwarm             0.94735154  3.6950170
contactyes           0.05318714  2.6417337
tempwarm:contactyes -1.45110279  2.1702006
> pr1 <- profile(fm1)
> confint(pr1)
                          2.5 %   97.5 %
tempwarm             0.99438454 3.761828
contactyes           0.08379044 2.694864
tempwarm:contactyes -1.45984555 2.180280
> 
> ## plotting the profiles:
> par(mfrow = c(2, 2))
> plot(pr1, root = TRUE) ## check for linearity
> par(mfrow = c(2, 2))
> plot(pr1)
> par(mfrow = c(2, 2))
> plot(pr1, approx = TRUE)
> par(mfrow = c(2, 2))
> plot(pr1, Log = TRUE)
> par(mfrow = c(2, 2))
> plot(pr1, Log = TRUE, relative = FALSE)
> ## Not likely to be useful but allowed for completeness:
> par(mfrow = c(2, 2))
> plot(pr1, Log = FALSE, relative = FALSE)
> 
> ## Example from polr in package MASS:
> ## Fit model from polr example:
> if(require(MASS)) {
+     fm1 <- clm(Sat ~ Infl + Type + Cont, weights = Freq,
+                data = housing)
+     pr1 <- profile(fm1)
+     confint(pr1)
+     par(mfrow=c(2,2))
+     plot(pr1)
+ }
Loading required package: MASS
> 
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()

detaching ‘package:MASS’

> nameEx("confint.clmmOld")
> ### * confint.clmmOld
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: profile.clmm2
> ### Title: Confidence intervals and profile likelihoods for the standard
> ###   deviation for the random term in cumulative link mixed models
> ### Aliases: profile.clmm2 confint.clmm2 confint.profile.clmm2
> ###   profile.clmm2 plot.profile.clmm2
> ### Keywords: models
> 
> ### ** Examples
> 
> options(contrasts = c("contr.treatment", "contr.poly"))
> 
> if(require(lme4)) { ## access cbpp data
+     cbpp2 <- rbind(cbpp[,-(2:3)], cbpp[,-(2:3)])
+     cbpp2 <- within(cbpp2, {
+         incidence <- as.factor(rep(0:1, each=nrow(cbpp)))
+         freq <- with(cbpp, c(incidence, size - incidence))
+     })
+ 
+     ## Fit with Laplace approximation:
+     fm1 <- clmm2(incidence ~ period, random = herd, weights = freq,
+                  data = cbpp2, Hess = 1)
+ 
+     pr.fm1 <- profile(fm1)
+     confint(pr.fm1)
+ 
+     par(mfrow = c(2,2))
+     plot(pr.fm1)
+     plot(pr.fm1, Log=TRUE, relative = TRUE)
+     plot(pr.fm1, Log=TRUE, relative = FALSE)
+ }
Loading required package: lme4
Loading required package: Matrix
Now profiling stDev with 20 steps: i =
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 
> 
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> base::options(contrasts = c(unordered = "contr.treatment",ordered = "contr.poly"))
> cleanEx()

detaching ‘package:lme4’, ‘package:Matrix’

> nameEx("confintOld")
> ### * confintOld
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: confint.clm2
> ### Title: Confidence intervals and profile likelihoods for parameters in
> ###   cumulative link models
> ### Aliases: confint.clm2 confint.profile.clm2 profile.clm2
> ###   plot.profile.clm2
> ### Keywords: internal
> 
> ### ** Examples
> 
> options(contrasts = c("contr.treatment", "contr.poly"))
> 
> ## More manageable data set:
> (tab26 <- with(soup, table("Product" = PROD, "Response" = SURENESS)))
       Response
Product   1   2   3   4   5   6
   Ref  132 161  65  41 121 219
   Test  96  99  50  57 156 650
> dimnames(tab26)[[2]] <- c("Sure", "Not Sure", "Guess", "Guess", "Not Sure", "Sure")
> dat26 <- expand.grid(sureness = as.factor(1:6), prod = c("Ref", "Test"))
> dat26$wghts <- c(t(tab26))
> 
> m1 <- clm2(sureness ~ prod, scale = ~prod, data = dat26,
+           weights = wghts, link = "logistic")
> 
> ## profile
> pr1 <- profile(m1)
> par(mfrow = c(2, 2))
> plot(pr1)
> 
> m9 <- update(m1, link = "log-gamma")
> pr9 <- profile(m9, whichL = numeric(0), whichS = numeric(0))
> par(mfrow = c(1, 1))
> plot(pr9)
> 
> plot(pr9, Log=TRUE, relative = TRUE)
> plot(pr9, Log=TRUE, relative = TRUE, ylim = c(-4, 0))
> plot(pr9, Log=TRUE, relative = FALSE)
> 
> ## confint
> confint(pr9)
       2.5 %    97.5 %
lambda    NA 0.5410888
> confint(pr1)
                    2.5 %    97.5 %
loc.prodTest   1.07071825 1.5385701
scale.prodTest 0.02048196 0.2758304
> 
> ## Extend example from polr in package MASS:
> ## Fit model from polr example:
> if(require(MASS)) {
+     fm1 <- clm2(Sat ~ Infl + Type + Cont, scale = ~ Cont, weights = Freq,
+                 data = housing)
+     pr1 <- profile(fm1)
+     confint(pr1)
+     par(mfrow=c(2,2))
+     plot(pr1)
+ }
Loading required package: MASS
> 
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> base::options(contrasts = c(unordered = "contr.treatment",ordered = "contr.poly"))
> cleanEx()

detaching ‘package:MASS’

> nameEx("convergence.clm")
> ### * convergence.clm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: convergence
> ### Title: Check convergence of cumulative link models
> ### Aliases: convergence convergence.clm print.convergence.clm
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> ## Simple model:
> fm1 <- clm(rating ~ contact + temp, data=wine)
> summary(fm1)
formula: rating ~ contact + temp
data:    wine

 link  threshold nobs logLik AIC    niter max.grad cond.H 
 logit flexible  72   -86.49 184.98 6(0)  4.01e-12 2.7e+01

Coefficients:
           Estimate Std. Error z value Pr(>|z|)    
contactyes   1.5278     0.4766   3.205  0.00135 ** 
tempwarm     2.5031     0.5287   4.735 2.19e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -1.3444     0.5171  -2.600
2|3   1.2508     0.4379   2.857
3|4   3.4669     0.5978   5.800
4|5   5.0064     0.7309   6.850
> convergence(fm1)
 nobs logLik niter max.grad cond.H  logLik.Error
 72   -86.49 6(0)  4.01e-12 2.7e+01 <1e-10      

           Estimate Std.Err  Gradient     Error Cor.Dec Sig.Dig
1|2          -1.344  0.5171  2.06e-12  3.09e-13      12      13
2|3           1.251  0.4379  2.12e-12 -2.42e-13      12      13
3|4           3.467  0.5978 -4.01e-12 -9.31e-13      11      12
4|5           5.006  0.7309 -7.46e-14 -9.20e-13      11      12
contactyes    1.528  0.4766  5.86e-14 -2.95e-13      12      13
tempwarm      2.503  0.5287 -4.52e-13 -6.32e-13      11      12

Eigen values of Hessian:
21.7090 18.5615 10.3914  5.2093  4.0955  0.8163 

Convergence message from clm:
(0) successful convergence 
In addition: Absolute and relative convergence criteria were met 

> 
> 
> 
> 
> cleanEx()
> nameEx("dropCoef")
> ### * dropCoef
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: drop.coef
> ### Title: Ensure Full Rank Design Matrix
> ### Aliases: drop.coef
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> X <- model.matrix( ~ PRODID * DAY, data = soup)
> ncol(X)
[1] 12
> newX <- drop.coef(X)
design is column rank deficient so dropping 1 coef
> ncol(newX)
[1] 11
> 
> ## Essentially this is being computed:
> qr.X <- qr(X, tol = 1e-7, LAPACK = FALSE)
> newX <- X[, qr.X$pivot[1:qr.X$rank], drop = FALSE]
> ## is newX of full column rank?
> ncol(newX) == qr(newX)$rank
[1] TRUE
> ## the number of columns being dropped:
> ncol(X) - ncol(newX)
[1] 1
> 
> 
> 
> 
> cleanEx()
> nameEx("gfun")
> ### * gfun
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: gfun
> ### Title: Gradients of common densities
> ### Aliases: gnorm glogis gcauchy
> ### Keywords: distribution
> 
> ### ** Examples
> 
> 
> x <- -5:5
> gnorm(x)
 [1]  7.433598e-06  5.353209e-04  1.329555e-02  1.079819e-01  2.419707e-01
 [6]  0.000000e+00 -2.419707e-01 -1.079819e-01 -1.329555e-02 -5.353209e-04
[11] -7.433598e-06
> glogis(x)
 [1]  0.006559068  0.017027336  0.040891575  0.079962501  0.090857748
 [6]  0.000000000 -0.090857748 -0.079962501 -0.040891575 -0.017027336
[11] -0.006559068
> gcauchy(x)
 [1]  0.004708726  0.008811346  0.019098593  0.050929582  0.159154943
 [6]  0.000000000 -0.159154943 -0.050929582 -0.019098593 -0.008811346
[11] -0.004708726
> 
> 
> 
> 
> cleanEx()
> nameEx("gumbel")
> ### * gumbel
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: gumbel
> ### Title: The Gumbel Distribution
> ### Aliases: dgumbel pgumbel qgumbel rgumbel ggumbel
> ### Keywords: distribution
> 
> ### ** Examples
> 
> 
> ## Illustrating the symmetry of the distribution functions:
> pgumbel(5) == 1 - pgumbel(-5, max=FALSE) ## TRUE
[1] TRUE
> dgumbel(5) == dgumbel(-5, max=FALSE) ## TRUE
[1] TRUE
> ggumbel(5) == -ggumbel(-5, max=FALSE) ## TRUE
[1] TRUE
> 
> ## More examples:
> x <- -5:5
> 
> (pp <- pgumbel(x))
 [1] 3.507389e-65 1.942338e-24 1.892179e-09 6.179790e-04 6.598804e-02
 [6] 3.678794e-01 6.922006e-01 8.734230e-01 9.514320e-01 9.818511e-01
[11] 9.932847e-01
> qgumbel(pp)
 [1] -5 -4 -3 -2 -1  0  1  2  3  4  5
> dgumbel(x)
 [1] 5.205427e-63 1.060480e-22 3.800543e-08 4.566281e-03 1.793741e-01
 [6] 3.678794e-01 2.546464e-01 1.182050e-01 4.736901e-02 1.798323e-02
[11] 6.692700e-03
> ggumbel(x)
 [1]  7.673485e-61  5.683979e-21  7.253539e-07  2.917423e-02  3.082152e-01
 [6]  0.000000e+00 -1.609672e-01 -1.022077e-01 -4.501065e-02 -1.765386e-02
[11] -6.647605e-03
> 
> (ppp <- pgumbel(x, max=FALSE))
 [1] 0.006715298 0.018148927 0.048568007 0.126576982 0.307799372 0.632120559
 [7] 0.934011964 0.999382021 0.999999998 1.000000000 1.000000000
> ## Observe that probabilities close to 0 are more accurately determined than 
> ## probabilities close to 1:
> qgumbel(ppp, max=FALSE)
 [1]  -5  -4  -3  -2  -1   0   1   2   3 Inf Inf
> dgumbel(x, max=FALSE)
 [1] 6.692700e-03 1.798323e-02 4.736901e-02 1.182050e-01 2.546464e-01
 [6] 3.678794e-01 1.793741e-01 4.566281e-03 3.800543e-08 1.060480e-22
[11] 5.205427e-63
> ggumbel(x, max=FALSE)
 [1]  6.647605e-03  1.765386e-02  4.501065e-02  1.022077e-01  1.609672e-01
 [6]  0.000000e+00 -3.082152e-01 -2.917423e-02 -7.253539e-07 -5.683979e-21
[11] -7.673485e-61
> 
> ## random deviates:
> set.seed(1)
> (r1 <- rgumbel(10))
 [1] -0.28224819  0.01153789  0.58496474  2.34047303 -0.47066805  2.23351289
 [7]  2.86621319  0.88114707  0.76907246 -1.02391536
> set.seed(1)
> r2 <- -rgumbel(10, max = FALSE)
> all(r1 == r2) ## TRUE
[1] TRUE
> 
> 
> 
> 
> cleanEx()
> nameEx("income")
> ### * income
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: income
> ### Title: Income distribution (percentages) in the Northeast US
> ### Aliases: income
> ### Keywords: datasets
> 
> ### ** Examples
> 
> 
> print(income)
   year  pct income
1  1960  6.5    0-3
2  1960  8.2    3-5
3  1960 11.3    5-7
4  1960 23.5   7-10
5  1960 15.6  10-12
6  1960 12.7  12-15
7  1960 22.2    15+
8  1970  4.3    0-3
9  1970  6.0    3-5
10 1970  7.7    5-7
11 1970 13.2   7-10
12 1970 10.5  10-12
13 1970 16.3  12-15
14 1970 42.1    15+
> 
> ## Convenient table:
> (tab <- xtabs(pct ~ year + income, income))
      income
year    0-3  3-5  5-7 7-10 10-12 12-15  15+
  1960  6.5  8.2 11.3 23.5  15.6  12.7 22.2
  1970  4.3  6.0  7.7 13.2  10.5  16.3 42.1
> 
> ## small rounding error in 1970:
> rowSums(tab)
 1960  1970 
100.0 100.1 
> 
> ## compare link functions via the log-likelihood:
> links <- c("logit", "probit", "cloglog", "loglog", "cauchit")
> sapply(links, function(link) {
+   clm(income ~ year, data=income, weights=pct, link=link)$logLik })
    logit    probit   cloglog    loglog   cauchit 
-353.3589 -353.8036 -352.8980 -355.6028 -352.8434 
> ## a heavy tailed (cauchy) or left skew (cloglog) latent distribution
> ## is fitting best.
> 
> ## The data are defined as:
> income.levels <- c(0, 3, 5, 7, 10, 12, 15)
> income <- paste(income.levels, c(rep("-", 6), "+"),
+                 c(income.levels[-1], ""), sep = "")
> income <-
+   data.frame(year=factor(rep(c("1960", "1970"), each = 7)),
+              pct = c(6.5, 8.2, 11.3, 23.5, 15.6, 12.7, 22.2,
+                4.3, 6, 7.7, 13.2, 10.5, 16.3, 42.1),
+              income=factor(rep(income, 2), ordered=TRUE,
+                levels=income))
> 
> 
> 
> 
> cleanEx()
> nameEx("lgamma")
> ### * lgamma
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lgamma
> ### Title: The log-gamma distribution
> ### Aliases: plgamma dlgamma glgamma
> ### Keywords: distribution
> 
> ### ** Examples
> 
> 
> ## Illustrating the link to other distribution functions: 
> x <- -5:5
> plgamma(x, lambda = 0) == pnorm(x)
 [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
> all.equal(plgamma(x, lambda = -1), pgumbel(x)) ## TRUE, but:
[1] TRUE
> plgamma(x, lambda = -1) == pgumbel(x)
 [1] FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE
> plgamma(x, lambda = 1) == pgumbel(x, max = FALSE)
 [1] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
> 
> dlgamma(x, lambda = 0) == dnorm(x)
 [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
> dlgamma(x, lambda = -1) == dgumbel(x)
 [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
> dlgamma(x, lambda = 1) == dgumbel(x, max = FALSE)
 [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
> 
> glgamma(x, lambda = 0) == gnorm(x)
 [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
> all.equal(glgamma(x, lambda = -1), ggumbel(x)) ## TRUE, but:
[1] TRUE
> glgamma(x, lambda = -1) == ggumbel(x)
 [1]  TRUE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE  TRUE FALSE
> all.equal(glgamma(x, lambda = 1), ggumbel(x, max = FALSE)) ## TRUE, but:
[1] TRUE
> glgamma(x, lambda = 1) == ggumbel(x, max = FALSE)
 [1] FALSE  TRUE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE  TRUE
> ## There is a loss of accuracy, but the difference is very small: 
> glgamma(x, lambda = 1) - ggumbel(x, max = FALSE)
 [1] -8.673617e-19  0.000000e+00 -1.387779e-17 -1.387779e-17 -2.775558e-17
 [6]  0.000000e+00  0.000000e+00  0.000000e+00  1.058791e-22 -7.523164e-37
[11]  0.000000e+00
> 
> ## More examples:
> x <- -5:5
> plgamma(x, lambda = .5)
 [1] 0.0003729435 0.0023299245 0.0130924716 0.0621186950 0.2267546348
 [6] 0.5665298796 0.8945151191 0.9945917346 0.9999813218 0.9999999993
[11] 1.0000000000
> dlgamma(x, lambda = .5)
 [1] 6.974573e-04 4.164869e-03 2.166083e-02 8.970337e-02 2.551632e-01
 [6] 3.907336e-01 2.155388e-01 2.208500e-02 1.410374e-04 9.274904e-09
[11] 3.227334e-16
> glgamma(x, lambda = .5)
 [1]  1.280413e-03  7.202431e-03  3.365529e-02  1.134067e-01  2.007978e-01
 [6]  0.000000e+00 -2.796492e-01 -7.589652e-02 -9.820967e-04 -1.185158e-07
[11] -7.217929e-15
> 
> 
> 
> 
> cleanEx()
> nameEx("nominal.test")
> ### * nominal.test
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: nominal_test
> ### Title: Likelihood ratio tests of model terms in scale and nominal
> ###   formulae
> ### Aliases: nominal_test scale_test nominal_test.clm scale_test.clm
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> ## Fit cumulative link model:
> fm <- clm(rating ~ temp + contact, data=wine)
> summary(fm)
formula: rating ~ temp + contact
data:    wine

 link  threshold nobs logLik AIC    niter max.grad cond.H 
 logit flexible  72   -86.49 184.98 6(0)  4.01e-12 2.7e+01

Coefficients:
           Estimate Std. Error z value Pr(>|z|)    
tempwarm     2.5031     0.5287   4.735 2.19e-06 ***
contactyes   1.5278     0.4766   3.205  0.00135 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -1.3444     0.5171  -2.600
2|3   1.2508     0.4379   2.857
3|4   3.4669     0.5978   5.800
4|5   5.0064     0.7309   6.850
> ## test partial proportional odds assumption for temp and contact:
> nominal_test(fm)
Tests of nominal effects

formula: rating ~ temp + contact
        Df  logLik    AIC    LRT Pr(>Chi)
<none>     -86.492 184.98                
temp     3 -84.904 187.81 3.1750   0.3654
contact  3 -86.209 190.42 0.5667   0.9040
> ## no evidence of non-proportional odds.
> ## test if there are signs of scale effects:
> scale_test(fm)
Tests of scale effects

formula: rating ~ temp + contact
        Df  logLik    AIC     LRT Pr(>Chi)
<none>     -86.492 184.98                 
temp     1 -86.439 186.88 0.10492   0.7460
contact  1 -86.355 186.71 0.27330   0.6011
> ## no evidence of scale effects.
> 
> ## tests of scale and nominal effects for the housing data from MASS:
> if(require(MASS)) {
+     fm1 <- clm(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
+     scale_test(fm1)
+     nominal_test(fm1)
+     ## Evidence of multiplicative/scale effect of 'Cont'. This is a breach
+     ## of the proportional odds assumption.
+ }
Loading required package: MASS
Tests of nominal effects

formula: Sat ~ Infl + Type + Cont
       Df  logLik    AIC    LRT Pr(>Chi)
<none>    -1739.6 3495.1                
Infl    2 -1739.0 3498.0 1.1065   0.5751
Type    3 -1736.7 3495.4 5.7337   0.1253
Cont    1 -1738.3 3494.7 2.4446   0.1179
> 
> 
> 
> 
> cleanEx()

detaching ‘package:MASS’

> nameEx("ordinal-package")
> ### * ordinal-package
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: ordinal-package
> ### Title: Regression Models for Ordinal Data via Cumulative Link (Mixed)
> ###   Models
> ### Aliases: ordinal-package ordinal
> ### Keywords: package
> 
> ### ** Examples
> 
> 
> ## A simple cumulative link model:
> fm1 <- clm(rating ~ contact + temp, data=wine)
> summary(fm1)
formula: rating ~ contact + temp
data:    wine

 link  threshold nobs logLik AIC    niter max.grad cond.H 
 logit flexible  72   -86.49 184.98 6(0)  4.01e-12 2.7e+01

Coefficients:
           Estimate Std. Error z value Pr(>|z|)    
contactyes   1.5278     0.4766   3.205  0.00135 ** 
tempwarm     2.5031     0.5287   4.735 2.19e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -1.3444     0.5171  -2.600
2|3   1.2508     0.4379   2.857
3|4   3.4669     0.5978   5.800
4|5   5.0064     0.7309   6.850
> 
> ## A simple cumulative link mixed model:
> fmm1 <- clmm(rating ~ contact + temp + (1|judge), data=wine)
> summary(fmm1)
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: rating ~ contact + temp + (1 | judge)
data:    wine

 link  threshold nobs logLik AIC    niter    max.grad cond.H 
 logit flexible  72   -81.57 177.13 332(999) 1.02e-05 2.8e+01

Random effects:
 Groups Name        Variance Std.Dev.
 judge  (Intercept) 1.279    1.131   
Number of groups:  judge 9 

Coefficients:
           Estimate Std. Error z value Pr(>|z|)    
contactyes   1.8349     0.5125   3.580 0.000344 ***
tempwarm     3.0630     0.5954   5.145 2.68e-07 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -1.6237     0.6824  -2.379
2|3   1.5134     0.6038   2.507
3|4   4.2285     0.8090   5.227
4|5   6.0888     0.9725   6.261
> 
> 
> 
> 
> cleanEx()
> nameEx("predict")
> ### * predict
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: predict.clm
> ### Title: Predict Method for CLM fits
> ### Aliases: predict.clm
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> ## simple model:
> fm1 <- clm(rating ~ contact + temp, data=wine)
> summary(fm1)
formula: rating ~ contact + temp
data:    wine

 link  threshold nobs logLik AIC    niter max.grad cond.H 
 logit flexible  72   -86.49 184.98 6(0)  4.01e-12 2.7e+01

Coefficients:
           Estimate Std. Error z value Pr(>|z|)    
contactyes   1.5278     0.4766   3.205  0.00135 ** 
tempwarm     2.5031     0.5287   4.735 2.19e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -1.3444     0.5171  -2.600
2|3   1.2508     0.4379   2.857
3|4   3.4669     0.5978   5.800
4|5   5.0064     0.7309   6.850
> 
> ## Fitted values with standard errors and confidence intervals:
> predict(fm1, se.fit=TRUE, interval=TRUE) # type="prob"
$fit
 [1] 0.57064970 0.19229094 0.44305990 0.09582084 0.20049402 0.20049402
 [7] 0.27378469 0.27378469 0.20679013 0.57064970 0.05354601 0.44305990
[13] 0.20141572 0.50157554 0.27378469 0.36359581 0.57064970 0.19229094
[19] 0.44305990 0.37764614 0.07562701 0.07562701 0.36359581 0.36359581
[25] 0.19229094 0.57064970 0.44305990 0.37764614 0.50157554 0.20141572
[31] 0.27378469 0.30420994 0.57064970 0.19229094 0.09582084 0.44305990
[37] 0.50157554 0.50157554 0.30420994 0.30420994 0.19229094 0.57064970
[43] 0.44305990 0.37764614 0.20141572 0.20049402 0.27378469 0.36359581
[49] 0.20679013 0.20679013 0.37764614 0.37764614 0.20141572 0.50157554
[55] 0.05380128 0.30420994 0.57064970 0.57064970 0.37764614 0.44305990
[61] 0.50157554 0.50157554 0.30420994 0.36359581 0.20679013 0.57064970
[67] 0.44305990 0.37764614 0.50157554 0.20141572 0.36359581 0.36359581

$se.fit
 [1] 0.08683884 0.06388672 0.07939754 0.04257593 0.06761012 0.06761012
 [7] 0.09132786 0.09132786 0.08481920 0.08683884 0.02976295 0.07939754
[13] 0.07233205 0.07498381 0.09132786 0.08671574 0.08683884 0.06388672
[19] 0.07939754 0.08851418 0.03777829 0.03777829 0.08671574 0.08671574
[25] 0.06388672 0.08683884 0.07939754 0.08851418 0.07498381 0.07233205
[31] 0.09132786 0.07805942 0.08683884 0.06388672 0.04257593 0.07939754
[37] 0.07498381 0.07498381 0.07805942 0.07805942 0.06388672 0.08683884
[43] 0.07939754 0.08851418 0.07233205 0.06761012 0.09132786 0.08671574
[49] 0.08481920 0.08481920 0.08851418 0.08851418 0.07233205 0.07498381
[55] 0.02668355 0.07805942 0.08683884 0.08683884 0.08851418 0.07939754
[61] 0.07498381 0.07498381 0.07805942 0.08671574 0.08481920 0.08683884
[67] 0.07939754 0.08851418 0.07498381 0.07233205 0.08671574 0.08671574

$lwr
 [1] 0.39887109 0.09609419 0.29746543 0.03887676 0.09886604 0.09886604
 [7] 0.13287400 0.13287400 0.08644108 0.39887109 0.01758030 0.29746543
[13] 0.09458859 0.35857236 0.13287400 0.21512673 0.39887109 0.09609419
[19] 0.29746543 0.22483820 0.02758599 0.02758599 0.21512673 0.21512673
[25] 0.09609419 0.39887109 0.29746543 0.22483820 0.35857236 0.09458859
[31] 0.13287400 0.17506663 0.39887109 0.09609419 0.03887676 0.29746543
[37] 0.35857236 0.35857236 0.17506663 0.17506663 0.09609419 0.39887109
[43] 0.29746543 0.22483820 0.09458859 0.09886604 0.13287400 0.21512673
[49] 0.08644108 0.08644108 0.22483820 0.22483820 0.09458859 0.35857236
[55] 0.01994752 0.17506663 0.39887109 0.39887109 0.22483820 0.29746543
[61] 0.35857236 0.35857236 0.17506663 0.21512673 0.08644108 0.39887109
[67] 0.29746543 0.22483820 0.35857236 0.09458859 0.21512673 0.21512673

$upr
 [1] 0.7269447 0.3477399 0.5991420 0.2173139 0.3643505 0.3643505 0.4812023
 [8] 0.4812023 0.4180260 0.7269447 0.1517267 0.5991420 0.3784608 0.6443214
[15] 0.4812023 0.5435675 0.7269447 0.3477399 0.5991420 0.5593657 0.1909065
[22] 0.1909065 0.5435675 0.5435675 0.3477399 0.7269447 0.5991420 0.5593657
[29] 0.6443214 0.3784608 0.4812023 0.4738928 0.7269447 0.3477399 0.2173139
[36] 0.5991420 0.6443214 0.6443214 0.4738928 0.4738928 0.3477399 0.7269447
[43] 0.5991420 0.5593657 0.3784608 0.3643505 0.4812023 0.5435675 0.4180260
[50] 0.4180260 0.5593657 0.5593657 0.3784608 0.6443214 0.1370739 0.4738928
[57] 0.7269447 0.7269447 0.5593657 0.5991420 0.6443214 0.6443214 0.4738928
[64] 0.5435675 0.4180260 0.7269447 0.5991420 0.5593657 0.6443214 0.3784608
[71] 0.5435675 0.5435675

> ## class predictions for the observations:
> predict(fm1, type="class")
$fit
 [1] 2 2 3 3 3 3 4 4 2 2 3 3 3 3 4 4 2 2 3 3 3 3 4 4 2 2 3 3 3 3 4 4 2 2 3 3 3 3
[39] 4 4 2 2 3 3 3 3 4 4 2 2 3 3 3 3 4 4 2 2 3 3 3 3 4 4 2 2 3 3 3 3 4 4
Levels: 1 2 3 4 5

> 
> newData <- expand.grid(temp = c("cold", "warm"),
+                        contact = c("no", "yes"))
> 
> ## Predicted probabilities in all five response categories for each of
> ## the four cases in newData:
> predict(fm1, newdata=newData, type="prob")
$fit
            1          2         3          4          5
1 0.206790132 0.57064970 0.1922909 0.02361882 0.00665041
2 0.020887709 0.20141572 0.5015755 0.20049402 0.07562701
3 0.053546010 0.37764614 0.4430599 0.09582084 0.02992711
4 0.004608274 0.05380128 0.3042099 0.36359581 0.27378469

> ## now include standard errors and intervals:
> predict(fm1, newdata=newData, se.fit=TRUE, interval=TRUE, type="prob")
$fit
            1          2         3          4          5
1 0.206790132 0.57064970 0.1922909 0.02361882 0.00665041
2 0.020887709 0.20141572 0.5015755 0.20049402 0.07562701
3 0.053546010 0.37764614 0.4430599 0.09582084 0.02992711
4 0.004608274 0.05380128 0.3042099 0.36359581 0.27378469

$se.fit
            1          2          3          4          5
1 0.084819201 0.08683884 0.06388672 0.01380264 0.00482850
2 0.013191469 0.07233205 0.07498381 0.06761012 0.03777829
3 0.029762953 0.08851418 0.07939754 0.04257593 0.01734387
4 0.003522846 0.02668355 0.07805942 0.08671574 0.09132786

$lwr
            1          2          3           4           5
1 0.086441084 0.39887109 0.09609419 0.007429029 0.001595527
2 0.005989787 0.09458859 0.35857236 0.098866040 0.027585992
3 0.017580298 0.22483820 0.29746543 0.038876765 0.009475544
4 0.001026538 0.01994752 0.17506663 0.215126732 0.132874005

$upr
           1         2         3          4          5
1 0.41802603 0.7269447 0.3477399 0.07251284 0.02728234
2 0.07022233 0.3784608 0.6443214 0.36435050 0.19090648
3 0.15172666 0.5593657 0.5991420 0.21731390 0.09048786
4 0.02043158 0.1370739 0.4738928 0.54356745 0.48120233

> 
> 
> 
> 
> 
> cleanEx()
> nameEx("predictOld")
> ### * predictOld
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: predict.clm2
> ### Title: Predict Method for CLM fits
> ### Aliases: predict.clm2 predict.clmm2
> ### Keywords: internal
> 
> ### ** Examples
> 
> options(contrasts = c("contr.treatment", "contr.poly"))
> 
> ## More manageable data set for less voluminous printing:
> (tab26 <- with(soup, table("Product" = PROD, "Response" = SURENESS)))
       Response
Product   1   2   3   4   5   6
   Ref  132 161  65  41 121 219
   Test  96  99  50  57 156 650
> dimnames(tab26)[[2]] <- c("Sure", "Not Sure", "Guess", "Guess", "Not Sure", "Sure")
> dat26 <- expand.grid(sureness = as.factor(1:6), prod = c("Ref", "Test"))
> dat26$wghts <- c(t(tab26))
> dat26
   sureness prod wghts
1         1  Ref   132
2         2  Ref   161
3         3  Ref    65
4         4  Ref    41
5         5  Ref   121
6         6  Ref   219
7         1 Test    96
8         2 Test    99
9         3 Test    50
10        4 Test    57
11        5 Test   156
12        6 Test   650
> 
> m1 <- clm2(sureness ~ prod, scale = ~prod, data = dat26,
+           weights = wghts, link = "logistic")
> predict(m1)
 [1] 0.18373313 0.20510835 0.08438208 0.06752717 0.16667487 0.29257440
 [7] 0.08288757 0.09840656 0.04839246 0.04385503 0.13834829 0.58811009
> 
> mN1 <-  clm2(sureness ~ 1, nominal = ~prod, data = dat26,
+             weights = wghts)
> predict(mN1)
 [1] 0.17861975 0.21786198 0.08795670 0.05548038 0.16373478 0.29634641
 [7] 0.08664260 0.08935018 0.04512635 0.05144404 0.14079422 0.58664260
> 
> predict(update(m1, scale = ~.-prod))
 [1] 0.19702319 0.19835927 0.07932257 0.06291764 0.15503077 0.30734657
 [7] 0.07246407 0.09986942 0.05111144 0.04674472 0.14759301 0.58221735
> 
> 
> #################################
> ## Mimicing the behavior of predict.polr:
> if(require(MASS)) {
+     ## Fit model from polr example:
+     fm1 <- clm2(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
+     predict(fm1)
+ 
+     set.seed(123)
+     nlev <- 3
+     y <- gl(nlev, 5)
+     x <- as.numeric(y) + rnorm(15)
+     fm.clm <- clm2(y ~ x)
+     fm.polr <- polr(y ~ x)
+ 
+     ## The equivalent of predict.polr(object, type = "probs"):
+     (pmat.polr <- predict(fm.polr, type = "probs"))
+     ndat <- expand.grid(y = gl(nlev,1), x = x)
+     (pmat.clm <- matrix(predict(fm.clm, newdata = ndat), ncol=nlev,
+                         byrow = TRUE))
+     all.equal(c(pmat.clm), c(pmat.polr), tol = 1e-5) # TRUE
+ 
+     ## The equivalent of predict.polr(object, type = "class"):
+     (class.polr <- predict(fm.polr))
+     (class.clm <- factor(apply(pmat.clm, 1, which.max)))
+     all.equal(class.clm, class.polr) ## TRUE
+ }
Loading required package: MASS
[1] TRUE
> 
> 
> 
> 
> base::options(contrasts = c(unordered = "contr.treatment",ordered = "contr.poly"))
> cleanEx()

detaching ‘package:MASS’

> nameEx("ranef")
> ### * ranef
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: condVar
> ### Title: Extract conditional modes and conditional variances from clmm
> ###   objects
> ### Aliases: ranef condVar ranef.clmm condVar.clmm
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> fm1 <- clmm(rating ~ contact + temp + (1|judge), data=wine)
> 
> ## Extract random effect estimates/conditional modes:
> re <- ranef(fm1, condVar=TRUE)
> 
> ## Get conditional variances:
> attr(re$judge, "condVar")
  (Intercept)
1   0.3067453
2   0.3779357
3   0.3545528
4   0.3651870
5   0.3566066
6   0.3485475
7   0.3435693
8   0.3050453
9   0.3183194
> ## Alternatively:
> condVar(fm1)
$judge
  (Intercept)
1   0.3067453
2   0.3779357
3   0.3545528
4   0.3651870
5   0.3566066
6   0.3485475
7   0.3435693
8   0.3050453
9   0.3183194

> 
> 
> 
> 
> cleanEx()
> nameEx("slice.clm")
> ### * slice.clm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: slice
> ### Title: Slice the likelihood of a clm
> ### Aliases: slice slice.clm plot.slice.clm
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> ## fit model:
> fm1 <- clm(rating ~ contact + temp, data = wine)
> ## slice the likelihood:
> sl1 <- slice(fm1)
> 
> ## three different ways to plot the slices:
> par(mfrow = c(2,3))
> plot(sl1)
> plot(sl1, type = "quadratic", plot.mle = FALSE)
> plot(sl1, type = "linear")
> 
> ## Verify convergence to the optimum:
> sl2 <- slice(fm1, lambda = 1e-5, quad.approx = FALSE)
> plot(sl2)
> 
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("updateOld")
> ### * updateOld
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: update.clm2
> ### Title: Update method for cumulative link models
> ### Aliases: update.clm2 update.clmm2
> ### Keywords: internal
> 
> ### ** Examples
> 
> options(contrasts = c("contr.treatment", "contr.poly"))
> 
> m1 <-  clm2(SURENESS ~ PROD, scale = ~PROD, data = soup,
+            link = "logistic")
> 
> m2 <- update(m1, link = "probit")
> m3 <- update(m1, link = "cloglog")
> m4 <- update(m1, link = "loglog")
> anova(m1, update(m1, scale = ~.-PROD))
Likelihood ratio tests of cumulative link models

Response: SURENESS
           Model Resid. df -2logLik   Test    Df LR stat.  Pr(Chi)
1    PROD | 1 |       1841 5380.664                               
2 PROD | PROD |       1840 5375.489 1 vs 2     1 5.174937 0.022915
> mT1 <- update(m1, threshold = "symmetric")
> 
> 
> 
> 
> base::options(contrasts = c(unordered = "contr.treatment",ordered = "contr.poly"))
> cleanEx()
> nameEx("wine")
> ### * wine
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: wine
> ### Title: Bitterness of wine
> ### Aliases: wine
> ### Keywords: datasets
> 
> ### ** Examples
> 
> 
> head(wine)
  response rating temp contact bottle judge
1       36      2 cold      no      1     1
2       48      3 cold      no      2     1
3       47      3 cold     yes      3     1
4       67      4 cold     yes      4     1
5       77      4 warm      no      5     1
6       60      4 warm      no      6     1
> str(wine)
'data.frame':	72 obs. of  6 variables:
 $ response: num  36 48 47 67 77 60 83 90 17 22 ...
 $ rating  : Ord.factor w/ 5 levels "1"<"2"<"3"<"4"<..: 2 3 3 4 4 4 5 5 1 2 ...
 $ temp    : Factor w/ 2 levels "cold","warm": 1 1 1 1 2 2 2 2 1 1 ...
 $ contact : Factor w/ 2 levels "no","yes": 1 1 2 2 1 1 2 2 1 1 ...
 $ bottle  : Factor w/ 8 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8 1 2 ...
 $ judge   : Factor w/ 9 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 2 2 ...
> 
> ## Variables 'rating' and 'response' are related in the following way:
> (intervals <- seq(0,100, by = 20))
[1]   0  20  40  60  80 100
> all(wine$rating == findInterval(wine$response, intervals)) ## ok
[1] TRUE
> 
> ## A few illustrative tabulations:
> ## Table matching Table 5 in Randall (1989):
> temp.contact.bottle <- with(wine, temp:contact:bottle)[drop=TRUE]
> xtabs(response ~ temp.contact.bottle + judge, data = wine)
                   judge
temp.contact.bottle  1  2  3  4  5  6  7  8  9
         cold:no:1  36 17 36 46 26 46 13 25 12
         cold:no:2  48 22 50 27 45 30 19 32 29
         cold:yes:3 47 14 42 48 61 54 31 39 47
         cold:yes:4 67 50 23 32 41 37 29 40 28
         warm:no:5  77 30 80 57 48 32 22 51 47
         warm:no:6  60 51 81 37 41 60 43 45 38
         warm:yes:7 83 90 73 84 58 88 32 42 72
         warm:yes:8 90 70 62 58 55 73 49 67 65
> 
> ## Table matching Table 6 in Randall (1989):
> with(wine, {
+   tcb <- temp:contact:bottle
+   tcb <- tcb[drop=TRUE]
+   table(tcb, rating)
+ })
            rating
tcb          1 2 3 4 5
  cold:no:1  3 4 2 0 0
  cold:no:2  1 5 3 0 0
  cold:yes:3 1 2 5 1 0
  cold:yes:4 0 5 3 1 0
  warm:no:5  0 3 4 1 1
  warm:no:6  0 2 4 2 1
  warm:yes:7 0 1 2 2 4
  warm:yes:8 0 0 3 5 1
> ## or simply: with(wine, table(bottle, rating))
> 
> ## Table matching Table 1 in Tutz & Hennevogl (1996):
> tab <- xtabs(as.numeric(rating) ~ judge + temp.contact.bottle,
+              data = wine)
> colnames(tab) <-
+   paste(rep(c("c","w"), each = 4), rep(c("n", "n", "y", "y"), 2),
+         1:8, sep=".")
> tab
     temp.contact.bottle
judge c.n.1 c.n.2 c.y.3 c.y.4 w.n.5 w.n.6 w.y.7 w.y.8
    1     2     3     3     4     4     4     5     5
    2     1     2     1     3     2     3     5     4
    3     2     3     3     2     5     5     4     4
    4     3     2     3     2     3     2     5     3
    5     2     3     4     3     3     3     3     3
    6     3     2     3     2     2     4     5     4
    7     1     1     2     2     2     3     2     3
    8     2     2     2     3     3     3     3     4
    9     1     2     3     2     3     2     4     4
> 
> 
> ## A simple model:
> m1 <- clm(rating ~ temp * contact, data = wine)
> summary(m1)
formula: rating ~ temp * contact
data:    wine

 link  threshold nobs logLik AIC    niter max.grad cond.H 
 logit flexible  72   -86.42 186.83 6(0)  5.22e-12 5.1e+01

Coefficients:
                    Estimate Std. Error z value Pr(>|z|)    
tempwarm              2.3212     0.7009   3.311 0.000928 ***
contactyes            1.3475     0.6604   2.041 0.041300 *  
tempwarm:contactyes   0.3595     0.9238   0.389 0.697129    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -1.4113     0.5454  -2.588
2|3   1.1436     0.5097   2.244
3|4   3.3771     0.6382   5.292
4|5   4.9420     0.7509   6.581
> 
> 
> 
> 
> ### * <FOOTER>
> ###
> cleanEx()
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  5.089 4.341 4.587 0 0 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
